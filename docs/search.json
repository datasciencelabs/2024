[
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "Syllabus",
    "section": "",
    "text": "BST 260 Introduction to Data Science\nKresge 202A and 202B (HSPH)\nMonday 09:45 AM - 11:15 AM; Wednesday 09:45 AM - 11:15 AM\nLecture notes: https://datasciencelabs.github.io/2024/\nSlack workspace: https://bst260fall2024.slack.com/\nCanvas: https://canvas.harvard.edu/courses/143922",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#general-information",
    "href": "syllabus.html#general-information",
    "title": "Syllabus",
    "section": "",
    "text": "BST 260 Introduction to Data Science\nKresge 202A and 202B (HSPH)\nMonday 09:45 AM - 11:15 AM; Wednesday 09:45 AM - 11:15 AM\nLecture notes: https://datasciencelabs.github.io/2024/\nSlack workspace: https://bst260fall2024.slack.com/\nCanvas: https://canvas.harvard.edu/courses/143922",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#prerequisites",
    "href": "syllabus.html#prerequisites",
    "title": "Syllabus",
    "section": "Prerequisites",
    "text": "Prerequisites\nWe assume students have taken or are taking a probability and statistics course and have basic programming skills.\nStudents not matriculated in an HSPH Biostatistics graduate program (HDS SM60, BIO SM80 / SM60 / SM1, and CBQG SM80) will be required to score at least 90% on a basic math and programming diagnostic test to enroll in the course. If you are in a HSPH Biostatistics graduate program and you score less than 90% we will contact you to offer supplementary resource to help you be prepared for the course.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#textbooks",
    "href": "syllabus.html#textbooks",
    "title": "Syllabus",
    "section": "Textbooks",
    "text": "Textbooks\n\nIntroduction to Data Science: Data Wrangling and Visualization with R\nIntroduction to Data Science: Statistics and Prediction Algorithms Through Case Studies",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#course-description",
    "href": "syllabus.html#course-description",
    "title": "Syllabus",
    "section": "Course Description",
    "text": "Course Description\nThis course introduces the following:\n\nUNIX/Linux shell\nReproducible document preparation with RStudio, knitr, and markdown\nVersion control with git and GitHub\nR programming\nData wrangling with dplyr and data.table\nData visualization with ggplot2\n\nWe also demonstrate how the following concepts are applied in data analysis:\n\nProbability theory\nStatistical inference and modeling\nHigh-dimensional data techniques\nMachine learning\n\nWe do not cover the theory and details of these methods as they are covered in other courses.\nThroughout the course, we use motivating case studies and data analysis problem sets based on challenges similar to those you encounter in scientific research.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#weekly-course-structure",
    "href": "syllabus.html#weekly-course-structure",
    "title": "Syllabus",
    "section": "Weekly Course Structure",
    "text": "Weekly Course Structure\n\nMonday lectures: We describe the concerts, methods, and skills needed for problem sets.\nWednesday labs: We work together on problem sets.\nFriday: Problem sets due (see Key Dates and Problem Sets).\n\nPlease ensure that you read the chapters listed in the syllabus before each Monday. The lectures are designed with the assumption that you have completed the readings, enabling us to dive deeper into the nuances of data analysis and coding.\nLectures will not be recorded.\nWe will have a Slack workspace for you to ask questions during and after class.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#grade-distribution",
    "href": "syllabus.html#grade-distribution",
    "title": "Syllabus",
    "section": "Grade Distribution",
    "text": "Grade Distribution\n\n\n\nComponent\nWeight\n\n\n\n\n10 problem sets\n50%\n\n\nMidterm 1\n10%\n\n\nMidterm 2\n20%\n\n\nFinal project\n20%",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#problem-sets",
    "href": "syllabus.html#problem-sets",
    "title": "Syllabus",
    "section": "Problem Sets",
    "text": "Problem Sets\nProblem sets will be due every week or every other week, depending on difficulty. They will be due at 11:59 PM on the day denoted on the Problem Sets page.\nSome problem sets include open ended questions that will be difficult to answer on your own. We will be working on these together during Wednesday labs. We also offer office hours where you can get help with unanswered questions.\nProblem sets must be submitted via GitHub. Students are required to have a GitHub account and create a repository for the course. We will be providing further instructions during the first lab.\n10% of the total points for the problem sets will be deducted for every late day. Students can have a total of 4 late days without penalty during the entire semester. No need to provide a written excuse. Providing an excuse does not give you more days unless an accommodation is requested and approved by the Office of Student Affairs (this includes COVID).\nProblem set submissions need to be completely reproducible Quarto documents. If your Quarto file does not compile it will be considered a late day, and you will be notified and will need to resubmit a Quarto file that does compile. You will be deducted further late days for every day it takes for you to turn in a Quarto file that does knit. You are required to check emails that come through the Canvas system, as this the only way we will communicate problems with your problem sets.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#midterm-policy",
    "href": "syllabus.html#midterm-policy",
    "title": "Syllabus",
    "section": "Midterm Policy",
    "text": "Midterm Policy\nBoth midterms are closed book, no internet, and in-class. You are expected to complete them in 1 hour.\nQuestions will be drawn mostly or entirely from the problem sets.\nPlease make sure you can come to class on the midterm dates provided in the Key Dates table below. If you miss the exam, you will need approval from the Office of Student Affairs to receive a makeup. All make-up exams will be completely different from the in-class ones.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#final-project",
    "href": "syllabus.html#final-project",
    "title": "Syllabus",
    "section": "Final Project",
    "text": "Final Project\nFor your final project we ask that you turn in a 4-6 page report using data to answer a public health related question. You can chose from one of the following:\n\nBased on state-level data, how effective where vaccines against SARS-CoV-2 reported cases and COVID-19 hospitalizations and deaths, and vaccination rates.\nWhat was the excess mortality after Hurricane María in Puerto Rico? Where different age groups affected differently?\n\nOptionally, you can select a question that align with your ongoing research. This way, it can be directly beneficial to your work. This will require prior approval from the instructor by October 25.\nYet another option is to build a interactive webpage with poll-driven predictions for the 2024 US elections. Note this will be more challenging as we will not cover tools for interactive webpages until the last week of class (time permitting).\nNote: You should start working on your project after the first midterm. Do not wait until the last week. Teaching staff will be available during office hours.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#chatgpt-policy",
    "href": "syllabus.html#chatgpt-policy",
    "title": "Syllabus",
    "section": "ChatGPT Policy",
    "text": "ChatGPT Policy\nYou can use ChatGPT however you want. Do remember you won’t be able to use it during the midterms.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#key-dates",
    "href": "syllabus.html#key-dates",
    "title": "Syllabus",
    "section": "Key Dates",
    "text": "Key Dates\n\n\n\n\n\n\n\nDate\nEvent\n\n\n\n\nSep 10\nPset 1 due\n\n\nSep 13\nPset 2 due\n\n\nOct 14\nNo class: Indigenous Peoples’ Day\n\n\nOct 16\nMidterm 1: covers material from Sep 04-Oct 11\n\n\nOct 23\nStart final project. Obtain approval if you want to do a personal project instead.\n\n\nNov 11\nNo class: Veterans’ Day\n\n\nNov 25\nMidterm 2: cover material from Sep 04-Nov 22\n\n\nNov 27\nNo class: Thanksgiving Recess Begins\n\n\nDec 20\nFinal Project due",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "slides/productivity/01-unix.html#naming-convention",
    "href": "slides/productivity/01-unix.html#naming-convention",
    "title": "Unix",
    "section": "Naming convention",
    "text": "Naming convention\n\nIn general you want to name your files in a way that is related to their contents and specifies how they relate to other files.\nThe Smithsonian Data Management Best Practices has “five precepts of file naming and organization”"
  },
  {
    "objectID": "slides/productivity/01-unix.html#five-precepts-of-file-naming-and-organization",
    "href": "slides/productivity/01-unix.html#five-precepts-of-file-naming-and-organization",
    "title": "Unix",
    "section": "Five precepts of file naming and organization",
    "text": "Five precepts of file naming and organization\n\nHave a distinctive, human-readable name that gives an indication of the content.\nFollow a consistent pattern that is machine-friendly.\nOrganize files into directories (when necessary) that follow a consistent pattern.\nAvoid repetition of semantic elements among file and directory names.\nHave a file extension that matches the file format (no changing extensions!)\n\nFor specific recommendations we highly recommend you follow The Tidyverse Style Guide"
  },
  {
    "objectID": "slides/productivity/01-unix.html#the-terminal",
    "href": "slides/productivity/01-unix.html#the-terminal",
    "title": "Unix",
    "section": "The terminal",
    "text": "The terminal\n\nInstead of clicking, dragging, and dropping to organize our files and folders, we will be typing Unix commands into the terminal.\nThe way we do this is similar to how we type commands into the R console, but instead of generating plots and statistical summaries, we will be organizing files on our system."
  },
  {
    "objectID": "slides/productivity/01-unix.html#the-terminal-1",
    "href": "slides/productivity/01-unix.html#the-terminal-1",
    "title": "Unix",
    "section": "The terminal",
    "text": "The terminal\n\nThe terminal is integrated into Mac and Linux systems, but Windows users will have to install an emulator. Once you have a terminal open, you can start typing commands.\nYou should see a blinking cursor at the spot where what you type will show up. This position is called the command line."
  },
  {
    "objectID": "slides/productivity/01-unix.html#the-filesystem",
    "href": "slides/productivity/01-unix.html#the-filesystem",
    "title": "Unix",
    "section": "The filesystem",
    "text": "The filesystem"
  },
  {
    "objectID": "slides/productivity/01-unix.html#the-home-directory",
    "href": "slides/productivity/01-unix.html#the-home-directory",
    "title": "Unix",
    "section": "The home directory",
    "text": "The home directory"
  },
  {
    "objectID": "slides/productivity/01-unix.html#windows",
    "href": "slides/productivity/01-unix.html#windows",
    "title": "Unix",
    "section": "Windows",
    "text": "Windows\nThe structure on Windows looks something like this:"
  },
  {
    "objectID": "slides/productivity/01-unix.html#mac",
    "href": "slides/productivity/01-unix.html#mac",
    "title": "Unix",
    "section": "Mac",
    "text": "Mac\nAnd on MacOS something like this:"
  },
  {
    "objectID": "slides/productivity/01-unix.html#working-directory",
    "href": "slides/productivity/01-unix.html#working-directory",
    "title": "Unix",
    "section": "Working directory",
    "text": "Working directory\n\nThe working directory is the directly you are currently in. Later we will see that we can move to other directories using the command line.\nIt’s similar to clicking on folders.\nYou can see your working directory using the Unix command pwd\n\nIn R we can use getwd()"
  },
  {
    "objectID": "slides/productivity/01-unix.html#paths",
    "href": "slides/productivity/01-unix.html#paths",
    "title": "Unix",
    "section": "Paths",
    "text": "Paths\n\nThis string returned in previous command is full path to working directory.\nThe full path to your home directory is stored in an environment variable.\nYou can see it like this echo $HOME"
  },
  {
    "objectID": "slides/productivity/01-unix.html#paths-1",
    "href": "slides/productivity/01-unix.html#paths-1",
    "title": "Unix",
    "section": "Paths",
    "text": "Paths\n\nIn Unix, we use the shorthand ~ as a nickname for your home directory\nExample: the full path for docs (in image above) can be written like this ~/docs.\nMost terminals will show the path to your working directory right on the command line.\nLet’s open a terminal window and see if the working directory is listed."
  },
  {
    "objectID": "slides/productivity/01-unix.html#unix-commands",
    "href": "slides/productivity/01-unix.html#unix-commands",
    "title": "Unix",
    "section": "Unix commands",
    "text": "Unix commands\n\nls: Listing directory content\nmkdir and rmdir: make and remove a directory\ncd: navigating the filesystem by changing directories\npwd: see your workding directory\nmv: moving files\ncp: copying files\nrm: removing files\nless: looking at a file"
  },
  {
    "objectID": "slides/productivity/01-unix.html#autocomplete",
    "href": "slides/productivity/01-unix.html#autocomplete",
    "title": "Unix",
    "section": "Autocomplete",
    "text": "Autocomplete\n\nIn Unix you can auto-complete by hitting tab.\nThis means that we can type cd d then hit tab.\nUnix will either auto-complete if docs is the only directory/file starting with d or show you the options.\nTry it out! Using Unix without auto-complete will make it unbearable."
  },
  {
    "objectID": "slides/productivity/01-unix.html#text-editors",
    "href": "slides/productivity/01-unix.html#text-editors",
    "title": "Unix",
    "section": "Text editors",
    "text": "Text editors\nCommand-line text editors are essential tools, especially for system administrators, developers, and other users who frequently work in a terminal environment. Here are some of the most popular command-line text editors:\n\nNano\nPico\nVi or Vim\nEmacs"
  },
  {
    "objectID": "slides/productivity/01-unix.html#other-very-useful-commands-you-should-learn",
    "href": "slides/productivity/01-unix.html#other-very-useful-commands-you-should-learn",
    "title": "Unix",
    "section": "Other very useful commands you should learn",
    "text": "Other very useful commands you should learn\n\ncurl - download data from the internet.\ntar - archive files and subdirectories of a directory into one file.\nssh - connect to another computer.\nfind - search for files by filename in your system.\ngrep - search for patterns in a file.\nawk/sed - These are two very powerful commands that permit you to find specific strings in files and change them."
  },
  {
    "objectID": "slides/productivity/01-unix.html#resources",
    "href": "slides/productivity/01-unix.html#resources",
    "title": "Unix",
    "section": "Resources",
    "text": "Resources\nTo get started.\n\nhttps://www.codecademy.com/learn/learn-the-command-line\nhttps://www.edx.org/course/introduction-linux-linuxfoundationx-lfs101x-1\nhttps://www.coursera.org/learn/unix"
  },
  {
    "objectID": "slides/productivity/03-quarto.html#the-header",
    "href": "slides/productivity/03-quarto.html#the-header",
    "title": "Quarto",
    "section": "The header",
    "text": "The header\n\nStart a new empty document.\nAt the top you see:\n\n\n---\ntitle: \"Untitled\"\n---\n\n\nThe things between the --- is the YAML header.\nYou will see it used throughout the Quarto guide."
  },
  {
    "objectID": "slides/productivity/03-quarto.html#text-formating",
    "href": "slides/productivity/03-quarto.html#text-formating",
    "title": "Quarto",
    "section": "Text formating",
    "text": "Text formating\n*italics* or _italics_ = italics\n**bold** = bold\n***bold italics*** = bold italics\n~~strikethrough~~ = strikethrough\n`code` = code"
  },
  {
    "objectID": "slides/productivity/03-quarto.html#text-formating-1",
    "href": "slides/productivity/03-quarto.html#text-formating-1",
    "title": "Quarto",
    "section": "Text formating",
    "text": "Text formating\nThis:\n```\nline 1\nline 2\n```\nshows code chunks:\nline 1\nline 2"
  },
  {
    "objectID": "slides/productivity/03-quarto.html#links",
    "href": "slides/productivity/03-quarto.html#links",
    "title": "Quarto",
    "section": "Links",
    "text": "Links\n\nShow the link and add link: &lt;https://quarto.org/docs/guide/&gt;\nAdd link to text: [Quarto Guide](https://quarto.org/docs/guide/)\n\nLooks like this:\nhttps://quarto.org/docs/guide/\nQuarto Guide"
  },
  {
    "objectID": "slides/productivity/03-quarto.html#images",
    "href": "slides/productivity/03-quarto.html#images",
    "title": "Quarto",
    "section": "Images",
    "text": "Images\n![My caption](https://datasciencedojo.com/wp-content/uploads/11-1.jpg)\nShows the plot and caption:\n\nMy captionThe image can also be a local file."
  },
  {
    "objectID": "slides/productivity/03-quarto.html#lists",
    "href": "slides/productivity/03-quarto.html#lists",
    "title": "Quarto",
    "section": "Lists",
    "text": "Lists\nBullets:\n-   bullet 1\n    -   sub-bullet 1\n    -   sub-bullet 2\n-   bullet 2\nLooks like this:\n\nbullet 1\n\nsub-bullet 1\nsub-bullet 2\n\nbullet 2"
  },
  {
    "objectID": "slides/productivity/03-quarto.html#lists-1",
    "href": "slides/productivity/03-quarto.html#lists-1",
    "title": "Quarto",
    "section": "Lists",
    "text": "Lists\nOrdered list:\n1.  Item 1\n2.  Item 2\nLooks like this:\n\nItem 1\nItem 2"
  },
  {
    "objectID": "slides/productivity/03-quarto.html#equations",
    "href": "slides/productivity/03-quarto.html#equations",
    "title": "Quarto",
    "section": "Equations",
    "text": "Equations\n\n\n\n\n\n\n\nNote\n\n\nIf you are going to write technical report, you definitely want to learn LaTeX.\nOnce you learn LaTeX you will never want to use an equation editor again.\nThere are many online tutorials, like this one.\nChatGPT is great at LaTeX"
  },
  {
    "objectID": "slides/productivity/03-quarto.html#equations-1",
    "href": "slides/productivity/03-quarto.html#equations-1",
    "title": "Quarto",
    "section": "Equations",
    "text": "Equations\nExamples:\n\nInline: $Y_i = \\beta_0 + \\beta_1 x_i + \\varepsilon_i$ looks like this \\(Y_i = \\beta_0 + \\beta_1 x_i + \\varepsilon_i\\)\nDisplay math:\n\n$$\n\\mathbf{Y} = \\mathbf{X\\beta} + \\mathbf{\\varepsilon}\n$$\nlooks like this:\n\\[\n\\mathbf{Y} = \\mathbf{X\\beta} + \\mathbf{\\varepsilon}\n\\]"
  },
  {
    "objectID": "slides/productivity/03-quarto.html#computations",
    "href": "slides/productivity/03-quarto.html#computations",
    "title": "Quarto",
    "section": "Computations",
    "text": "Computations\n\nThe main reason we use Quarto is because we can include code and execute the code when compiling the document.\nIn R we refer to them as R chunks.\nThis applies to plots as well; the plot will be placed in that position.\n\n\n\n\n\n\n\nNote\n\n\nTo add your own R chunks, you can type the characters above quickly with the key binding command-option-I on the Mac and Ctrl-Alt-I on Windows."
  },
  {
    "objectID": "slides/productivity/03-quarto.html#computations-1",
    "href": "slides/productivity/03-quarto.html#computations-1",
    "title": "Quarto",
    "section": "Computations",
    "text": "Computations\nWe can write something like this:\n```{r}\nx &lt;- 1\ny &lt;- 2\nx + y\n```"
  },
  {
    "objectID": "slides/productivity/03-quarto.html#computations-2",
    "href": "slides/productivity/03-quarto.html#computations-2",
    "title": "Quarto",
    "section": "Computations",
    "text": "Computations\nIt look slike this:\n\nx &lt;- 1\ny &lt;- 2\nx + y\n\n[1] 3\n\n\nNote that it was evaluated and the result is shown."
  },
  {
    "objectID": "slides/productivity/03-quarto.html#computations-3",
    "href": "slides/productivity/03-quarto.html#computations-3",
    "title": "Quarto",
    "section": "Computations",
    "text": "Computations\n\nBy default, the code and result will show up as well.\nYou can send arguments to control the behavior with |#\nFor example, to avoid showing code in the final document, you can use the argument echo: FALSE.\n\n```{r}\n#| echo: false\nx &lt;- 1\ny &lt;- 2\nx + y\n```"
  },
  {
    "objectID": "slides/productivity/03-quarto.html#computations-4",
    "href": "slides/productivity/03-quarto.html#computations-4",
    "title": "Quarto",
    "section": "Computations",
    "text": "Computations\n\nThere are many options (auto-complete shows them).\nFor example, to avoid the the code running you can use eval: FALSE.\nTo avoid showing warnings warning: FALSE, to avoid showing messages message: FALSE.\n\n\n\n\n\n\n\nNote\n\n\nIf you want to apply an option globally, these can be set globally in the header.\nexecute:\n  echo: false"
  },
  {
    "objectID": "slides/productivity/03-quarto.html#computations-5",
    "href": "slides/productivity/03-quarto.html#computations-5",
    "title": "Quarto",
    "section": "Computations",
    "text": "Computations\n\nWe recommend getting into the habit of labeling code chunks:\n\n```{r}\n#| label: one-plus-two\nx &lt;- 1\ny &lt;- 2\nx + y\n```\n\nHelps with debugging\nGives meaningful names to generated images."
  },
  {
    "objectID": "slides/productivity/03-quarto.html#more-on-markdown",
    "href": "slides/productivity/03-quarto.html#more-on-markdown",
    "title": "Quarto",
    "section": "More on markdown",
    "text": "More on markdown\nThere is a lot more you can do with R markdown. We highly recommend you continue learning as you gain more experience writing reports in R. There are many free resources on the internet including:\n\nRStudio’s tutorial: https://quarto.org/docs/get-started/hello/rstudio.html\nThe knitR book: https://yihui.name/knitr/\nPandoc’s Markdown in-depth documentation\nGuide for academic reports"
  },
  {
    "objectID": "slides/productivity/03-quarto.html#quarto-render",
    "href": "slides/productivity/03-quarto.html#quarto-render",
    "title": "Quarto",
    "section": "quarto render",
    "text": "quarto render\n\nRStudio provides the Render button that makes it easier to compile the document.\nYou can also type quarto render filename.qmd on the command line. This offers many options.\nYou can produce html, pdf, or word documents.\nYou can specify the default in the YAML header using: format: html, format: pdf,format: docx, or format: gfm (gfm stands for GitHub flavored markdown, a convenient way to share your reports)."
  },
  {
    "objectID": "slides/inference/23-parameters-estimates.html#the-sampling-model-for-polls",
    "href": "slides/inference/23-parameters-estimates.html#the-sampling-model-for-polls",
    "title": "Parameters and Estimates",
    "section": "The sampling model for polls",
    "text": "The sampling model for polls\nThe week before the election Real Clear Politics showed this:"
  },
  {
    "objectID": "slides/inference/23-parameters-estimates.html#the-sampling-model-for-polls-1",
    "href": "slides/inference/23-parameters-estimates.html#the-sampling-model-for-polls-1",
    "title": "Parameters and Estimates",
    "section": "The sampling model for polls",
    "text": "The sampling model for polls\n\nTo help us understand the connection between polls and what we have learned, let’s construct a situation similar to what pollsters face.\nTo simulate the challenge pollsters encounter in terms of competing with other pollsters for media attention, we will use an urn filled with beads to represent voters, and pretend we are competing for a $25 dollar prize.\nThe challenge is to guess the spread between the proportion of blue and red beads in an urn."
  },
  {
    "objectID": "slides/inference/23-parameters-estimates.html#the-sampling-model-for-polls-2",
    "href": "slides/inference/23-parameters-estimates.html#the-sampling-model-for-polls-2",
    "title": "Parameters and Estimates",
    "section": "The sampling model for polls",
    "text": "The sampling model for polls\n\nBefore making a prediction, you can take a sample (with replacement) from the urn.\nTo reflect the fact that running polls is expensive, it costs you $0.10 for each bead you sample.\nTherefore, if your sample size is 250, and you win, you will break even since you would have paid $25 to collect your $25 prize.\nYour entry into the competition can be an interval."
  },
  {
    "objectID": "slides/inference/23-parameters-estimates.html#the-sampling-model-for-polls-3",
    "href": "slides/inference/23-parameters-estimates.html#the-sampling-model-for-polls-3",
    "title": "Parameters and Estimates",
    "section": "The sampling model for polls",
    "text": "The sampling model for polls\n\nIf the interval you submit contains the true proportion, you receive half what you paid and proceed to the second phase of the competition.\nIn the second phase, the entry with the smallest interval is selected as the winner.\nThe dslabs package includes a function that shows a random draw from this urn:\n\n\nset.seed(1)\nlibrary(tidyverse) \nlibrary(dslabs) \ntake_poll(25)"
  },
  {
    "objectID": "slides/inference/23-parameters-estimates.html#populations-samples-parameters-and-estimates",
    "href": "slides/inference/23-parameters-estimates.html#populations-samples-parameters-and-estimates",
    "title": "Parameters and Estimates",
    "section": "Populations, samples, parameters, and estimates",
    "text": "Populations, samples, parameters, and estimates\n\nWe want to predict difference proportion of blue beads - proportion of red beads\nLet’s the proportion of blue \\(p\\)\nWe want to estimate \\(p - (1-p)\\) = \\(2p - 1\\)."
  },
  {
    "objectID": "slides/inference/23-parameters-estimates.html#populations-samples-parameters-and-estimates-1",
    "href": "slides/inference/23-parameters-estimates.html#populations-samples-parameters-and-estimates-1",
    "title": "Parameters and Estimates",
    "section": "Populations, samples, parameters, and estimates",
    "text": "Populations, samples, parameters, and estimates\n\nIn statistical class, the beads in the urn are called the population.\nThe proportion of blue beads in the population \\(p\\) is called a parameter.\nThe 25 beads we see in the previous plot are called a sample."
  },
  {
    "objectID": "slides/inference/23-parameters-estimates.html#populations-samples-parameters-and-estimates-2",
    "href": "slides/inference/23-parameters-estimates.html#populations-samples-parameters-and-estimates-2",
    "title": "Parameters and Estimates",
    "section": "Populations, samples, parameters, and estimates",
    "text": "Populations, samples, parameters, and estimates\n\nThe goal of statistical inference is to predict the parameter \\(p\\) based on the observed data in the sample.\nCan we do this with the 25 observations above? It is certainly informative.\nFor example, given that we see 13 red and 12 blue beads, it is unlikely that \\(p\\) &gt; .9 or \\(p\\) &lt; .1.\nWe want to construct an estimate of \\(p\\) using only the information we observe."
  },
  {
    "objectID": "slides/inference/23-parameters-estimates.html#populations-samples-parameters-and-estimates-3",
    "href": "slides/inference/23-parameters-estimates.html#populations-samples-parameters-and-estimates-3",
    "title": "Parameters and Estimates",
    "section": "Populations, samples, parameters, and estimates",
    "text": "Populations, samples, parameters, and estimates\n\nObserve that in the four random samples shown above, the sample proportions range from 0.44 to 0.60."
  },
  {
    "objectID": "slides/inference/23-parameters-estimates.html#the-sample-average",
    "href": "slides/inference/23-parameters-estimates.html#the-sample-average",
    "title": "Parameters and Estimates",
    "section": "The sample average",
    "text": "The sample average\n\nWe use the symbol \\(\\bar{X}\\) to represent this average.\nIn statistics textbooks, a bar on top of a symbol typically denotes the average.\nThe theory we just covered about the sum of draws becomes useful because the average is a sum of draws multiplied by the constant \\(1/N\\):\n\n\\[\\bar{X} = \\frac{1}{N} \\sum_{i=1}^N X_i\\]"
  },
  {
    "objectID": "slides/inference/23-parameters-estimates.html#the-sample-average-1",
    "href": "slides/inference/23-parameters-estimates.html#the-sample-average-1",
    "title": "Parameters and Estimates",
    "section": "The sample average",
    "text": "The sample average\n\nWhat do we know about the distribution of the sum?\nWe know that the expected value of the sum of draws is \\(N\\) times the average of the values in the urn.\nWe know that the average of the 0s and 1s in the urn must be \\(p\\), the proportion of blue beads.\nThere is an important difference compared to what we did previously: we don’t know the composition of the urn.\nThis is what we want to find out: we are trying to estimate \\(p\\)."
  },
  {
    "objectID": "slides/inference/23-parameters-estimates.html#parameters",
    "href": "slides/inference/23-parameters-estimates.html#parameters",
    "title": "Parameters and Estimates",
    "section": "Parameters",
    "text": "Parameters\n\nJust as we use variables to define unknowns in systems of equations, in statistical inference, we define parameters to represent unknown parts of our models.\nWe define the parameters \\(p\\) to represent the the proportion of blue beads in the urn.\nSince our main goal is determining \\(p\\), we are going to estimate this parameter.\nThe concepts presented here on how we estimate parameters, and provide insights into how good these estimates are, extend to many data analysis tasks."
  },
  {
    "objectID": "slides/inference/23-parameters-estimates.html#parameters-1",
    "href": "slides/inference/23-parameters-estimates.html#parameters-1",
    "title": "Parameters and Estimates",
    "section": "Parameters",
    "text": "Parameters\n\nFor example, we may want to determine\n\nthe difference in health improvement between patients receiving treatment and a control group,\ninvestigate the health effects of smoking on a population,\nanalyze the differences in racial groups of fatal shootings by police, or\nassess the rate of change in life expectancy in the US during the last 10 years."
  },
  {
    "objectID": "slides/inference/23-parameters-estimates.html#parameters-2",
    "href": "slides/inference/23-parameters-estimates.html#parameters-2",
    "title": "Parameters and Estimates",
    "section": "Parameters",
    "text": "Parameters\n\nAll these questions can be framed as a task of estimating a parameter from a sample.\nThe properties we learned tell us that:\n\n\\[\n\\mbox{E}(\\bar{X}) = p\n\\]\nand\n\\[\n\\mbox{SE}(\\bar{X}) = \\sqrt{p(1-p)/N}\n\\]"
  },
  {
    "objectID": "slides/inference/23-parameters-estimates.html#properties-of-our-estimate",
    "href": "slides/inference/23-parameters-estimates.html#properties-of-our-estimate",
    "title": "Parameters and Estimates",
    "section": "Properties of our estimate",
    "text": "Properties of our estimate\n\nThe law of large numbers tells us that with a large enough poll, our estimate converges to \\(p\\).\nIf we take a large enough poll to make our standard error about 1%, we will be quite certain about who will win.\nBut how large does the poll have to be for the standard error to be this small?\nOne problem is that we do not know \\(p\\), so we can’t compute the standard error."
  },
  {
    "objectID": "slides/inference/23-parameters-estimates.html#properties-of-our-estimate-1",
    "href": "slides/inference/23-parameters-estimates.html#properties-of-our-estimate-1",
    "title": "Parameters and Estimates",
    "section": "Properties of our estimate",
    "text": "Properties of our estimate\n\nFor illustrative purposes, let’s assume that \\(p=0.51\\) and make a plot of the standard error versus the sample size \\(N\\):"
  },
  {
    "objectID": "slides/inference/23-parameters-estimates.html#properties-of-our-estimate-2",
    "href": "slides/inference/23-parameters-estimates.html#properties-of-our-estimate-2",
    "title": "Parameters and Estimates",
    "section": "Properties of our estimate",
    "text": "Properties of our estimate\n\nThe plot shows that we would need a poll of over 10,000 people to achieve a standard error that low.\nWe rarely see polls of this size due in part to the associated costs.\nAccording to the Real Clear Politics table, sample sizes in opinion polls range from 500-3,500 people.\nFor a sample size of 1,000 and \\(p=0.51\\), the standard error is:\n\n\nsqrt(p*(1 - p))/sqrt(1000) \n\n[1] 0.01580823"
  },
  {
    "objectID": "slides/inference/23-parameters-estimates.html#properties-of-our-estimate-3",
    "href": "slides/inference/23-parameters-estimates.html#properties-of-our-estimate-3",
    "title": "Parameters and Estimates",
    "section": "Properties of our estimate",
    "text": "Properties of our estimate\n\nThe CLT tells us that the distribution function for a sum of draws is approximately normal.\nUsing the properties we learned: \\(\\bar{X}\\) has an approximately normal distribution with expected value \\(p\\) and standard error \\(\\sqrt{p(1-p)/N}\\)."
  },
  {
    "objectID": "slides/inference/23-parameters-estimates.html#central-limit-theorem",
    "href": "slides/inference/23-parameters-estimates.html#central-limit-theorem",
    "title": "Parameters and Estimates",
    "section": "Central Limit Theorem",
    "text": "Central Limit Theorem\n\nNow how can answer questions like what is the probability that we are within 1% from \\(p\\).\nWe are basically asking what is:\n\n\\[\n\\mbox{Pr}(| \\bar{X} - p| \\leq .01)\n\\]\nwhich is the same as:\n\\[\n\\mbox{Pr}(\\bar{X}\\leq p + .01) - \\mbox{Pr}(\\bar{X} \\leq p - .01)\n\\]"
  },
  {
    "objectID": "slides/inference/23-parameters-estimates.html#central-limit-theorem-1",
    "href": "slides/inference/23-parameters-estimates.html#central-limit-theorem-1",
    "title": "Parameters and Estimates",
    "section": "Central Limit Theorem",
    "text": "Central Limit Theorem\n\nSince \\(p\\) is the expected value and \\(\\mbox{SE}(\\bar{X}) = \\sqrt{p(1-p)/N}\\) is the standard error, we get:\n\n\\[\n\\mbox{Pr}\\left(Z \\leq \\frac{ \\,.01} {\\mbox{SE}(\\bar{X})} \\right) -\n\\mbox{Pr}\\left(Z \\leq - \\frac{ \\,.01} {\\mbox{SE}(\\bar{X})} \\right)  \n\\]"
  },
  {
    "objectID": "slides/inference/23-parameters-estimates.html#central-limit-theorem-2",
    "href": "slides/inference/23-parameters-estimates.html#central-limit-theorem-2",
    "title": "Parameters and Estimates",
    "section": "Central Limit Theorem",
    "text": "Central Limit Theorem\n\nOne problem we have is that since we don’t know \\(p\\), we don’t know \\(\\mbox{SE}(\\bar{X})\\).\nHowever, it turns out that the CLT still works if we estimate the standard error by using \\(\\bar{X}\\) in place of \\(p\\).\nWe say that we plug-in the estimate.\nOur estimate of the standard error is therefore:\n\n\\[\n\\hat{\\mbox{SE}}(\\bar{X})=\\sqrt{\\bar{X}(1-\\bar{X})/N}\n\\]"
  },
  {
    "objectID": "slides/inference/23-parameters-estimates.html#central-limit-theorem-3",
    "href": "slides/inference/23-parameters-estimates.html#central-limit-theorem-3",
    "title": "Parameters and Estimates",
    "section": "Central Limit Theorem",
    "text": "Central Limit Theorem\n\nNow we continue with our calculation, but dividing by\n\n\\[\\hat{\\mbox{SE}}(\\bar{X})=\\sqrt{\\bar{X}(1-\\bar{X})/N})\\]"
  },
  {
    "objectID": "slides/inference/23-parameters-estimates.html#central-limit-theorem-4",
    "href": "slides/inference/23-parameters-estimates.html#central-limit-theorem-4",
    "title": "Parameters and Estimates",
    "section": "Central Limit Theorem",
    "text": "Central Limit Theorem\n\nIn our first sample, we had 12 blue and 13 red, so \\(\\bar{X} = 0.48\\) and our estimate of standard error is:\n\n\nx_hat &lt;- 0.48 \nse &lt;- sqrt(x_hat*(1-x_hat)/25) \nse \n\n[1] 0.09991997"
  },
  {
    "objectID": "slides/inference/23-parameters-estimates.html#central-limit-theorem-5",
    "href": "slides/inference/23-parameters-estimates.html#central-limit-theorem-5",
    "title": "Parameters and Estimates",
    "section": "Central Limit Theorem",
    "text": "Central Limit Theorem\n\nNow, we can answer the question of the probability of being close to \\(p\\).\nThe answer is:\n\n\npnorm(0.01/se) - pnorm(-0.01/se) \n\n[1] 0.07971926\n\n\n\nTherefore, there is a small chance that we will be close."
  },
  {
    "objectID": "slides/inference/23-parameters-estimates.html#central-limit-theorem-6",
    "href": "slides/inference/23-parameters-estimates.html#central-limit-theorem-6",
    "title": "Parameters and Estimates",
    "section": "Central Limit Theorem",
    "text": "Central Limit Theorem\n\nEarlier, we mentioned the margin of error.\nNow, we can define it simply as two times the standard error, which we can now estimate.\n\n\n1.96*se \n\n[1] 0.1958431"
  },
  {
    "objectID": "slides/inference/23-parameters-estimates.html#central-limit-theorem-7",
    "href": "slides/inference/23-parameters-estimates.html#central-limit-theorem-7",
    "title": "Parameters and Estimates",
    "section": "Central Limit Theorem",
    "text": "Central Limit Theorem\n\nWhy do we multiply by 1.96?\nBecause if you ask what is the probability that we are within 1.96 standard errors from \\(p\\), we get:\n\n\\[\n\\mbox{Pr}\\left(Z \\leq \\, 1.96\\,\\mbox{SE}(\\bar{X})  / \\mbox{SE}(\\bar{X}) \\right) -\n\\mbox{Pr}\\left(Z \\leq - 1.96\\, \\mbox{SE}(\\bar{X}) / \\mbox{SE}(\\bar{X}) \\right)  \n\\]\nwhich is:\n\\[\n\\mbox{Pr}\\left(Z \\leq 1.96 \\right) -\n\\mbox{Pr}\\left(Z \\leq - 1.96\\right)  = 0.95\n\\]"
  },
  {
    "objectID": "slides/inference/23-parameters-estimates.html#central-limit-theorem-8",
    "href": "slides/inference/23-parameters-estimates.html#central-limit-theorem-8",
    "title": "Parameters and Estimates",
    "section": "Central Limit Theorem",
    "text": "Central Limit Theorem\nToo see this:\n\npnorm(1.96) - pnorm(-1.96) \n\n[1] 0.9500042"
  },
  {
    "objectID": "slides/inference/23-parameters-estimates.html#central-limit-theorem-9",
    "href": "slides/inference/23-parameters-estimates.html#central-limit-theorem-9",
    "title": "Parameters and Estimates",
    "section": "Central Limit Theorem",
    "text": "Central Limit Theorem\n\nThere is a 95% probability that \\(\\bar{X}\\) will be within \\(1.96\\times \\hat{SE}(\\bar{X})\\), in our case within about 0.2, of \\(p\\).\nObserve that 95% is somewhat of an arbitrary choice and sometimes other percentages are used, but it is the most commonly used value to define margin of error."
  },
  {
    "objectID": "slides/inference/23-parameters-estimates.html#a-monte-carlo-simulation",
    "href": "slides/inference/23-parameters-estimates.html#a-monte-carlo-simulation",
    "title": "Parameters and Estimates",
    "section": "A Monte Carlo simulation",
    "text": "A Monte Carlo simulation\n\nB &lt;- 10000 \nN &lt;- 1000 \nx_hat &lt;- replicate(B, { \n  x &lt;- sample(c(0,1), size = N, replace = TRUE, prob = c(1 - p, p)) \n  mean(x) \n}) \n\n\nThe problem is, of course, that we don’t know p."
  },
  {
    "objectID": "slides/inference/23-parameters-estimates.html#a-monte-carlo-simulation-1",
    "href": "slides/inference/23-parameters-estimates.html#a-monte-carlo-simulation-1",
    "title": "Parameters and Estimates",
    "section": "A Monte Carlo simulation",
    "text": "A Monte Carlo simulation\n\nLet’s set p=0.45.\nWe can then simulate a poll:\n\n\np &lt;- 0.45 \nN &lt;- 1000 \nx &lt;- sample(c(0, 1), size = N, replace = TRUE, prob = c(1 - p, p)) \nx_hat &lt;- mean(x) \n\n\nIn this particular sample, our estimate is x_hat.\nWe can use that code to do a Monte Carlo simulation:"
  },
  {
    "objectID": "slides/inference/23-parameters-estimates.html#a-monte-carlo-simulation-2",
    "href": "slides/inference/23-parameters-estimates.html#a-monte-carlo-simulation-2",
    "title": "Parameters and Estimates",
    "section": "A Monte Carlo simulation",
    "text": "A Monte Carlo simulation\n\nB &lt;- 10000 \nx_hat &lt;- replicate(B, { \n  x &lt;- sample(c(0, 1), size = N, replace = TRUE, prob = c(1 - p, p)) \n  mean(x) \n})"
  },
  {
    "objectID": "slides/inference/23-parameters-estimates.html#a-monte-carlo-simulation-3",
    "href": "slides/inference/23-parameters-estimates.html#a-monte-carlo-simulation-3",
    "title": "Parameters and Estimates",
    "section": "A Monte Carlo simulation",
    "text": "A Monte Carlo simulation\n\nTo review, the theory tells us that \\(\\bar{X}\\) is approximately normally distributed, has expected value \\(p=\\) 0.45, and standard error \\(\\sqrt{p(1-p)/N}\\) = 0.0157321.\nThe simulation confirms this:\n\n\nmean(x_hat) \n\n[1] 0.4498571\n\nsd(x_hat) \n\n[1] 0.01558679"
  },
  {
    "objectID": "slides/inference/23-parameters-estimates.html#a-monte-carlo-simulation-4",
    "href": "slides/inference/23-parameters-estimates.html#a-monte-carlo-simulation-4",
    "title": "Parameters and Estimates",
    "section": "A Monte Carlo simulation",
    "text": "A Monte Carlo simulation\n\nA histogram and qqplot confirm that the normal approximation is also accurate:"
  },
  {
    "objectID": "slides/inference/23-parameters-estimates.html#a-monte-carlo-simulation-5",
    "href": "slides/inference/23-parameters-estimates.html#a-monte-carlo-simulation-5",
    "title": "Parameters and Estimates",
    "section": "A Monte Carlo simulation",
    "text": "A Monte Carlo simulation\n\nOf course, in real life, we would never be able to run such an experiment because we don’t know \\(p\\).\nHowever, we can run it for various values of \\(p\\) and \\(N\\) and see that the theory does indeed work well for most values.\nYou can easily do this by rerunning the code above after changing the values of p and N."
  },
  {
    "objectID": "slides/inference/23-parameters-estimates.html#the-spread",
    "href": "slides/inference/23-parameters-estimates.html#the-spread",
    "title": "Parameters and Estimates",
    "section": "The spread",
    "text": "The spread\n\nWe did all this theory for the estimate of \\(p\\). How do we estimate the spread \\(2p - 1\\)?"
  },
  {
    "objectID": "slides/inference/23-parameters-estimates.html#why-not-run-a-very-large-poll",
    "href": "slides/inference/23-parameters-estimates.html#why-not-run-a-very-large-poll",
    "title": "Parameters and Estimates",
    "section": "Why not run a very large poll?",
    "text": "Why not run a very large poll?\n\nFor realistic values of \\(p\\), let’s say ranging from 0.35 to 0.65, if we conduct a very large poll with 100,000 people, theory tells us that we would predict the election perfectly, as the largest possible margin of error is around 0.3%."
  },
  {
    "objectID": "slides/inference/23-parameters-estimates.html#why-not-run-a-very-large-poll-1",
    "href": "slides/inference/23-parameters-estimates.html#why-not-run-a-very-large-poll-1",
    "title": "Parameters and Estimates",
    "section": "Why not run a very large poll?",
    "text": "Why not run a very large poll?\n\nOne reason is that conducting such a poll is very expensive.\nAnother, and possibly more important reason, is that theory has its limitations.\nPolling is much more complicated than simply picking beads from an urn.\nSome people might lie to pollsters, and others might not have phones."
  },
  {
    "objectID": "slides/inference/23-parameters-estimates.html#bias-why-not-run-a-very-large-poll",
    "href": "slides/inference/23-parameters-estimates.html#bias-why-not-run-a-very-large-poll",
    "title": "Parameters and Estimates",
    "section": "Bias: Why not run a very large poll?",
    "text": "Bias: Why not run a very large poll?\n\nHowever, perhaps the most important way an actual poll differs from an urn model is that we don’t actually know for sure who is in our population and who is not.\nHow do we know who is going to vote? Are we reaching all possible voters? Hence, even if our margin of error is very small, it might not be exactly right that our expected value is \\(p\\).\nWe call this bias."
  },
  {
    "objectID": "slides/inference/23-parameters-estimates.html#bias-why-not-run-a-very-large-poll-1",
    "href": "slides/inference/23-parameters-estimates.html#bias-why-not-run-a-very-large-poll-1",
    "title": "Parameters and Estimates",
    "section": "Bias: Why not run a very large poll?",
    "text": "Bias: Why not run a very large poll?\n\nHistorically, we observe that polls are indeed biased, although not by a substantial amount.\nThe typical bias appears to be about 2-3%."
  },
  {
    "objectID": "slides/wrangling/15-web-scraping.html#scraping-html",
    "href": "slides/wrangling/15-web-scraping.html#scraping-html",
    "title": "Web Scraping",
    "section": "Scraping HTML",
    "text": "Scraping HTML\n\nThe data we need to answer a question is not always in a spreadsheet ready for us to read.\nFor example, the US murders dataset we used in the R Basics chapter originally comes from this Wikipedia page:\n\n\nurl &lt;- paste0(\"https://en.wikipedia.org/w/index.php?title=\", \n              \"Gun_violence_in_the_United_States_by_state\", \n              \"&direction=prev&oldid=810166167\")"
  },
  {
    "objectID": "slides/wrangling/15-web-scraping.html#scraping-html-1",
    "href": "slides/wrangling/15-web-scraping.html#scraping-html-1",
    "title": "Web Scraping",
    "section": "Scraping HTML",
    "text": "Scraping HTML\n\nYou can see the data table when you visit the webpage:\n\n.\n\nWeb scraping, or web harvesting, is the term we use to describe the process of extracting data from a website."
  },
  {
    "objectID": "slides/wrangling/15-web-scraping.html#scraping-html-2",
    "href": "slides/wrangling/15-web-scraping.html#scraping-html-2",
    "title": "Web Scraping",
    "section": "Scraping HTML",
    "text": "Scraping HTML\n\nThe reason we can do this is because the information used by a browser to render webpages is received as a text file from a server.\nThe text is code written in hyper text markup language (HTML).\nEvery browser has a way to show the html source code for a page, each one different.\nOn Chrome, you can use Control-U on a PC and command+alt+U on a Mac."
  },
  {
    "objectID": "slides/wrangling/15-web-scraping.html#scraping-html-3",
    "href": "slides/wrangling/15-web-scraping.html#scraping-html-3",
    "title": "Web Scraping",
    "section": "Scraping HTML",
    "text": "Scraping HTML\n."
  },
  {
    "objectID": "slides/wrangling/15-web-scraping.html#html",
    "href": "slides/wrangling/15-web-scraping.html#html",
    "title": "Web Scraping",
    "section": "HTML",
    "text": "HTML\n\nBecause this code is accessible, we can download the HTML file, import it into R, and then write programs to extract the information we need from the page.\nHowever, once we look at HTML code, this might seem like a daunting task.\nBut we will show you some convenient tools to facilitate the process."
  },
  {
    "objectID": "slides/wrangling/15-web-scraping.html#html-1",
    "href": "slides/wrangling/15-web-scraping.html#html-1",
    "title": "Web Scraping",
    "section": "HTML",
    "text": "HTML\n\nTo get an idea of how it works, here are a few lines of code from the Wikipedia page that provides the US murders data:\n\n&lt;table class=\"wikitable sortable\"&gt; \n&lt;tr&gt; \n&lt;th&gt;State&lt;/th&gt; \n&lt;th&gt;&lt;a href=\"/wiki/List_of_U.S._states_and_territories_by_population\"  \ntitle=\"List of U.S. states and territories by population\"&gt;Population&lt;/a&gt;&lt;br /&gt; \n&lt;small&gt;(total inhabitants)&lt;/small&gt;&lt;br /&gt; \n&lt;small&gt;(2015)&lt;/small&gt; &lt;sup id=\"cite_ref-1\" class=\"reference\"&gt; \n&lt;a href=\"#cite_note-1\"&gt;[1]&lt;/a&gt;&lt;/sup&gt;&lt;/th&gt; \n&lt;th&gt;Murders and Nonnegligent \n&lt;p&gt;Manslaughter&lt;br /&gt; \n&lt;small&gt;(total deaths)&lt;/small&gt;&lt;br /&gt; \n&lt;small&gt;(2015)&lt;/small&gt; &lt;sup id=\"cite_ref-2\" class=\"reference\"&gt; \n&lt;a href=\"#cite_note-2\"&gt;[2]&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt; \n&lt;/th&gt; \n&lt;th&gt;Murder and Nonnegligent \n&lt;p&gt;Manslaughter Rate&lt;br /&gt; \n&lt;small&gt;(per 100,000 inhabitants)&lt;/small&gt;&lt;br /&gt; \n&lt;small&gt;(2015)&lt;/small&gt;&lt;/p&gt; \n&lt;/th&gt; \n&lt;/tr&gt; \n&lt;tr&gt; \n&lt;td&gt;&lt;a href=\"/wiki/Alabama\" title=\"Alabama\"&gt;Alabama&lt;/a&gt;&lt;/td&gt; \n&lt;td&gt;4,853,875&lt;/td&gt; \n&lt;td&gt;348&lt;/td&gt; \n&lt;td&gt;7.2&lt;/td&gt; \n&lt;/tr&gt; \n&lt;tr&gt; \n&lt;td&gt;&lt;a href=\"/wiki/Alaska\" title=\"Alaska\"&gt;Alaska&lt;/a&gt;&lt;/td&gt; \n&lt;td&gt;737,709&lt;/td&gt; \n&lt;td&gt;59&lt;/td&gt; \n&lt;td&gt;8.0&lt;/td&gt; \n&lt;/tr&gt; \n&lt;tr&gt;"
  },
  {
    "objectID": "slides/wrangling/15-web-scraping.html#html-2",
    "href": "slides/wrangling/15-web-scraping.html#html-2",
    "title": "Web Scraping",
    "section": "HTML",
    "text": "HTML\n\nYou can actually see the data, except data values are surrounded by html code such as &lt;td&gt;.\nWe can also see a pattern of how it is stored.\nIf you know HTML, you can write programs that leverage knowledge of these patterns to extract what we want.\nWe also take advantage of a language widely used to make webpages look “pretty” called Cascading Style Sheets (CSS)."
  },
  {
    "objectID": "slides/wrangling/15-web-scraping.html#html-3",
    "href": "slides/wrangling/15-web-scraping.html#html-3",
    "title": "Web Scraping",
    "section": "HTML",
    "text": "HTML\n\nAlthough we provide tools that make it possible to scrape data without knowing HTML, it is useful to learn some HTML and CSS.\nNot only does this improve your scraping skills, but it might come in handy if you are creating a webpage to showcase your work.\nThere are plenty of online courses and tutorials for learning these.\nTwo examples are Codeacademy and W3schools."
  },
  {
    "objectID": "slides/wrangling/15-web-scraping.html#the-rvest-package",
    "href": "slides/wrangling/15-web-scraping.html#the-rvest-package",
    "title": "Web Scraping",
    "section": "The rvest package",
    "text": "The rvest package\n\nThe tidyverse provides a web harvesting package called rvest.\nThe first step using this package is to import the webpage into R.\nThe package makes this quite simple:\n\n\nlibrary(tidyverse) \nlibrary(rvest) \nh &lt;- read_html(url) \n\n\nNote that the entire Murders in the US Wikipedia webpage is now contained in h."
  },
  {
    "objectID": "slides/wrangling/15-web-scraping.html#the-rvest-package-1",
    "href": "slides/wrangling/15-web-scraping.html#the-rvest-package-1",
    "title": "Web Scraping",
    "section": "The rvest package",
    "text": "The rvest package\n\nThe class of this object is:\n\n\nclass(h) \n\n[1] \"xml_document\" \"xml_node\"    \n\n\n\nThe rvest package is actually more general; it handles XML documents.\nXML is a general markup language (that’s what the ML stands for) that can be used to represent any kind of data.\nHTML is a specific type of XML specifically developed for representing webpages."
  },
  {
    "objectID": "slides/wrangling/15-web-scraping.html#the-rvest-package-2",
    "href": "slides/wrangling/15-web-scraping.html#the-rvest-package-2",
    "title": "Web Scraping",
    "section": "The rvest package",
    "text": "The rvest package\n\nNow, how do we extract the table from the object h? If you were to print h, we would see information about the object that is not very informative.\nWe can see all the code that defines the downloaded webpage using the html_text function like this:\n\n\nhtml_text(h)"
  },
  {
    "objectID": "slides/wrangling/15-web-scraping.html#the-rvest-package-3",
    "href": "slides/wrangling/15-web-scraping.html#the-rvest-package-3",
    "title": "Web Scraping",
    "section": "The rvest package",
    "text": "The rvest package\n\nWe don’t show the output here because it includes thousands of characters.\nBut if we look at it, we can see the data we are after are stored in an HTML table: you can see this in this line of the HTML code above &lt;table class=\"wikitable sortable\"&gt;."
  },
  {
    "objectID": "slides/wrangling/15-web-scraping.html#the-rvest-package-4",
    "href": "slides/wrangling/15-web-scraping.html#the-rvest-package-4",
    "title": "Web Scraping",
    "section": "The rvest package",
    "text": "The rvest package\n\nThe different parts of an HTML document, often defined with a message in between &lt; and &gt; are referred to as nodes.\nThe rvest package includes functions to extract nodes of an HTML document: html_nodes extracts all nodes of different types and html_node extracts the first one."
  },
  {
    "objectID": "slides/wrangling/15-web-scraping.html#the-rvest-package-5",
    "href": "slides/wrangling/15-web-scraping.html#the-rvest-package-5",
    "title": "Web Scraping",
    "section": "The rvest package",
    "text": "The rvest package\n\nTo extract the tables from the html code we use:\n\n\ntab &lt;- h |&gt; html_nodes(\"table\") \n\n\nNow, instead of the entire webpage, we just have the html code for the tables in the page:"
  },
  {
    "objectID": "slides/wrangling/15-web-scraping.html#the-rvest-package-6",
    "href": "slides/wrangling/15-web-scraping.html#the-rvest-package-6",
    "title": "Web Scraping",
    "section": "The rvest package",
    "text": "The rvest package\n\ntab \n\n{xml_nodeset (2)}\n[1] &lt;table class=\"wikitable sortable\"&gt;&lt;tbody&gt;\\n&lt;tr&gt;\\n&lt;th&gt;State\\n&lt;/th&gt;\\n&lt;th&gt;\\n ...\n[2] &lt;table class=\"nowraplinks hlist mw-collapsible mw-collapsed navbox-inner\" ...\n\n\n\nThe table we are interested is the first one:\n\n\ntab[[1]] \n\n{html_node}\n&lt;table class=\"wikitable sortable\"&gt;\n[1] &lt;tbody&gt;\\n&lt;tr&gt;\\n&lt;th&gt;State\\n&lt;/th&gt;\\n&lt;th&gt;\\n&lt;a href=\"/wiki/List_of_U.S._states ..."
  },
  {
    "objectID": "slides/wrangling/15-web-scraping.html#the-rvest-package-7",
    "href": "slides/wrangling/15-web-scraping.html#the-rvest-package-7",
    "title": "Web Scraping",
    "section": "The rvest package",
    "text": "The rvest package\n\nThis is clearly not a tidy dataset, not even a data frame.\nIn the code above, you can definitely see a pattern and writing code to extract just the data is very doable.\nIn fact, rvest includes a function just for converting HTML tables into data frames:\n\n\ntab &lt;- tab[[1]] |&gt; html_table() \nclass(tab) \n\n[1] \"tbl_df\"     \"tbl\"        \"data.frame\""
  },
  {
    "objectID": "slides/wrangling/15-web-scraping.html#the-rvest-package-8",
    "href": "slides/wrangling/15-web-scraping.html#the-rvest-package-8",
    "title": "Web Scraping",
    "section": "The rvest package",
    "text": "The rvest package\n\nWe can now make the data frame:\n\n\ntab &lt;- tab |&gt; \n  setNames(c(\"state\", \"population\", \"total\", \"murder_rate\")) |&gt;\n  mutate(across(c(population, total), parse_number))\nhead(tab) \n\n# A tibble: 6 × 4\n  state      population total murder_rate\n  &lt;chr&gt;           &lt;dbl&gt; &lt;dbl&gt;       &lt;dbl&gt;\n1 Alabama       4853875   348         7.2\n2 Alaska         737709    59         8  \n3 Arizona       6817565   309         4.5\n4 Arkansas      2977853   181         6.1\n5 California   38993940  1861         4.8\n6 Colorado      5448819   176         3.2"
  },
  {
    "objectID": "slides/wrangling/15-web-scraping.html#css-selectors",
    "href": "slides/wrangling/15-web-scraping.html#css-selectors",
    "title": "Web Scraping",
    "section": "CSS selectors",
    "text": "CSS selectors\n\nhttps://rvest.tidyverse.org/articles/selectorgadget.html]\nhttps://www.analyticsvidhya.com/blog/2017/03/beginners-guide-on-web-scraping-in-r-using-rvest-with-hands-on-knowledge/"
  },
  {
    "objectID": "slides/wrangling/12-dates-and-times.html#parsing-dates-and-times",
    "href": "slides/wrangling/12-dates-and-times.html#parsing-dates-and-times",
    "title": "Dates And Times",
    "section": "Parsing dates and times",
    "text": "Parsing dates and times\n\nWe have described three main types of vectors: numeric, character, and logical.\nWhen analyzing data, we often encounter variables that are dates.\nAlthough we can represent a date with a string, for example November 2, 2017, once we pick a reference day, referred to as the epoch by computer programmers, they can be converted to numbers by calculating the number of days since the epoch.\nIn R and Unix, the epoch is defined as January 1, 1970."
  },
  {
    "objectID": "slides/wrangling/12-dates-and-times.html#parsing-dates-and-times-1",
    "href": "slides/wrangling/12-dates-and-times.html#parsing-dates-and-times-1",
    "title": "Dates And Times",
    "section": "Parsing dates and times",
    "text": "Parsing dates and times\n\nIf I tell you it’s November 2, 2017, you know what this means immediately.\nIf I tell you it’s day 17,204, you will be quite confused.\nSimilar problems arise with times and even more complications can appear due to time zones.\nFor this reason, R defines a data type just for dates and times."
  },
  {
    "objectID": "slides/wrangling/12-dates-and-times.html#the-date-data-type",
    "href": "slides/wrangling/12-dates-and-times.html#the-date-data-type",
    "title": "Dates And Times",
    "section": "The date data type",
    "text": "The date data type\n\nWe can see an example of the data type R uses for data here:\n\n\nlibrary(tidyverse) \nlibrary(dslabs) \npolls_us_election_2016$startdate |&gt; head() \n\n[1] \"2016-11-03\" \"2016-11-01\" \"2016-11-02\" \"2016-11-04\" \"2016-11-03\"\n[6] \"2016-11-03\"\n\n\n\nThe dates look like strings, but they are not:\n\n\nclass(polls_us_election_2016$startdate) \n\n[1] \"Date\""
  },
  {
    "objectID": "slides/wrangling/12-dates-and-times.html#the-date-data-type-1",
    "href": "slides/wrangling/12-dates-and-times.html#the-date-data-type-1",
    "title": "Dates And Times",
    "section": "The date data type",
    "text": "The date data type\n\nLook at what happens when we convert them to numbers:\n\n\nas.numeric(polls_us_election_2016$startdate) |&gt; head() \n\n[1] 17108 17106 17107 17109 17108 17108\n\n\n\nIt turns them into days since the epoch."
  },
  {
    "objectID": "slides/wrangling/12-dates-and-times.html#the-date-data-type-2",
    "href": "slides/wrangling/12-dates-and-times.html#the-date-data-type-2",
    "title": "Dates And Times",
    "section": "The date data type",
    "text": "The date data type\n\nas.Date converts characters into dates.\nSo to see that the epoch is day 0 we can type.\n\n\nas.Date(\"1970-01-01\") |&gt; as.numeric() \n\n[1] 0\n\n\n\nPlotting functions, such as those in ggplot, are aware of the date format."
  },
  {
    "objectID": "slides/wrangling/12-dates-and-times.html#the-date-data-type-3",
    "href": "slides/wrangling/12-dates-and-times.html#the-date-data-type-3",
    "title": "Dates And Times",
    "section": "The date data type",
    "text": "The date data type\n\nScatterplots use the numeric representation to assign positions, but include the string in the labels:\n\n\npolls_us_election_2016 |&gt; \n  filter(startdate &gt;= make_date(2016, 6, 1)) |&gt;\n  filter(pollster == \"Ipsos\" & state == \"U.S.\") |&gt; \n  ggplot(aes(startdate, rawpoll_clinton)) + \n  geom_line()"
  },
  {
    "objectID": "slides/wrangling/12-dates-and-times.html#the-date-data-type-4",
    "href": "slides/wrangling/12-dates-and-times.html#the-date-data-type-4",
    "title": "Dates And Times",
    "section": "The date data type",
    "text": "The date data type\n\nCodePlot\n\n\nggplot offers convenient functions to change labels:\n\npolls_us_election_2016 |&gt; \n  filter(startdate &gt;= make_date(2016, 6, 1)) |&gt;\n  filter(pollster == \"Ipsos\" & state == \"U.S.\") |&gt; \n  ggplot(aes(startdate, rawpoll_clinton)) + \n  geom_line() +\n  scale_x_date(date_breaks = \"2 weeks\", date_labels = \"%b %d\") + \n  geom_vline(xintercept = as.Date(\"2016-10-28\"), linetype = \"dashed\")"
  },
  {
    "objectID": "slides/wrangling/12-dates-and-times.html#the-lubridate-package",
    "href": "slides/wrangling/12-dates-and-times.html#the-lubridate-package",
    "title": "Dates And Times",
    "section": "The lubridate package",
    "text": "The lubridate package\n\nThe lubridate package provides tools to work with date and times.\n\n\nlibrary(lubridate) \n\n\nWe will take a random sample of dates to show some of the useful things one can do:\n\n\nset.seed(2002) \ndates &lt;- sample(polls_us_election_2016$startdate, 10) |&gt; sort() \ndates \n\n [1] \"2016-05-31\" \"2016-08-08\" \"2016-08-19\" \"2016-09-22\" \"2016-09-27\"\n [6] \"2016-10-12\" \"2016-10-24\" \"2016-10-26\" \"2016-10-29\" \"2016-10-30\""
  },
  {
    "objectID": "slides/wrangling/12-dates-and-times.html#the-lubridate-package-1",
    "href": "slides/wrangling/12-dates-and-times.html#the-lubridate-package-1",
    "title": "Dates And Times",
    "section": "The lubridate package",
    "text": "The lubridate package\n\nThe functions year, month and day extract those values:\n\n\ntibble(date = dates, month = month(dates), day = day(dates), year = year(dates)) \n\n# A tibble: 10 × 4\n   date       month   day  year\n   &lt;date&gt;     &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt;\n 1 2016-05-31     5    31  2016\n 2 2016-08-08     8     8  2016\n 3 2016-08-19     8    19  2016\n 4 2016-09-22     9    22  2016\n 5 2016-09-27     9    27  2016\n 6 2016-10-12    10    12  2016\n 7 2016-10-24    10    24  2016\n 8 2016-10-26    10    26  2016\n 9 2016-10-29    10    29  2016\n10 2016-10-30    10    30  2016"
  },
  {
    "objectID": "slides/wrangling/12-dates-and-times.html#the-lubridate-package-2",
    "href": "slides/wrangling/12-dates-and-times.html#the-lubridate-package-2",
    "title": "Dates And Times",
    "section": "The lubridate package",
    "text": "The lubridate package\n\nWe can also extract the month labels:\n\n\nmonth(dates, label = TRUE) \n\n [1] May Aug Aug Sep Sep Oct Oct Oct Oct Oct\n12 Levels: Jan &lt; Feb &lt; Mar &lt; Apr &lt; May &lt; Jun &lt; Jul &lt; Aug &lt; Sep &lt; ... &lt; Dec"
  },
  {
    "objectID": "slides/wrangling/12-dates-and-times.html#the-lubridate-package-3",
    "href": "slides/wrangling/12-dates-and-times.html#the-lubridate-package-3",
    "title": "Dates And Times",
    "section": "The lubridate package",
    "text": "The lubridate package\n\nAnother useful set of functions are the parsers that convert strings into dates.\nThe function ymd assumes the dates are in the format YYYY-MM-DD and tries to parse as well as possible.\n\n\nx &lt;- c(20090101, \"2009-01-02\", \"2009 01 03\", \"2009-1-4\", \n       \"2009-1, 5\", \"Created on 2009 1 6\", \"200901 !!! 07\") \nymd(x) \n\n[1] \"2009-01-01\" \"2009-01-02\" \"2009-01-03\" \"2009-01-04\" \"2009-01-05\"\n[6] \"2009-01-06\" \"2009-01-07\""
  },
  {
    "objectID": "slides/wrangling/12-dates-and-times.html#the-lubridate-package-4",
    "href": "slides/wrangling/12-dates-and-times.html#the-lubridate-package-4",
    "title": "Dates And Times",
    "section": "The lubridate package",
    "text": "The lubridate package\n\nA further complication comes from the fact that dates often come in different formats in which the order of year, month, and day are different.\nThe preferred format is to show year (with all four digits), month (two digits), and then day, or what is called the ISO 8601.\nSpecifically we use YYYY-MM-DD so that if we order the string, it will be ordered by date.\nYou can see the function ymd returns them in this format."
  },
  {
    "objectID": "slides/wrangling/12-dates-and-times.html#the-lubridate-package-5",
    "href": "slides/wrangling/12-dates-and-times.html#the-lubridate-package-5",
    "title": "Dates And Times",
    "section": "The lubridate package",
    "text": "The lubridate package\n\nBut, what if you encounter dates such as “09/01/02”? This could be September 1, 2002 or January 2, 2009 or January 9, 2002.\nIn these cases, examining the entire vector of dates will help you determine what format it is by process of elimination.\nOnce you know, you can use the many parses provided by lubridate.\nFor example, if the string is:\n\n\nx &lt;- \"09/01/02\""
  },
  {
    "objectID": "slides/wrangling/12-dates-and-times.html#the-lubridate-package-6",
    "href": "slides/wrangling/12-dates-and-times.html#the-lubridate-package-6",
    "title": "Dates And Times",
    "section": "The lubridate package",
    "text": "The lubridate package\n\nThe ymd function assumes the first entry is the year, the second is the month, and the third is the day, so it converts it to:\n\n\nymd(x) \n\n[1] \"2009-01-02\""
  },
  {
    "objectID": "slides/wrangling/12-dates-and-times.html#the-lubridate-package-7",
    "href": "slides/wrangling/12-dates-and-times.html#the-lubridate-package-7",
    "title": "Dates And Times",
    "section": "The lubridate package",
    "text": "The lubridate package\n\nThe mdy function assumes the first entry is the month, then the day, then the year:\n\n\nmdy(x) \n\n[1] \"2002-09-01\""
  },
  {
    "objectID": "slides/wrangling/12-dates-and-times.html#the-lubridate-package-8",
    "href": "slides/wrangling/12-dates-and-times.html#the-lubridate-package-8",
    "title": "Dates And Times",
    "section": "The lubridate package",
    "text": "The lubridate package\n\nThe lubridate package provides a function for every possibility.\nHere is the other common one:\n\n\ndmy(x) \n\n[1] \"2002-01-09\""
  },
  {
    "objectID": "slides/wrangling/12-dates-and-times.html#the-lubridate-package-9",
    "href": "slides/wrangling/12-dates-and-times.html#the-lubridate-package-9",
    "title": "Dates And Times",
    "section": "The lubridate package",
    "text": "The lubridate package\n\nThe lubridate package is also useful for dealing with times.\nIn base R, you can get the current time typing Sys.time().\nThe lubridate package provides a slightly more advanced function, now, that permits you to define the time zone:\n\n\nnow() \n\n[1] \"2024-10-26 16:18:08 EDT\"\n\nnow(\"GMT\") \n\n[1] \"2024-10-26 20:18:08 GMT\""
  },
  {
    "objectID": "slides/wrangling/12-dates-and-times.html#the-lubridate-package-10",
    "href": "slides/wrangling/12-dates-and-times.html#the-lubridate-package-10",
    "title": "Dates And Times",
    "section": "The lubridate package",
    "text": "The lubridate package\n\nYou can see all the available time zones with:\n\n\nOlsonNames()\n\n  [1] \"Africa/Abidjan\"                   \"Africa/Accra\"                    \n  [3] \"Africa/Addis_Ababa\"               \"Africa/Algiers\"                  \n  [5] \"Africa/Asmara\"                    \"Africa/Asmera\"                   \n  [7] \"Africa/Bamako\"                    \"Africa/Bangui\"                   \n  [9] \"Africa/Banjul\"                    \"Africa/Bissau\"                   \n [11] \"Africa/Blantyre\"                  \"Africa/Brazzaville\"              \n [13] \"Africa/Bujumbura\"                 \"Africa/Cairo\"                    \n [15] \"Africa/Casablanca\"                \"Africa/Ceuta\"                    \n [17] \"Africa/Conakry\"                   \"Africa/Dakar\"                    \n [19] \"Africa/Dar_es_Salaam\"             \"Africa/Djibouti\"                 \n [21] \"Africa/Douala\"                    \"Africa/El_Aaiun\"                 \n [23] \"Africa/Freetown\"                  \"Africa/Gaborone\"                 \n [25] \"Africa/Harare\"                    \"Africa/Johannesburg\"             \n [27] \"Africa/Juba\"                      \"Africa/Kampala\"                  \n [29] \"Africa/Khartoum\"                  \"Africa/Kigali\"                   \n [31] \"Africa/Kinshasa\"                  \"Africa/Lagos\"                    \n [33] \"Africa/Libreville\"                \"Africa/Lome\"                     \n [35] \"Africa/Luanda\"                    \"Africa/Lubumbashi\"               \n [37] \"Africa/Lusaka\"                    \"Africa/Malabo\"                   \n [39] \"Africa/Maputo\"                    \"Africa/Maseru\"                   \n [41] \"Africa/Mbabane\"                   \"Africa/Mogadishu\"                \n [43] \"Africa/Monrovia\"                  \"Africa/Nairobi\"                  \n [45] \"Africa/Ndjamena\"                  \"Africa/Niamey\"                   \n [47] \"Africa/Nouakchott\"                \"Africa/Ouagadougou\"              \n [49] \"Africa/Porto-Novo\"                \"Africa/Sao_Tome\"                 \n [51] \"Africa/Timbuktu\"                  \"Africa/Tripoli\"                  \n [53] \"Africa/Tunis\"                     \"Africa/Windhoek\"                 \n [55] \"America/Adak\"                     \"America/Anchorage\"               \n [57] \"America/Anguilla\"                 \"America/Antigua\"                 \n [59] \"America/Araguaina\"                \"America/Argentina/Buenos_Aires\"  \n [61] \"America/Argentina/Catamarca\"      \"America/Argentina/ComodRivadavia\"\n [63] \"America/Argentina/Cordoba\"        \"America/Argentina/Jujuy\"         \n [65] \"America/Argentina/La_Rioja\"       \"America/Argentina/Mendoza\"       \n [67] \"America/Argentina/Rio_Gallegos\"   \"America/Argentina/Salta\"         \n [69] \"America/Argentina/San_Juan\"       \"America/Argentina/San_Luis\"      \n [71] \"America/Argentina/Tucuman\"        \"America/Argentina/Ushuaia\"       \n [73] \"America/Aruba\"                    \"America/Asuncion\"                \n [75] \"America/Atikokan\"                 \"America/Atka\"                    \n [77] \"America/Bahia\"                    \"America/Bahia_Banderas\"          \n [79] \"America/Barbados\"                 \"America/Belem\"                   \n [81] \"America/Belize\"                   \"America/Blanc-Sablon\"            \n [83] \"America/Boa_Vista\"                \"America/Bogota\"                  \n [85] \"America/Boise\"                    \"America/Buenos_Aires\"            \n [87] \"America/Cambridge_Bay\"            \"America/Campo_Grande\"            \n [89] \"America/Cancun\"                   \"America/Caracas\"                 \n [91] \"America/Catamarca\"                \"America/Cayenne\"                 \n [93] \"America/Cayman\"                   \"America/Chicago\"                 \n [95] \"America/Chihuahua\"                \"America/Ciudad_Juarez\"           \n [97] \"America/Coral_Harbour\"            \"America/Cordoba\"                 \n [99] \"America/Costa_Rica\"               \"America/Creston\"                 \n[101] \"America/Cuiaba\"                   \"America/Curacao\"                 \n[103] \"America/Danmarkshavn\"             \"America/Dawson\"                  \n[105] \"America/Dawson_Creek\"             \"America/Denver\"                  \n[107] \"America/Detroit\"                  \"America/Dominica\"                \n[109] \"America/Edmonton\"                 \"America/Eirunepe\"                \n[111] \"America/El_Salvador\"              \"America/Ensenada\"                \n[113] \"America/Fort_Nelson\"              \"America/Fort_Wayne\"              \n[115] \"America/Fortaleza\"                \"America/Glace_Bay\"               \n[117] \"America/Godthab\"                  \"America/Goose_Bay\"               \n[119] \"America/Grand_Turk\"               \"America/Grenada\"                 \n[121] \"America/Guadeloupe\"               \"America/Guatemala\"               \n[123] \"America/Guayaquil\"                \"America/Guyana\"                  \n[125] \"America/Halifax\"                  \"America/Havana\"                  \n[127] \"America/Hermosillo\"               \"America/Indiana/Indianapolis\"    \n[129] \"America/Indiana/Knox\"             \"America/Indiana/Marengo\"         \n[131] \"America/Indiana/Petersburg\"       \"America/Indiana/Tell_City\"       \n[133] \"America/Indiana/Vevay\"            \"America/Indiana/Vincennes\"       \n[135] \"America/Indiana/Winamac\"          \"America/Indianapolis\"            \n[137] \"America/Inuvik\"                   \"America/Iqaluit\"                 \n[139] \"America/Jamaica\"                  \"America/Jujuy\"                   \n[141] \"America/Juneau\"                   \"America/Kentucky/Louisville\"     \n[143] \"America/Kentucky/Monticello\"      \"America/Knox_IN\"                 \n[145] \"America/Kralendijk\"               \"America/La_Paz\"                  \n[147] \"America/Lima\"                     \"America/Los_Angeles\"             \n[149] \"America/Louisville\"               \"America/Lower_Princes\"           \n[151] \"America/Maceio\"                   \"America/Managua\"                 \n[153] \"America/Manaus\"                   \"America/Marigot\"                 \n[155] \"America/Martinique\"               \"America/Matamoros\"               \n[157] \"America/Mazatlan\"                 \"America/Mendoza\"                 \n[159] \"America/Menominee\"                \"America/Merida\"                  \n[161] \"America/Metlakatla\"               \"America/Mexico_City\"             \n[163] \"America/Miquelon\"                 \"America/Moncton\"                 \n[165] \"America/Monterrey\"                \"America/Montevideo\"              \n[167] \"America/Montreal\"                 \"America/Montserrat\"              \n[169] \"America/Nassau\"                   \"America/New_York\"                \n[171] \"America/Nipigon\"                  \"America/Nome\"                    \n[173] \"America/Noronha\"                  \"America/North_Dakota/Beulah\"     \n[175] \"America/North_Dakota/Center\"      \"America/North_Dakota/New_Salem\"  \n[177] \"America/Nuuk\"                     \"America/Ojinaga\"                 \n[179] \"America/Panama\"                   \"America/Pangnirtung\"             \n[181] \"America/Paramaribo\"               \"America/Phoenix\"                 \n[183] \"America/Port_of_Spain\"            \"America/Port-au-Prince\"          \n[185] \"America/Porto_Acre\"               \"America/Porto_Velho\"             \n[187] \"America/Puerto_Rico\"              \"America/Punta_Arenas\"            \n[189] \"America/Rainy_River\"              \"America/Rankin_Inlet\"            \n[191] \"America/Recife\"                   \"America/Regina\"                  \n[193] \"America/Resolute\"                 \"America/Rio_Branco\"              \n[195] \"America/Rosario\"                  \"America/Santa_Isabel\"            \n[197] \"America/Santarem\"                 \"America/Santiago\"                \n[199] \"America/Santo_Domingo\"            \"America/Sao_Paulo\"               \n[201] \"America/Scoresbysund\"             \"America/Shiprock\"                \n[203] \"America/Sitka\"                    \"America/St_Barthelemy\"           \n[205] \"America/St_Johns\"                 \"America/St_Kitts\"                \n[207] \"America/St_Lucia\"                 \"America/St_Thomas\"               \n[209] \"America/St_Vincent\"               \"America/Swift_Current\"           \n[211] \"America/Tegucigalpa\"              \"America/Thule\"                   \n[213] \"America/Thunder_Bay\"              \"America/Tijuana\"                 \n[215] \"America/Toronto\"                  \"America/Tortola\"                 \n[217] \"America/Vancouver\"                \"America/Virgin\"                  \n[219] \"America/Whitehorse\"               \"America/Winnipeg\"                \n[221] \"America/Yakutat\"                  \"America/Yellowknife\"             \n[223] \"Antarctica/Casey\"                 \"Antarctica/Davis\"                \n[225] \"Antarctica/DumontDUrville\"        \"Antarctica/Macquarie\"            \n[227] \"Antarctica/Mawson\"                \"Antarctica/McMurdo\"              \n[229] \"Antarctica/Palmer\"                \"Antarctica/Rothera\"              \n[231] \"Antarctica/South_Pole\"            \"Antarctica/Syowa\"                \n[233] \"Antarctica/Troll\"                 \"Antarctica/Vostok\"               \n[235] \"Arctic/Longyearbyen\"              \"Asia/Aden\"                       \n[237] \"Asia/Almaty\"                      \"Asia/Amman\"                      \n[239] \"Asia/Anadyr\"                      \"Asia/Aqtau\"                      \n[241] \"Asia/Aqtobe\"                      \"Asia/Ashgabat\"                   \n[243] \"Asia/Ashkhabad\"                   \"Asia/Atyrau\"                     \n[245] \"Asia/Baghdad\"                     \"Asia/Bahrain\"                    \n[247] \"Asia/Baku\"                        \"Asia/Bangkok\"                    \n[249] \"Asia/Barnaul\"                     \"Asia/Beirut\"                     \n[251] \"Asia/Bishkek\"                     \"Asia/Brunei\"                     \n[253] \"Asia/Calcutta\"                    \"Asia/Chita\"                      \n[255] \"Asia/Choibalsan\"                  \"Asia/Chongqing\"                  \n[257] \"Asia/Chungking\"                   \"Asia/Colombo\"                    \n[259] \"Asia/Dacca\"                       \"Asia/Damascus\"                   \n[261] \"Asia/Dhaka\"                       \"Asia/Dili\"                       \n[263] \"Asia/Dubai\"                       \"Asia/Dushanbe\"                   \n[265] \"Asia/Famagusta\"                   \"Asia/Gaza\"                       \n[267] \"Asia/Harbin\"                      \"Asia/Hebron\"                     \n[269] \"Asia/Ho_Chi_Minh\"                 \"Asia/Hong_Kong\"                  \n[271] \"Asia/Hovd\"                        \"Asia/Irkutsk\"                    \n[273] \"Asia/Istanbul\"                    \"Asia/Jakarta\"                    \n[275] \"Asia/Jayapura\"                    \"Asia/Jerusalem\"                  \n[277] \"Asia/Kabul\"                       \"Asia/Kamchatka\"                  \n[279] \"Asia/Karachi\"                     \"Asia/Kashgar\"                    \n[281] \"Asia/Kathmandu\"                   \"Asia/Katmandu\"                   \n[283] \"Asia/Khandyga\"                    \"Asia/Kolkata\"                    \n[285] \"Asia/Krasnoyarsk\"                 \"Asia/Kuala_Lumpur\"               \n[287] \"Asia/Kuching\"                     \"Asia/Kuwait\"                     \n[289] \"Asia/Macao\"                       \"Asia/Macau\"                      \n[291] \"Asia/Magadan\"                     \"Asia/Makassar\"                   \n[293] \"Asia/Manila\"                      \"Asia/Muscat\"                     \n[295] \"Asia/Nicosia\"                     \"Asia/Novokuznetsk\"               \n[297] \"Asia/Novosibirsk\"                 \"Asia/Omsk\"                       \n[299] \"Asia/Oral\"                        \"Asia/Phnom_Penh\"                 \n[301] \"Asia/Pontianak\"                   \"Asia/Pyongyang\"                  \n[303] \"Asia/Qatar\"                       \"Asia/Qostanay\"                   \n[305] \"Asia/Qyzylorda\"                   \"Asia/Rangoon\"                    \n[307] \"Asia/Riyadh\"                      \"Asia/Saigon\"                     \n[309] \"Asia/Sakhalin\"                    \"Asia/Samarkand\"                  \n[311] \"Asia/Seoul\"                       \"Asia/Shanghai\"                   \n[313] \"Asia/Singapore\"                   \"Asia/Srednekolymsk\"              \n[315] \"Asia/Taipei\"                      \"Asia/Tashkent\"                   \n[317] \"Asia/Tbilisi\"                     \"Asia/Tehran\"                     \n[319] \"Asia/Tel_Aviv\"                    \"Asia/Thimbu\"                     \n[321] \"Asia/Thimphu\"                     \"Asia/Tokyo\"                      \n[323] \"Asia/Tomsk\"                       \"Asia/Ujung_Pandang\"              \n[325] \"Asia/Ulaanbaatar\"                 \"Asia/Ulan_Bator\"                 \n[327] \"Asia/Urumqi\"                      \"Asia/Ust-Nera\"                   \n[329] \"Asia/Vientiane\"                   \"Asia/Vladivostok\"                \n[331] \"Asia/Yakutsk\"                     \"Asia/Yangon\"                     \n[333] \"Asia/Yekaterinburg\"               \"Asia/Yerevan\"                    \n[335] \"Atlantic/Azores\"                  \"Atlantic/Bermuda\"                \n[337] \"Atlantic/Canary\"                  \"Atlantic/Cape_Verde\"             \n[339] \"Atlantic/Faeroe\"                  \"Atlantic/Faroe\"                  \n[341] \"Atlantic/Jan_Mayen\"               \"Atlantic/Madeira\"                \n[343] \"Atlantic/Reykjavik\"               \"Atlantic/South_Georgia\"          \n[345] \"Atlantic/St_Helena\"               \"Atlantic/Stanley\"                \n[347] \"Australia/ACT\"                    \"Australia/Adelaide\"              \n[349] \"Australia/Brisbane\"               \"Australia/Broken_Hill\"           \n[351] \"Australia/Canberra\"               \"Australia/Currie\"                \n[353] \"Australia/Darwin\"                 \"Australia/Eucla\"                 \n[355] \"Australia/Hobart\"                 \"Australia/LHI\"                   \n[357] \"Australia/Lindeman\"               \"Australia/Lord_Howe\"             \n[359] \"Australia/Melbourne\"              \"Australia/North\"                 \n[361] \"Australia/NSW\"                    \"Australia/Perth\"                 \n[363] \"Australia/Queensland\"             \"Australia/South\"                 \n[365] \"Australia/Sydney\"                 \"Australia/Tasmania\"              \n[367] \"Australia/Victoria\"               \"Australia/West\"                  \n[369] \"Australia/Yancowinna\"             \"Brazil/Acre\"                     \n[371] \"Brazil/DeNoronha\"                 \"Brazil/East\"                     \n[373] \"Brazil/West\"                      \"Canada/Atlantic\"                 \n[375] \"Canada/Central\"                   \"Canada/Eastern\"                  \n[377] \"Canada/Mountain\"                  \"Canada/Newfoundland\"             \n[379] \"Canada/Pacific\"                   \"Canada/Saskatchewan\"             \n[381] \"Canada/Yukon\"                     \"CET\"                             \n[383] \"Chile/Continental\"                \"Chile/EasterIsland\"              \n[385] \"CST6CDT\"                          \"Cuba\"                            \n[387] \"EET\"                              \"Egypt\"                           \n[389] \"Eire\"                             \"EST\"                             \n[391] \"EST5EDT\"                          \"Etc/GMT\"                         \n[393] \"Etc/GMT-0\"                        \"Etc/GMT-1\"                       \n[395] \"Etc/GMT-10\"                       \"Etc/GMT-11\"                      \n[397] \"Etc/GMT-12\"                       \"Etc/GMT-13\"                      \n[399] \"Etc/GMT-14\"                       \"Etc/GMT-2\"                       \n[401] \"Etc/GMT-3\"                        \"Etc/GMT-4\"                       \n[403] \"Etc/GMT-5\"                        \"Etc/GMT-6\"                       \n[405] \"Etc/GMT-7\"                        \"Etc/GMT-8\"                       \n[407] \"Etc/GMT-9\"                        \"Etc/GMT+0\"                       \n[409] \"Etc/GMT+1\"                        \"Etc/GMT+10\"                      \n[411] \"Etc/GMT+11\"                       \"Etc/GMT+12\"                      \n[413] \"Etc/GMT+2\"                        \"Etc/GMT+3\"                       \n[415] \"Etc/GMT+4\"                        \"Etc/GMT+5\"                       \n[417] \"Etc/GMT+6\"                        \"Etc/GMT+7\"                       \n[419] \"Etc/GMT+8\"                        \"Etc/GMT+9\"                       \n[421] \"Etc/GMT0\"                         \"Etc/Greenwich\"                   \n[423] \"Etc/UCT\"                          \"Etc/Universal\"                   \n[425] \"Etc/UTC\"                          \"Etc/Zulu\"                        \n[427] \"Europe/Amsterdam\"                 \"Europe/Andorra\"                  \n[429] \"Europe/Astrakhan\"                 \"Europe/Athens\"                   \n[431] \"Europe/Belfast\"                   \"Europe/Belgrade\"                 \n[433] \"Europe/Berlin\"                    \"Europe/Bratislava\"               \n[435] \"Europe/Brussels\"                  \"Europe/Bucharest\"                \n[437] \"Europe/Budapest\"                  \"Europe/Busingen\"                 \n[439] \"Europe/Chisinau\"                  \"Europe/Copenhagen\"               \n[441] \"Europe/Dublin\"                    \"Europe/Gibraltar\"                \n[443] \"Europe/Guernsey\"                  \"Europe/Helsinki\"                 \n[445] \"Europe/Isle_of_Man\"               \"Europe/Istanbul\"                 \n[447] \"Europe/Jersey\"                    \"Europe/Kaliningrad\"              \n[449] \"Europe/Kiev\"                      \"Europe/Kirov\"                    \n[451] \"Europe/Kyiv\"                      \"Europe/Lisbon\"                   \n[453] \"Europe/Ljubljana\"                 \"Europe/London\"                   \n[455] \"Europe/Luxembourg\"                \"Europe/Madrid\"                   \n[457] \"Europe/Malta\"                     \"Europe/Mariehamn\"                \n[459] \"Europe/Minsk\"                     \"Europe/Monaco\"                   \n[461] \"Europe/Moscow\"                    \"Europe/Nicosia\"                  \n[463] \"Europe/Oslo\"                      \"Europe/Paris\"                    \n[465] \"Europe/Podgorica\"                 \"Europe/Prague\"                   \n[467] \"Europe/Riga\"                      \"Europe/Rome\"                     \n[469] \"Europe/Samara\"                    \"Europe/San_Marino\"               \n[471] \"Europe/Sarajevo\"                  \"Europe/Saratov\"                  \n[473] \"Europe/Simferopol\"                \"Europe/Skopje\"                   \n[475] \"Europe/Sofia\"                     \"Europe/Stockholm\"                \n[477] \"Europe/Tallinn\"                   \"Europe/Tirane\"                   \n[479] \"Europe/Tiraspol\"                  \"Europe/Ulyanovsk\"                \n[481] \"Europe/Uzhgorod\"                  \"Europe/Vaduz\"                    \n[483] \"Europe/Vatican\"                   \"Europe/Vienna\"                   \n[485] \"Europe/Vilnius\"                   \"Europe/Volgograd\"                \n[487] \"Europe/Warsaw\"                    \"Europe/Zagreb\"                   \n[489] \"Europe/Zaporozhye\"                \"Europe/Zurich\"                   \n[491] \"Factory\"                          \"GB\"                              \n[493] \"GB-Eire\"                          \"GMT\"                             \n[495] \"GMT-0\"                            \"GMT+0\"                           \n[497] \"GMT0\"                             \"Greenwich\"                       \n[499] \"Hongkong\"                         \"HST\"                             \n[501] \"Iceland\"                          \"Indian/Antananarivo\"             \n[503] \"Indian/Chagos\"                    \"Indian/Christmas\"                \n[505] \"Indian/Cocos\"                     \"Indian/Comoro\"                   \n[507] \"Indian/Kerguelen\"                 \"Indian/Mahe\"                     \n[509] \"Indian/Maldives\"                  \"Indian/Mauritius\"                \n[511] \"Indian/Mayotte\"                   \"Indian/Reunion\"                  \n[513] \"Iran\"                             \"Israel\"                          \n[515] \"Jamaica\"                          \"Japan\"                           \n[517] \"Kwajalein\"                        \"Libya\"                           \n[519] \"MET\"                              \"Mexico/BajaNorte\"                \n[521] \"Mexico/BajaSur\"                   \"Mexico/General\"                  \n[523] \"MST\"                              \"MST7MDT\"                         \n[525] \"Navajo\"                           \"NZ\"                              \n[527] \"NZ-CHAT\"                          \"Pacific/Apia\"                    \n[529] \"Pacific/Auckland\"                 \"Pacific/Bougainville\"            \n[531] \"Pacific/Chatham\"                  \"Pacific/Chuuk\"                   \n[533] \"Pacific/Easter\"                   \"Pacific/Efate\"                   \n[535] \"Pacific/Enderbury\"                \"Pacific/Fakaofo\"                 \n[537] \"Pacific/Fiji\"                     \"Pacific/Funafuti\"                \n[539] \"Pacific/Galapagos\"                \"Pacific/Gambier\"                 \n[541] \"Pacific/Guadalcanal\"              \"Pacific/Guam\"                    \n[543] \"Pacific/Honolulu\"                 \"Pacific/Johnston\"                \n[545] \"Pacific/Kanton\"                   \"Pacific/Kiritimati\"              \n[547] \"Pacific/Kosrae\"                   \"Pacific/Kwajalein\"               \n[549] \"Pacific/Majuro\"                   \"Pacific/Marquesas\"               \n[551] \"Pacific/Midway\"                   \"Pacific/Nauru\"                   \n[553] \"Pacific/Niue\"                     \"Pacific/Norfolk\"                 \n[555] \"Pacific/Noumea\"                   \"Pacific/Pago_Pago\"               \n[557] \"Pacific/Palau\"                    \"Pacific/Pitcairn\"                \n[559] \"Pacific/Pohnpei\"                  \"Pacific/Ponape\"                  \n[561] \"Pacific/Port_Moresby\"             \"Pacific/Rarotonga\"               \n[563] \"Pacific/Saipan\"                   \"Pacific/Samoa\"                   \n[565] \"Pacific/Tahiti\"                   \"Pacific/Tarawa\"                  \n[567] \"Pacific/Tongatapu\"                \"Pacific/Truk\"                    \n[569] \"Pacific/Wake\"                     \"Pacific/Wallis\"                  \n[571] \"Pacific/Yap\"                      \"Poland\"                          \n[573] \"Portugal\"                         \"PRC\"                             \n[575] \"PST8PDT\"                          \"ROC\"                             \n[577] \"ROK\"                              \"Singapore\"                       \n[579] \"Turkey\"                           \"UCT\"                             \n[581] \"Universal\"                        \"US/Alaska\"                       \n[583] \"US/Aleutian\"                      \"US/Arizona\"                      \n[585] \"US/Central\"                       \"US/East-Indiana\"                 \n[587] \"US/Eastern\"                       \"US/Hawaii\"                       \n[589] \"US/Indiana-Starke\"                \"US/Michigan\"                     \n[591] \"US/Mountain\"                      \"US/Pacific\"                      \n[593] \"US/Samoa\"                         \"UTC\"                             \n[595] \"W-SU\"                             \"WET\"                             \n[597] \"Zulu\"                            \nattr(,\"Version\")\n[1] \"2024a\""
  },
  {
    "objectID": "slides/wrangling/12-dates-and-times.html#the-lubridate-package-11",
    "href": "slides/wrangling/12-dates-and-times.html#the-lubridate-package-11",
    "title": "Dates And Times",
    "section": "The lubridate package",
    "text": "The lubridate package\n\nWe can also extract hours, minutes, and seconds:\n\n\nnow() |&gt; hour() \n\n[1] 16\n\nnow() |&gt; minute() \n\n[1] 18\n\nnow() |&gt; second() \n\n[1] 8.076461"
  },
  {
    "objectID": "slides/wrangling/12-dates-and-times.html#the-lubridate-package-12",
    "href": "slides/wrangling/12-dates-and-times.html#the-lubridate-package-12",
    "title": "Dates And Times",
    "section": "The lubridate package",
    "text": "The lubridate package\n\nThe package also includes a function to parse strings into times as well as parsers for time objects that include dates:\n\n\nx &lt;- c(\"12:34:56\") \nhms(x) \n\n[1] \"12H 34M 56S\"\n\nx &lt;- \"Nov/2/2012 12:34:56\" \nmdy_hms(x) \n\n[1] \"2012-11-02 12:34:56 UTC\""
  },
  {
    "objectID": "slides/wrangling/12-dates-and-times.html#the-lubridate-package-13",
    "href": "slides/wrangling/12-dates-and-times.html#the-lubridate-package-13",
    "title": "Dates And Times",
    "section": "The lubridate package",
    "text": "The lubridate package\n\nThe make_date function can be used to quickly create a date object.\nFor example, to create an date object representing, for example, July 6, 2019 we write:\n\n\nmake_date(2019, 7, 6) \n\n[1] \"2019-07-06\""
  },
  {
    "objectID": "slides/wrangling/12-dates-and-times.html#the-lubridate-package-14",
    "href": "slides/wrangling/12-dates-and-times.html#the-lubridate-package-14",
    "title": "Dates And Times",
    "section": "The lubridate package",
    "text": "The lubridate package\n\nWe can use it to make vectors of dates.\nTo make a vector of January 1 for the 80s we write:\n\n\nmake_date(1980:1989) \n\n [1] \"1980-01-01\" \"1981-01-01\" \"1982-01-01\" \"1983-01-01\" \"1984-01-01\"\n [6] \"1985-01-01\" \"1986-01-01\" \"1987-01-01\" \"1988-01-01\" \"1989-01-01\""
  },
  {
    "objectID": "slides/wrangling/12-dates-and-times.html#the-lubridate-package-15",
    "href": "slides/wrangling/12-dates-and-times.html#the-lubridate-package-15",
    "title": "Dates And Times",
    "section": "The lubridate package",
    "text": "The lubridate package\n\nAnother very useful function is round_date.\nIt can be used to round dates to nearest year, quarter, month, week, day, hour, minutes, or seconds."
  },
  {
    "objectID": "slides/wrangling/12-dates-and-times.html#the-lubridate-package-16",
    "href": "slides/wrangling/12-dates-and-times.html#the-lubridate-package-16",
    "title": "Dates And Times",
    "section": "The lubridate package",
    "text": "The lubridate package\n\nCodePlot\n\n\n\nExample: if we want to group all the polls by week of the year we can do the following:\n\n\npolls_us_election_2016 |&gt;  \n  mutate(week = round_date(startdate, \"week\")) |&gt; \n  group_by(week) |&gt; \n  summarize(margin = mean(rawpoll_clinton - rawpoll_trump)) |&gt; \n  ggplot(aes(week, margin)) + \n  geom_point()"
  },
  {
    "objectID": "slides/wrangling/12-dates-and-times.html#final-pointers",
    "href": "slides/wrangling/12-dates-and-times.html#final-pointers",
    "title": "Dates And Times",
    "section": "Final pointers",
    "text": "Final pointers\n\nYou should be aware the there are useful function for computing operations on time such a difftime, time_length, and interval.\nWe don’t cover it here but be aware that The data.table package includes some of the same functionality as lubridate."
  },
  {
    "objectID": "slides/wrangling/13-locales.html#locales",
    "href": "slides/wrangling/13-locales.html#locales",
    "title": "Locales",
    "section": "Locales",
    "text": "Locales\n\nComputer settings change depending on language and location, and being unaware of this possibility can make certain data wrangling challenges difficult to overcome."
  },
  {
    "objectID": "slides/wrangling/13-locales.html#locales-1",
    "href": "slides/wrangling/13-locales.html#locales-1",
    "title": "Locales",
    "section": "Locales",
    "text": "Locales\n\nThe purpose of locales is to group together common settings that can affect:\n\nMonth and day names, which are necessary for interpreting dates.\nThe standard date format.\nThe default time zone.\nCharacter encoding, vital for reading non-ASCII characters.\nThe symbols for decimals and number groupings, important for interpreting numerical values."
  },
  {
    "objectID": "slides/wrangling/13-locales.html#locales-2",
    "href": "slides/wrangling/13-locales.html#locales-2",
    "title": "Locales",
    "section": "Locales",
    "text": "Locales\n\nIn R, a locale refers to a suite of settings that dictate how the system should behave with respect to cultural conventions.\nThese affect the way data is formatted and presented, including date formatting, currency symbols, decimal separators, and other related aspects.\nLocales in R affect several areas, including how character vectors are sorted.\nAdditionally, errors, warnings, and other messages might be translated into languages other than English based on the locale."
  },
  {
    "objectID": "slides/wrangling/13-locales.html#locales-in-r",
    "href": "slides/wrangling/13-locales.html#locales-in-r",
    "title": "Locales",
    "section": "Locales in R",
    "text": "Locales in R\n\nTo access the current locale settings in R, you can use the Sys.getlocale() function:\n\n\nSys.getlocale() \n\n[1] \"en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\""
  },
  {
    "objectID": "slides/wrangling/13-locales.html#locales-in-r-1",
    "href": "slides/wrangling/13-locales.html#locales-in-r-1",
    "title": "Locales",
    "section": "Locales in R",
    "text": "Locales in R\n\nTo set a specific locale, use the Sys.setlocale() function.\nFor example, to set the locale to US English:\n\n\nSys.setlocale(\"LC_ALL\", \"en_US.UTF-8\") \n\n[1] \"en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\"\n\n\n\nThe exact string to use for setting the locale (like “en_US.UTF-8”) can depend on your operating system and its configuration."
  },
  {
    "objectID": "slides/wrangling/13-locales.html#locales-in-r-2",
    "href": "slides/wrangling/13-locales.html#locales-in-r-2",
    "title": "Locales",
    "section": "Locales in R",
    "text": "Locales in R\n\nLC_ALL refers to all locale categories.\nR breaks down the locale into categories:\n\nLC_COLLATE: for string collation.\nLC_TIME: date and time formatting.\nLC_MONETARY: currency formatting.\nLC_MESSAGES: system message translations.\nLC_NUMERIC: number formatting.\n\nYou can set the locale for each category individually if you don’t want to use LC_ALL."
  },
  {
    "objectID": "slides/wrangling/13-locales.html#locales-in-r-3",
    "href": "slides/wrangling/13-locales.html#locales-in-r-3",
    "title": "Locales",
    "section": "Locales in R",
    "text": "Locales in R\n\n\n\n\n\n\nWarning\n\n\n\nWe have shown tools to control locales.\nThese settings are important because they affect how your data looks and behaves.\nHowever, not all of these settings are available on every computer; their availability depends on what kind of computer you have and how it’s set up.\nChanging these settings, especially LC_NUMERIC, can lead to unexpected problems when you’re working with numbers in R.\nThese locale settings only last as long as one R session."
  },
  {
    "objectID": "slides/wrangling/13-locales.html#the-locale-function",
    "href": "slides/wrangling/13-locales.html#the-locale-function",
    "title": "Locales",
    "section": "The locale function",
    "text": "The locale function\n\nThe readr package includes a locale() function that can be used to learn or change the current locale from within R:\n\n\nlibrary(readr) \nlocale() \n\n&lt;locale&gt;\nNumbers:  123,456.78\nFormats:  %AD / %AT\nTimezone: UTC\nEncoding: UTF-8\n&lt;date_names&gt;\nDays:   Sunday (Sun), Monday (Mon), Tuesday (Tue), Wednesday (Wed), Thursday\n        (Thu), Friday (Fri), Saturday (Sat)\nMonths: January (Jan), February (Feb), March (Mar), April (Apr), May (May),\n        June (Jun), July (Jul), August (Aug), September (Sep), October\n        (Oct), November (Nov), December (Dec)\nAM/PM:  AM/PM"
  },
  {
    "objectID": "slides/wrangling/13-locales.html#the-locale-function-1",
    "href": "slides/wrangling/13-locales.html#the-locale-function-1",
    "title": "Locales",
    "section": "The locale function",
    "text": "The locale function\n\nYou can see all the locales available on your system by typing:\n\n\nsystem(\"locale -a\")"
  },
  {
    "objectID": "slides/wrangling/13-locales.html#the-locale-function-2",
    "href": "slides/wrangling/13-locales.html#the-locale-function-2",
    "title": "Locales",
    "section": "The locale function",
    "text": "The locale function\n\nHere is what you obtain if you change the dates locale to Spanish:\n\n\nlocale(date_names = \"es\") \n\n&lt;locale&gt;\nNumbers:  123,456.78\nFormats:  %AD / %AT\nTimezone: UTC\nEncoding: UTF-8\n&lt;date_names&gt;\nDays:   domingo (dom.), lunes (lun.), martes (mar.), miércoles (mié.), jueves\n        (jue.), viernes (vie.), sábado (sáb.)\nMonths: enero (ene.), febrero (feb.), marzo (mar.), abril (abr.), mayo (may.),\n        junio (jun.), julio (jul.), agosto (ago.), septiembre (sept.),\n        octubre (oct.), noviembre (nov.), diciembre (dic.)\nAM/PM:  a. m./p. m."
  },
  {
    "objectID": "slides/wrangling/13-locales.html#example",
    "href": "slides/wrangling/13-locales.html#example",
    "title": "Locales",
    "section": "Example",
    "text": "Example\n\nEarlier we noted that reading the file:\n\n\nfn &lt;- file.path(system.file(\"extdata\", package = \"dslabs\"), \"calificaciones.csv\") \n\n\nhad a encoding different than UTF-8, the default."
  },
  {
    "objectID": "slides/wrangling/13-locales.html#example-1",
    "href": "slides/wrangling/13-locales.html#example-1",
    "title": "Locales",
    "section": "Example",
    "text": "Example\n\nWe used guess_encoding to determine the correct one:\n\n\nguess_encoding(fn)$encoding[1] \n\n[1] \"ISO-8859-1\"\n\n\n\nand used the locale function to change this and read in this encoding instead:\n\n\ndat &lt;- read_csv(fn, locale = locale(encoding = \"ISO-8859-1\"))"
  },
  {
    "objectID": "slides/wrangling/13-locales.html#example-2",
    "href": "slides/wrangling/13-locales.html#example-2",
    "title": "Locales",
    "section": "Example",
    "text": "Example\n\nThis file provides homework assignment scores for seven students. Columns represent the name, date of birth, the time they submitted their assignment, and their score:\n\n\nread_lines(fn, locale = locale(encoding = \"ISO-8859-1\")) \n\n[1] \"\\\"nombre\\\",\\\"f.n.\\\",\\\"estampa\\\",\\\"puntuación\\\"\"                       \n[2] \"\\\"Beyoncé\\\",\\\"04 de septiembre de 1981\\\",2023-09-22 02:11:02,\\\"87,5\\\"\"\n[3] \"\\\"Blümchen\\\",\\\"20 de abril de 1980\\\",2023-09-22 03:23:05,\\\"99,0\\\"\"    \n[4] \"\\\"João\\\",\\\"10 de junio de 1931\\\",2023-09-21 22:43:28,\\\"98,9\\\"\"        \n[5] \"\\\"López\\\",\\\"24 de julio de 1969\\\",2023-09-22 01:06:59,\\\"88,7\\\"\"       \n[6] \"\\\"Ñengo\\\",\\\"15 de diciembre de 1981\\\",2023-09-21 23:35:37,\\\"93,1\\\"\"   \n[7] \"\\\"Plácido\\\",\\\"24 de enero de 1941\\\",2023-09-21 23:17:21,\\\"88,7\\\"\"     \n[8] \"\\\"Thalía\\\",\\\"26 de agosto de 1971\\\",2023-09-21 23:08:02,\\\"83,0\\\"\""
  },
  {
    "objectID": "slides/wrangling/13-locales.html#example-3",
    "href": "slides/wrangling/13-locales.html#example-3",
    "title": "Locales",
    "section": "Example",
    "text": "Example\n\nAs an illustrative example, we will write code to compute the students age and check if they turned in their assignment by the deadline of September 21, 2023, before midnight.\nWe can read in the file with correct encoding like this:\n\n\ndat &lt;- read_csv(fn, locale = locale(encoding = \"ISO-8859-1\"))"
  },
  {
    "objectID": "slides/wrangling/13-locales.html#example-4",
    "href": "slides/wrangling/13-locales.html#example-4",
    "title": "Locales",
    "section": "Example",
    "text": "Example\n\nHowever, notice that the last column, which is supposed to contain exam scores between 0 and 100, shows numbers larger than 800:\n\n\ndat$puntuación \n\n[1] 875 990 989 887 931 887 830"
  },
  {
    "objectID": "slides/wrangling/13-locales.html#example-5",
    "href": "slides/wrangling/13-locales.html#example-5",
    "title": "Locales",
    "section": "Example",
    "text": "Example\n\nThis happens because the scores in the file use the European decimal point, which confuses read_csv.\nTo address this issue, we can also change the encoding to use European decimals, which fixes the problem:\n\n\ndat &lt;- read_csv(fn, locale = locale(decimal_mark = \",\", \n                                    encoding = \"ISO-8859-1\")) \ndat$puntuación \n\n[1] 87.5 99.0 98.9 88.7 93.1 88.7 83.0"
  },
  {
    "objectID": "slides/wrangling/13-locales.html#example-6",
    "href": "slides/wrangling/13-locales.html#example-6",
    "title": "Locales",
    "section": "Example",
    "text": "Example\n\nNow, to compute the student ages, let’s try changing the submission times to date format:\n\n\nlibrary(lubridate) \ndmy(dat$f.n.) \n\n[1] NA NA NA NA NA NA NA\n\n\n\nNothing gets converted correctly.\nThis is because the dates are in Spanish."
  },
  {
    "objectID": "slides/wrangling/13-locales.html#example-7",
    "href": "slides/wrangling/13-locales.html#example-7",
    "title": "Locales",
    "section": "Example",
    "text": "Example\nWe can change the locale to use Spanish as the language for dates:\n\nparse_date(dat$f.n., format = \"%d de %B de %Y\", locale = locale(date_names = \"es\")) \n\n[1] \"1981-09-04\" \"1980-04-20\" \"1931-06-10\" \"1969-07-24\" \"1981-12-15\"\n[6] \"1941-01-24\" \"1971-08-26\""
  },
  {
    "objectID": "slides/wrangling/13-locales.html#example-8",
    "href": "slides/wrangling/13-locales.html#example-8",
    "title": "Locales",
    "section": "Example",
    "text": "Example\nWe can also reread the file using the correct locales:\n\ndat &lt;- read_csv(fn, locale = locale(date_names = \"es\", \n                                    date_format = \"%d de %B de %Y\", \n                                    decimal_mark = \",\", \n                                    encoding = \"ISO-8859-1\"))"
  },
  {
    "objectID": "slides/wrangling/13-locales.html#example-9",
    "href": "slides/wrangling/13-locales.html#example-9",
    "title": "Locales",
    "section": "Example",
    "text": "Example\nComputing the students’ ages is now straightforward:\n\ntime_length(today() - dat$f.n., unit = \"years\") |&gt; floor() \n\n[1] 43 44 93 55 42 83 53"
  },
  {
    "objectID": "slides/wrangling/13-locales.html#example-10",
    "href": "slides/wrangling/13-locales.html#example-10",
    "title": "Locales",
    "section": "Example",
    "text": "Example\n\nLet’s check which students turned in their homework past the deadline of September 22:\n\n\ndat$estampa &gt;= make_date(2023, 9, 22) \n\n[1]  TRUE  TRUE FALSE  TRUE FALSE FALSE FALSE\n\n\n\nWe see that two students where late.\nHowever, with times we have to be particularly careful as some functions default to the UTC timezone:\n\n\ntz(dat$estampa) \n\n[1] \"UTC\""
  },
  {
    "objectID": "slides/wrangling/13-locales.html#example-11",
    "href": "slides/wrangling/13-locales.html#example-11",
    "title": "Locales",
    "section": "Example",
    "text": "Example\n\nIf we change to the timezone to Eastern Standard Time (EST), we see no one was late:\n\n\nwith_tz(dat$estampa, tz =  \"EST\") &gt;= make_date(2023, 9, 22) \n\n[1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE"
  },
  {
    "objectID": "slides/wrangling/16-joining-tables.html#joining-tables",
    "href": "slides/wrangling/16-joining-tables.html#joining-tables",
    "title": "Joining Tables",
    "section": "Joining tables",
    "text": "Joining tables\n\nThe information we need for a given analysis may not be just in one table.\nHere we use a simple examples to illustrate the general challenge of combining tables."
  },
  {
    "objectID": "slides/wrangling/16-joining-tables.html#joining-tables-1",
    "href": "slides/wrangling/16-joining-tables.html#joining-tables-1",
    "title": "Joining Tables",
    "section": "Joining tables",
    "text": "Joining tables\n\nSuppose we want to explore the relationship between population size for US states and electoral votes.\nWe have the population size in this table:\n\n\nlibrary(tidyverse) \nlibrary(dslabs) \nhead(murders) \n\n       state abb region population total\n1    Alabama  AL  South    4779736   135\n2     Alaska  AK   West     710231    19\n3    Arizona  AZ   West    6392017   232\n4   Arkansas  AR  South    2915918    93\n5 California  CA   West   37253956  1257\n6   Colorado  CO   West    5029196    65"
  },
  {
    "objectID": "slides/wrangling/16-joining-tables.html#joining-tables-2",
    "href": "slides/wrangling/16-joining-tables.html#joining-tables-2",
    "title": "Joining Tables",
    "section": "Joining tables",
    "text": "Joining tables\n\nand electoral votes in this one:\n\n\nhead(results_us_election_2016) \n\n         state electoral_votes clinton trump others\n1   California              55    61.7  31.6    6.7\n2        Texas              38    43.2  52.2    4.5\n3      Florida              29    47.8  49.0    3.2\n4     New York              29    59.0  36.5    4.5\n5     Illinois              20    55.8  38.8    5.4\n6 Pennsylvania              20    47.9  48.6    3.6"
  },
  {
    "objectID": "slides/wrangling/16-joining-tables.html#joining-tables-3",
    "href": "slides/wrangling/16-joining-tables.html#joining-tables-3",
    "title": "Joining Tables",
    "section": "Joining tables",
    "text": "Joining tables\n\nJust concatenating these two tables together will not work since the order of the states is not the same.\n\n\nidentical(results_us_election_2016$state, murders$state) \n\n[1] FALSE"
  },
  {
    "objectID": "slides/wrangling/16-joining-tables.html#joins",
    "href": "slides/wrangling/16-joining-tables.html#joins",
    "title": "Joining Tables",
    "section": "Joins",
    "text": "Joins\n\nThe join functions are designed to handle this challenge.\nThe join functions in the dplyr package make sure that the tables are combined so that matching rows are together.\nThe general idea is that one needs to identify one or more columns that will serve to match the two tables.\nA new table with the combined information is returned."
  },
  {
    "objectID": "slides/wrangling/16-joining-tables.html#joins-1",
    "href": "slides/wrangling/16-joining-tables.html#joins-1",
    "title": "Joining Tables",
    "section": "Joins",
    "text": "Joins\n\nNotice what happens if we join the two tables above by state using left_join:\n\n\ntab &lt;- left_join(murders, results_us_election_2016, by = \"state\") |&gt; \n  select(-others) |&gt; rename(ev = electoral_votes) \nhead(tab) \n\n       state abb region population total ev clinton trump\n1    Alabama  AL  South    4779736   135  9    34.4  62.1\n2     Alaska  AK   West     710231    19  3    36.6  51.3\n3    Arizona  AZ   West    6392017   232 11    45.1  48.7\n4   Arkansas  AR  South    2915918    93  6    33.7  60.6\n5 California  CA   West   37253956  1257 55    61.7  31.6\n6   Colorado  CO   West    5029196    65  9    48.2  43.3"
  },
  {
    "objectID": "slides/wrangling/16-joining-tables.html#joins-2",
    "href": "slides/wrangling/16-joining-tables.html#joins-2",
    "title": "Joining Tables",
    "section": "Joins",
    "text": "Joins\n\nThe data has been successfully joined and we can now, for example, make a plot to explore the relationship:"
  },
  {
    "objectID": "slides/wrangling/16-joining-tables.html#joins-3",
    "href": "slides/wrangling/16-joining-tables.html#joins-3",
    "title": "Joining Tables",
    "section": "Joins",
    "text": "Joins\n\nWe see the relationship is close to linear with about 2 electoral votes for every million persons, but with very small states getting higher ratios.\nIn practice, it is not always the case that each row in one table has a matching row in the other.\nFor this reason, we have several versions of join.\nTo illustrate this challenge, we will take subsets of the tables above."
  },
  {
    "objectID": "slides/wrangling/16-joining-tables.html#joins-4",
    "href": "slides/wrangling/16-joining-tables.html#joins-4",
    "title": "Joining Tables",
    "section": "Joins",
    "text": "Joins\n.\nNote: These names are based on SQL."
  },
  {
    "objectID": "slides/wrangling/16-joining-tables.html#joins-5",
    "href": "slides/wrangling/16-joining-tables.html#joins-5",
    "title": "Joining Tables",
    "section": "Joins",
    "text": "Joins\n\nWe create the tables tab1 and tab2 so that they have some states in common but not all:\n\n\ntab_1 &lt;- slice(murders, 1:6) |&gt; select(state, population) \ntab_2 &lt;- results_us_election_2016 |&gt;  \n  filter(state %in% c(\"Alabama\", \"Alaska\", \"Arizona\",  \n                    \"California\", \"Connecticut\", \"Delaware\")) |&gt;  \n  select(state, electoral_votes) |&gt; rename(ev = electoral_votes) \n\n\nWe will use these two tables as examples in the next sections."
  },
  {
    "objectID": "slides/wrangling/16-joining-tables.html#left-join",
    "href": "slides/wrangling/16-joining-tables.html#left-join",
    "title": "Joining Tables",
    "section": "Left join",
    "text": "Left join\n\nSuppose we want a table like tab_1, but adding electoral votes to whatever states we have available.\nFor this, we use left_join with tab_1 as the first argument.\nWe specify which column to use to match with the by argument.\n\n\nleft_join(tab_1, tab_2, by = \"state\") \n\n       state population ev\n1    Alabama    4779736  9\n2     Alaska     710231  3\n3    Arizona    6392017 11\n4   Arkansas    2915918 NA\n5 California   37253956 55\n6   Colorado    5029196 NA\n\n\n\nNote that NAs are added to the two states not appearing in tab_2."
  },
  {
    "objectID": "slides/wrangling/16-joining-tables.html#left-join-1",
    "href": "slides/wrangling/16-joining-tables.html#left-join-1",
    "title": "Joining Tables",
    "section": "Left join",
    "text": "Left join\n\nAlso, notice that this function, as well as all the other joins, can receive the first arguments through the pipe:\n\n\ntab_1 |&gt; left_join(tab_2, by = \"state\")"
  },
  {
    "objectID": "slides/wrangling/16-joining-tables.html#right-join",
    "href": "slides/wrangling/16-joining-tables.html#right-join",
    "title": "Joining Tables",
    "section": "Right join",
    "text": "Right join\n\nIf instead of a table with the same rows as first table, we want one with the same rows as second table, we can use right_join:\n\n\ntab_1 |&gt; right_join(tab_2, by = \"state\") \n\n        state population ev\n1     Alabama    4779736  9\n2      Alaska     710231  3\n3     Arizona    6392017 11\n4  California   37253956 55\n5 Connecticut         NA  7\n6    Delaware         NA  3\n\n\n\nNow the NAs are in the column coming from tab_1."
  },
  {
    "objectID": "slides/wrangling/16-joining-tables.html#inner-join",
    "href": "slides/wrangling/16-joining-tables.html#inner-join",
    "title": "Joining Tables",
    "section": "Inner join",
    "text": "Inner join\n\nIf we want to keep only the rows that have information in both tables, we use inner_join.\nYou can think of this as an intersection:\n\n\ninner_join(tab_1, tab_2, by = \"state\") \n\n       state population ev\n1    Alabama    4779736  9\n2     Alaska     710231  3\n3    Arizona    6392017 11\n4 California   37253956 55"
  },
  {
    "objectID": "slides/wrangling/16-joining-tables.html#full-join",
    "href": "slides/wrangling/16-joining-tables.html#full-join",
    "title": "Joining Tables",
    "section": "Full join",
    "text": "Full join\n\nIf we want to keep all the rows and fill the missing parts with NAs, we can use full_join.\nYou can think of this as a union:\n\n\nfull_join(tab_1, tab_2, by = \"state\") \n\n        state population ev\n1     Alabama    4779736  9\n2      Alaska     710231  3\n3     Arizona    6392017 11\n4    Arkansas    2915918 NA\n5  California   37253956 55\n6    Colorado    5029196 NA\n7 Connecticut         NA  7\n8    Delaware         NA  3"
  },
  {
    "objectID": "slides/wrangling/16-joining-tables.html#semi-join",
    "href": "slides/wrangling/16-joining-tables.html#semi-join",
    "title": "Joining Tables",
    "section": "Semi join",
    "text": "Semi join\n\nThe semi_join function lets us keep the part of first table for which we have information in the second.\nIt does not add the columns of the second:\n\n\nsemi_join(tab_1, tab_2, by = \"state\") \n\n       state population\n1    Alabama    4779736\n2     Alaska     710231\n3    Arizona    6392017\n4 California   37253956"
  },
  {
    "objectID": "slides/wrangling/16-joining-tables.html#anti-join",
    "href": "slides/wrangling/16-joining-tables.html#anti-join",
    "title": "Joining Tables",
    "section": "Anti join",
    "text": "Anti join\n\nThe function anti_join is the opposite of semi_join.\nIt keeps the elements of the first table for which there is no information in the second:\n\n\nanti_join(tab_1, tab_2, by = \"state\") \n\n     state population\n1 Arkansas    2915918\n2 Colorado    5029196"
  },
  {
    "objectID": "slides/wrangling/16-joining-tables.html#binding",
    "href": "slides/wrangling/16-joining-tables.html#binding",
    "title": "Joining Tables",
    "section": "Binding",
    "text": "Binding\n\nAlthough we have yet to use it in this book, another common way in which datasets are combined is by binding them.\nUnlike the join function, the binding functions do not try to match by a variable, but instead simply combine datasets.\nIf the datasets don’t match by the appropriate dimensions, one obtains an error."
  },
  {
    "objectID": "slides/wrangling/16-joining-tables.html#binding-columns",
    "href": "slides/wrangling/16-joining-tables.html#binding-columns",
    "title": "Joining Tables",
    "section": "Binding columns",
    "text": "Binding columns\n\nThe dplyr function bind_cols binds two objects by making them columns in a tibble.\n\n\nbind_cols(a = 1:3, b = 4:6) \n\n# A tibble: 3 × 2\n      a     b\n  &lt;int&gt; &lt;int&gt;\n1     1     4\n2     2     5\n3     3     6\n\n\n\nThis function requires that we assign names to the columns. Here we chose a and b.\nNote that there is an R-base function cbind with the exact same functionality."
  },
  {
    "objectID": "slides/wrangling/16-joining-tables.html#binding-columns-1",
    "href": "slides/wrangling/16-joining-tables.html#binding-columns-1",
    "title": "Joining Tables",
    "section": "Binding columns",
    "text": "Binding columns\n\nAn important difference is that cbind can create different types of objects, while bind_cols always produces a data frame.\nbind_cols can also bind two different data frames."
  },
  {
    "objectID": "slides/wrangling/16-joining-tables.html#binding-columns-2",
    "href": "slides/wrangling/16-joining-tables.html#binding-columns-2",
    "title": "Joining Tables",
    "section": "Binding columns",
    "text": "Binding columns\n\nFor example, here we break up the tab data frame and then bind them back together:\n\n\ntab_1 &lt;- tab[, 1:3] \ntab_2 &lt;- tab[, 4:6] \ntab_3 &lt;- tab[, 7:8] \nnew_tab &lt;- bind_cols(tab_1, tab_2, tab_3) \nhead(new_tab) \n\n       state abb region population total ev clinton trump\n1    Alabama  AL  South    4779736   135  9    34.4  62.1\n2     Alaska  AK   West     710231    19  3    36.6  51.3\n3    Arizona  AZ   West    6392017   232 11    45.1  48.7\n4   Arkansas  AR  South    2915918    93  6    33.7  60.6\n5 California  CA   West   37253956  1257 55    61.7  31.6\n6   Colorado  CO   West    5029196    65  9    48.2  43.3"
  },
  {
    "objectID": "slides/wrangling/16-joining-tables.html#binding-by-rows",
    "href": "slides/wrangling/16-joining-tables.html#binding-by-rows",
    "title": "Joining Tables",
    "section": "Binding by rows",
    "text": "Binding by rows\n\nThe bind_rows function is similar to bind_cols, but binds rows instead of columns:\n\n\ntab_1 &lt;- tab[1:2,] \ntab_2 &lt;- tab[3:4,] \nbind_rows(tab_1, tab_2) \n\n     state abb region population total ev clinton trump\n1  Alabama  AL  South    4779736   135  9    34.4  62.1\n2   Alaska  AK   West     710231    19  3    36.6  51.3\n3  Arizona  AZ   West    6392017   232 11    45.1  48.7\n4 Arkansas  AR  South    2915918    93  6    33.7  60.6\n\n\n\nThis is based on an R-base function rbind."
  },
  {
    "objectID": "slides/wrangling/16-joining-tables.html#set-operators",
    "href": "slides/wrangling/16-joining-tables.html#set-operators",
    "title": "Joining Tables",
    "section": "Set operators",
    "text": "Set operators\n\nAnother set of commands useful for combining datasets are the set operators.\nWhen applied to vectors, these behave as their names suggest.\nExamples are intersect, union, setdiff, and setequal.\nHowever, if the tidyverse, or more specifically dplyr, is loaded, these functions can be used on data frames as opposed to just on vectors."
  },
  {
    "objectID": "slides/wrangling/16-joining-tables.html#intersect",
    "href": "slides/wrangling/16-joining-tables.html#intersect",
    "title": "Joining Tables",
    "section": "Intersect",
    "text": "Intersect\n\nYou can take intersections of vectors of any type, such as numeric:\n\n\nintersect(1:10, 6:15) \n\n[1]  6  7  8  9 10\n\n\n\nor characters:\n\n\nintersect(c(\"a\",\"b\",\"c\"), c(\"b\",\"c\",\"d\")) \n\n[1] \"b\" \"c\"\n\n\n\ndplyr includes an intersect function that can be applied to tables with the same column names.\nThis function returns the rows in common between two tables."
  },
  {
    "objectID": "slides/wrangling/16-joining-tables.html#intersect-1",
    "href": "slides/wrangling/16-joining-tables.html#intersect-1",
    "title": "Joining Tables",
    "section": "Intersect",
    "text": "Intersect\n\nTo make sure we use the dplyr version of intersect rather than the base R version, we can use dplyr::intersect like this:\n\n\ntab_1 &lt;- tab[1:5,] \ntab_2 &lt;- tab[3:7,] \ndplyr::intersect(tab_1, tab_2) \n\n       state abb region population total ev clinton trump\n1    Arizona  AZ   West    6392017   232 11    45.1  48.7\n2   Arkansas  AR  South    2915918    93  6    33.7  60.6\n3 California  CA   West   37253956  1257 55    61.7  31.6"
  },
  {
    "objectID": "slides/wrangling/16-joining-tables.html#union",
    "href": "slides/wrangling/16-joining-tables.html#union",
    "title": "Joining Tables",
    "section": "Union",
    "text": "Union\n\nSimilarly union takes the union of vectors.\nFor example:\n\n\nunion(1:10, 6:15) \n\n [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15\n\nunion(c(\"a\",\"b\",\"c\"), c(\"b\",\"c\",\"d\")) \n\n[1] \"a\" \"b\" \"c\" \"d\""
  },
  {
    "objectID": "slides/wrangling/16-joining-tables.html#union-1",
    "href": "slides/wrangling/16-joining-tables.html#union-1",
    "title": "Joining Tables",
    "section": "Union",
    "text": "Union\n\ndplyr includes a version of union that combines all the rows of two tables with the same column names.\n\n\ntab_1 &lt;- tab[1:5,] \ntab_2 &lt;- tab[3:7,] \ndplyr::union(tab_1, tab_2)  \n\n        state abb    region population total ev clinton trump\n1     Alabama  AL     South    4779736   135  9    34.4  62.1\n2      Alaska  AK      West     710231    19  3    36.6  51.3\n3     Arizona  AZ      West    6392017   232 11    45.1  48.7\n4    Arkansas  AR     South    2915918    93  6    33.7  60.6\n5  California  CA      West   37253956  1257 55    61.7  31.6\n6    Colorado  CO      West    5029196    65  9    48.2  43.3\n7 Connecticut  CT Northeast    3574097    97  7    54.6  40.9"
  },
  {
    "objectID": "slides/wrangling/16-joining-tables.html#setdiff",
    "href": "slides/wrangling/16-joining-tables.html#setdiff",
    "title": "Joining Tables",
    "section": "setdiff",
    "text": "setdiff\n\nThe set difference between a first and second argument can be obtained with setdiff.\nUnlike intersect and union, this function is not symmetric:\n\n\nsetdiff(1:10, 6:15) \n\n[1] 1 2 3 4 5\n\nsetdiff(6:15, 1:10) \n\n[1] 11 12 13 14 15"
  },
  {
    "objectID": "slides/wrangling/16-joining-tables.html#setdiff-1",
    "href": "slides/wrangling/16-joining-tables.html#setdiff-1",
    "title": "Joining Tables",
    "section": "setdiff",
    "text": "setdiff\n\nAs with the functions shown above, dplyr has a version for data frames:\n\n\ntab_1 &lt;- tab[1:5,] \ntab_2 &lt;- tab[3:7,] \ndplyr::setdiff(tab_1, tab_2) \n\n    state abb region population total ev clinton trump\n1 Alabama  AL  South    4779736   135  9    34.4  62.1\n2  Alaska  AK   West     710231    19  3    36.6  51.3"
  },
  {
    "objectID": "slides/wrangling/16-joining-tables.html#setequal",
    "href": "slides/wrangling/16-joining-tables.html#setequal",
    "title": "Joining Tables",
    "section": "setequal",
    "text": "setequal\n\nFinally, the function setequal tells us if two sets are the same, regardless of order.\nSo notice that:\n\n\nsetequal(1:5, 1:6) \n\n[1] FALSE\n\n\n\nbut:\n\n\nsetequal(1:5, 5:1) \n\n[1] TRUE"
  },
  {
    "objectID": "slides/wrangling/16-joining-tables.html#setequal-1",
    "href": "slides/wrangling/16-joining-tables.html#setequal-1",
    "title": "Joining Tables",
    "section": "setequal",
    "text": "setequal\n\nThe dplyr version checks whether data frames are equal, regardless of order of rows or columns:\n\n\ndplyr::setequal(tab_1, tab_2) \n\n[1] FALSE"
  },
  {
    "objectID": "slides/wrangling/16-joining-tables.html#joining-with-data.table",
    "href": "slides/wrangling/16-joining-tables.html#joining-with-data.table",
    "title": "Joining Tables",
    "section": "Joining with data.table",
    "text": "Joining with data.table\n\nThe data.table package includes merge, a very efficient function for joining tables.\nIn tidyverse we joined two tables with left_join:\n\n\ntab &lt;- left_join(murders, results_us_election_2016, by = \"state\")"
  },
  {
    "objectID": "slides/wrangling/16-joining-tables.html#joining-with-data.table-1",
    "href": "slides/wrangling/16-joining-tables.html#joining-with-data.table-1",
    "title": "Joining Tables",
    "section": "Joining with data.table",
    "text": "Joining with data.table\n\nIn data.table the merge functions works similarly:\n\n\nlibrary(data.table) \ntab &lt;- merge(murders, results_us_election_2016, by = \"state\", all.x = TRUE)"
  },
  {
    "objectID": "slides/wrangling/16-joining-tables.html#joining-with-data.table-2",
    "href": "slides/wrangling/16-joining-tables.html#joining-with-data.table-2",
    "title": "Joining Tables",
    "section": "Joining with data.table",
    "text": "Joining with data.table\n\nInstead of defining different functions for the different type of joins, merge uses the the logical arguments all (full join), all.x (left join), and all.y (right join)."
  },
  {
    "objectID": "slides/R/07-tidyverse.html#tidyverse",
    "href": "slides/R/07-tidyverse.html#tidyverse",
    "title": "Tidyverse",
    "section": "Tidyverse",
    "text": "Tidyverse\n\nlibrary(tidyverse)\n\n\nThe tidyverse is not a package but a group of packages developed to work with each other.\nThe tidyverse makes data analysis simpler and code easier to read by sacrificing some flexibility.\nOne way code is simplified by ensuring all functions take and return tidy data."
  },
  {
    "objectID": "slides/R/07-tidyverse.html#tidy-data",
    "href": "slides/R/07-tidyverse.html#tidy-data",
    "title": "Tidyverse",
    "section": "Tidy data",
    "text": "Tidy data\n\nStored in a data frame.\nEach observation is exactly one row.\nVariables are stored in columns.\nNot all data can be represented this way, but a very large subset of data analysis challenges are based on tidy data.\nAssuming data is tidy simplifies coding and frees up our minds for statistical thinking."
  },
  {
    "objectID": "slides/R/07-tidyverse.html#tidy-data-1",
    "href": "slides/R/07-tidyverse.html#tidy-data-1",
    "title": "Tidyverse",
    "section": "Tidy data",
    "text": "Tidy data\n\nThis is an example of a tidy dataset:\n\n\n\n      country year fertility\n1     Germany 1960      2.41\n2 South Korea 1960      6.16\n3     Germany 1961      2.44\n4 South Korea 1961      5.99\n5     Germany 1962      2.47\n6 South Korea 1962      5.79"
  },
  {
    "objectID": "slides/R/07-tidyverse.html#tidy-data-2",
    "href": "slides/R/07-tidyverse.html#tidy-data-2",
    "title": "Tidyverse",
    "section": "Tidy data",
    "text": "Tidy data\n\nOriginally, the data was in the following format:\n\n\n\n      country 1960 1961 1962 1963 1964 1965 1966 1967 1968 1969 1970\n1     Germany 2.41 2.44 2.47 2.49 2.49 2.48 2.44 2.37 2.28 2.17 2.04\n2 South Korea 6.16 5.99 5.79 5.57 5.36 5.16 4.99 4.85 4.73 4.62 4.53\n\n\n\nThis is not tidy."
  },
  {
    "objectID": "slides/R/07-tidyverse.html#tidyverse-packages",
    "href": "slides/R/07-tidyverse.html#tidyverse-packages",
    "title": "Tidyverse",
    "section": "Tidyverse packages",
    "text": "Tidyverse packages\n\ntibble - improves data frame class.\nreadr - import data.\ndplyr - used to modify data frames.\nggplot2 - simplifies plotting.\ntidyr - helps convert data into tidy format.\nstringr - string processing.\nforcats - utilities for categorical data.\npurrr - tidy version of apply functions."
  },
  {
    "objectID": "slides/R/07-tidyverse.html#dplyr",
    "href": "slides/R/07-tidyverse.html#dplyr",
    "title": "Tidyverse",
    "section": "dplyr",
    "text": "dplyr\n\nIn this lecture we focus mainly on dplyr.\nIn particular the following functions:\n\nmutate\nselect\nacross\nfilter\ngroup_by\nsummarize"
  },
  {
    "objectID": "slides/R/07-tidyverse.html#adding-a-column-with-mutate",
    "href": "slides/R/07-tidyverse.html#adding-a-column-with-mutate",
    "title": "Tidyverse",
    "section": "Adding a column with mutate",
    "text": "Adding a column with mutate\n\nmurders &lt;- mutate(murders, rate = total/population*100000)\n\n\nNotice that here we used total and population inside the function, which are objects that are not defined in our workspace.\nThis is known as non-standard evaluation where the context is used to know what variable names means.\nTidyverse extensively uses non-standard evaluation.\nThis can create confusion but it certainly simplifies code."
  },
  {
    "objectID": "slides/R/07-tidyverse.html#subsetting-with-filter",
    "href": "slides/R/07-tidyverse.html#subsetting-with-filter",
    "title": "Tidyverse",
    "section": "Subsetting with filter",
    "text": "Subsetting with filter\n\nfilter(murders, rate &lt;= 0.71)\n\n          state abb        region population total      rate\n1        Hawaii  HI          West    1360301     7 0.5145920\n2          Iowa  IA North Central    3046355    21 0.6893484\n3 New Hampshire  NH     Northeast    1316470     5 0.3798036\n4  North Dakota  ND North Central     672591     4 0.5947151\n5       Vermont  VT     Northeast     625741     2 0.3196211"
  },
  {
    "objectID": "slides/R/07-tidyverse.html#selecting-columns-with-select",
    "href": "slides/R/07-tidyverse.html#selecting-columns-with-select",
    "title": "Tidyverse",
    "section": "Selecting columns with select",
    "text": "Selecting columns with select\n\nnew_table &lt;- select(murders, state, region, rate)\nfilter(new_table, rate &lt;= 0.71)\n\n          state        region      rate\n1        Hawaii          West 0.5145920\n2          Iowa North Central 0.6893484\n3 New Hampshire     Northeast 0.3798036\n4  North Dakota North Central 0.5947151\n5       Vermont     Northeast 0.3196211"
  },
  {
    "objectID": "slides/R/07-tidyverse.html#transforming-variables",
    "href": "slides/R/07-tidyverse.html#transforming-variables",
    "title": "Tidyverse",
    "section": "Transforming variables",
    "text": "Transforming variables\n\nThe function mutate can also be used to transform variables.\nFor example, the following code takes the log transformation of the population variable:\n\n\nmutate(murders, population = log10(population))"
  },
  {
    "objectID": "slides/R/07-tidyverse.html#transforming-variables-1",
    "href": "slides/R/07-tidyverse.html#transforming-variables-1",
    "title": "Tidyverse",
    "section": "Transforming variables",
    "text": "Transforming variables\n\nOften, we need to apply the same transformation to several variables.\nThe function across facilitates the operation.\nFor example if want to log transform both population and total murders we can use:\n\n\nmutate(murders, across(c(population, total), log10))"
  },
  {
    "objectID": "slides/R/07-tidyverse.html#transforming-variables-2",
    "href": "slides/R/07-tidyverse.html#transforming-variables-2",
    "title": "Tidyverse",
    "section": "Transforming variables",
    "text": "Transforming variables\n\nThe helper functions come in handy when using across.\nAn example is if we want to apply the same transformation to all numeric variables:\n\n\nmutate(murders, across(where(is.numeric), log10))\n\n\nor all character variables:\n\n\nmutate(murders, across(where(is.character), tolower))\n\n\nThere are several other useful helper functions."
  },
  {
    "objectID": "slides/R/07-tidyverse.html#the-pipe-or",
    "href": "slides/R/07-tidyverse.html#the-pipe-or",
    "title": "Tidyverse",
    "section": "The pipe: |> or %>%",
    "text": "The pipe: |&gt; or %&gt;%\n\nWe use the pipe to chain a series of operations.\nFor example if we want to select columns and then filter rows we chain like this:\n\n\\[ \\mbox{original data }\n\\rightarrow \\mbox{ select }\n\\rightarrow \\mbox{ filter } \\]"
  },
  {
    "objectID": "slides/R/07-tidyverse.html#the-pipe-or-1",
    "href": "slides/R/07-tidyverse.html#the-pipe-or-1",
    "title": "Tidyverse",
    "section": "The pipe: |> or %>%",
    "text": "The pipe: |&gt; or %&gt;%\n\nThe code looks like this:\n\n\nmurders |&gt; select(state, region, rate) |&gt; filter(rate &lt;= 0.71)\n\n          state        region      rate\n1        Hawaii          West 0.5145920\n2          Iowa North Central 0.6893484\n3 New Hampshire     Northeast 0.3798036\n4  North Dakota North Central 0.5947151\n5       Vermont     Northeast 0.3196211\n\n\n\nThe object on the left of the pipe is used as the first argument for the function on the right.\nThe second argument becomes the first, the third the second, and so on…"
  },
  {
    "objectID": "slides/R/07-tidyverse.html#the-pipe-or-2",
    "href": "slides/R/07-tidyverse.html#the-pipe-or-2",
    "title": "Tidyverse",
    "section": "The pipe: |> or %>%",
    "text": "The pipe: |&gt; or %&gt;%\n\nHere is a simple example:\n\n\n16 |&gt; sqrt() |&gt; log(base = 2)\n\n[1] 2"
  },
  {
    "objectID": "slides/R/07-tidyverse.html#summarizing-data",
    "href": "slides/R/07-tidyverse.html#summarizing-data",
    "title": "Tidyverse",
    "section": "Summarizing data",
    "text": "Summarizing data\n\nWe use the dplyr summarize function, not to be confused with summary from R base.\nHere is an example of how it works:\n\n\nmurders |&gt; summarize(avg = mean(rate))\n\n       avg\n1 2.779125\n\n\n\nLet’s compute murder rate for the US. Is the above it?"
  },
  {
    "objectID": "slides/R/07-tidyverse.html#summarizing-data-1",
    "href": "slides/R/07-tidyverse.html#summarizing-data-1",
    "title": "Tidyverse",
    "section": "Summarizing data",
    "text": "Summarizing data\n\nNo, the rate is NOT the average of rates.\nIt is the total murders divided by total population:\n\n\nmurders |&gt; summarize(rate = sum(total)/sum(population)*100000)\n\n      rate\n1 3.034555"
  },
  {
    "objectID": "slides/R/07-tidyverse.html#multiple-summaries",
    "href": "slides/R/07-tidyverse.html#multiple-summaries",
    "title": "Tidyverse",
    "section": "Multiple summaries",
    "text": "Multiple summaries\n\nSuppose we want the median, minimum and max population size:\n\n\nmurders |&gt; summarize(median = median(population), min = min(population), max = max(population))\n\n   median    min      max\n1 4339367 563626 37253956\n\n\n\nWhy don’t we use quantiles?\n\n\nmurders |&gt; summarize(quantiles = quantile(population, c(0.5, 0, 1)))\n\n  quantiles\n1   4339367\n2    563626\n3  37253956"
  },
  {
    "objectID": "slides/R/07-tidyverse.html#multiple-summaries-1",
    "href": "slides/R/07-tidyverse.html#multiple-summaries-1",
    "title": "Tidyverse",
    "section": "Multiple summaries",
    "text": "Multiple summaries\n\n\n\n\n\n\nWarning\n\n\nUsing a function that returns more than one number within summarize will soon be deprecated.\n\n\n\n\nFor multiple summaries we use reframe:\n\n\nmurders |&gt; reframe(quantiles = quantile(population, c(0.5, 0, 1)))\n\n  quantiles\n1   4339367\n2    563626\n3  37253956"
  },
  {
    "objectID": "slides/R/07-tidyverse.html#multiple-summaries-2",
    "href": "slides/R/07-tidyverse.html#multiple-summaries-2",
    "title": "Tidyverse",
    "section": "Multiple summaries",
    "text": "Multiple summaries\n\nHowever, if we want a column per summary, as when we called min, median, and max separately, we have to define a function that returns a data frame like this:\n\n\nmedian_min_max &lt;- function(x){\n  qs &lt;- quantile(x, c(0.5, 0, 1))\n  data.frame(median = qs[1], min = qs[2], max = qs[3])\n}\n\n\nThen we can call summarize:\n\n\nmurders |&gt; summarize(median_min_max(population))\n\n   median    min      max\n1 4339367 563626 37253956"
  },
  {
    "objectID": "slides/R/07-tidyverse.html#group-then-summarize",
    "href": "slides/R/07-tidyverse.html#group-then-summarize",
    "title": "Tidyverse",
    "section": "Group then summarize",
    "text": "Group then summarize\n\nLet’s compute murder rate by region.\nTake a close look at this output?\n\n\nmurders |&gt; group_by(region) |&gt; head(4)\n\n# A tibble: 4 × 6\n# Groups:   region [2]\n  state    abb   region population total  rate\n  &lt;chr&gt;    &lt;chr&gt; &lt;fct&gt;       &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Alabama  AL    South     4779736   135  2.82\n2 Alaska   AK    West       710231    19  2.68\n3 Arizona  AZ    West      6392017   232  3.63\n4 Arkansas AR    South     2915918    93  3.19\n\n\n\nNote the Groups: region [4] at the top.\nThis is a special data frame called a grouped data frame."
  },
  {
    "objectID": "slides/R/07-tidyverse.html#group-then-summarize-1",
    "href": "slides/R/07-tidyverse.html#group-then-summarize-1",
    "title": "Tidyverse",
    "section": "Group then summarize",
    "text": "Group then summarize\n\nIn particular summarize, will behave differently when acting on this object.\n\n\nmurders |&gt; \n  group_by(region) |&gt; \n  summarize(rate = sum(total) / sum(population) * 100000)\n\n# A tibble: 4 × 2\n  region         rate\n  &lt;fct&gt;         &lt;dbl&gt;\n1 Northeast      2.66\n2 South          3.63\n3 North Central  2.73\n4 West           2.66\n\n\n\nThe summarize function applies the summarization to each group separately."
  },
  {
    "objectID": "slides/R/07-tidyverse.html#group-then-summarize-2",
    "href": "slides/R/07-tidyverse.html#group-then-summarize-2",
    "title": "Tidyverse",
    "section": "Group then summarize",
    "text": "Group then summarize\n\nFor another example, let’s compute the median, minimum, and maximum population in the four regions of the country using the median_min_max previously defined:\n\n\nmurders |&gt; group_by(region) |&gt; summarize(median_min_max(population))\n\n# A tibble: 4 × 4\n  region          median    min      max\n  &lt;fct&gt;            &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;\n1 Northeast     3574097  625741 19378102\n2 South         4625364  601723 25145561\n3 North Central 5495456. 672591 12830632\n4 West          2700551  563626 37253956"
  },
  {
    "objectID": "slides/R/07-tidyverse.html#group-then-summarize-3",
    "href": "slides/R/07-tidyverse.html#group-then-summarize-3",
    "title": "Tidyverse",
    "section": "Group then summarize",
    "text": "Group then summarize\n\nYou can also summarize a variable but not collapse the dataset.\nWe use mutate instead of summarize.\nHere is an example where we add a column with the population in each region and the number of states in the region, shown for each state.\n\n\nmurders |&gt; group_by(region) |&gt; \n  mutate(region_pop = sum(population), n = n())"
  },
  {
    "objectID": "slides/R/07-tidyverse.html#ungroup",
    "href": "slides/R/07-tidyverse.html#ungroup",
    "title": "Tidyverse",
    "section": "ungroup",
    "text": "ungroup\n\nWhen we do this, we usually want to ungroup before continuing our analysis.\n\n\nmurders |&gt; group_by(region) |&gt; \n  mutate(region_pop = sum(population), n = n()) |&gt;\n  ungroup()\n\n\nThis avoids having a grouped data frame that we don’t need."
  },
  {
    "objectID": "slides/R/07-tidyverse.html#pull",
    "href": "slides/R/07-tidyverse.html#pull",
    "title": "Tidyverse",
    "section": "pull",
    "text": "pull\n\nTidyverse function always returns a data frame. Even if its just one number.\n\n\nmurders |&gt; \n  summarize(rate = sum(total)/sum(population)*100000) |&gt;\n  class()\n\n[1] \"data.frame\""
  },
  {
    "objectID": "slides/R/07-tidyverse.html#pull-1",
    "href": "slides/R/07-tidyverse.html#pull-1",
    "title": "Tidyverse",
    "section": "pull",
    "text": "pull\n\nTo get a numeric use pull:\n\n\nmurders |&gt; \n  summarize(rate = sum(total)/sum(population)*100000) |&gt;\n  pull(rate) \n\n[1] 3.034555"
  },
  {
    "objectID": "slides/R/07-tidyverse.html#sorting-data-frames",
    "href": "slides/R/07-tidyverse.html#sorting-data-frames",
    "title": "Tidyverse",
    "section": "Sorting data frames",
    "text": "Sorting data frames\n\nStates order by rate\n\n\nmurders |&gt; arrange(rate) |&gt; head()\n\n          state abb        region population total      rate\n1       Vermont  VT     Northeast     625741     2 0.3196211\n2 New Hampshire  NH     Northeast    1316470     5 0.3798036\n3        Hawaii  HI          West    1360301     7 0.5145920\n4  North Dakota  ND North Central     672591     4 0.5947151\n5          Iowa  IA North Central    3046355    21 0.6893484\n6         Idaho  ID          West    1567582    12 0.7655102"
  },
  {
    "objectID": "slides/R/07-tidyverse.html#sorting-data-frames-1",
    "href": "slides/R/07-tidyverse.html#sorting-data-frames-1",
    "title": "Tidyverse",
    "section": "Sorting data frames",
    "text": "Sorting data frames\n\nIf we want decreasing we can either use the negative or, for more readability, use desc:\n\n\nmurders |&gt; arrange(desc(rate)) |&gt; head()\n\n                 state abb        region population total      rate\n1 District of Columbia  DC         South     601723    99 16.452753\n2            Louisiana  LA         South    4533372   351  7.742581\n3             Missouri  MO North Central    5988927   321  5.359892\n4             Maryland  MD         South    5773552   293  5.074866\n5       South Carolina  SC         South    4625364   207  4.475323\n6             Delaware  DE         South     897934    38  4.231937"
  },
  {
    "objectID": "slides/R/07-tidyverse.html#sorting-data-frames-2",
    "href": "slides/R/07-tidyverse.html#sorting-data-frames-2",
    "title": "Tidyverse",
    "section": "Sorting data frames",
    "text": "Sorting data frames\n\nWe can use two variables as well:\n\n\nmurders |&gt; arrange(region, desc(rate)) |&gt; head(11)\n\n                  state abb    region population total       rate\n1          Pennsylvania  PA Northeast   12702379   457  3.5977513\n2            New Jersey  NJ Northeast    8791894   246  2.7980319\n3           Connecticut  CT Northeast    3574097    97  2.7139722\n4              New York  NY Northeast   19378102   517  2.6679599\n5         Massachusetts  MA Northeast    6547629   118  1.8021791\n6          Rhode Island  RI Northeast    1052567    16  1.5200933\n7                 Maine  ME Northeast    1328361    11  0.8280881\n8         New Hampshire  NH Northeast    1316470     5  0.3798036\n9               Vermont  VT Northeast     625741     2  0.3196211\n10 District of Columbia  DC     South     601723    99 16.4527532\n11            Louisiana  LA     South    4533372   351  7.7425810"
  },
  {
    "objectID": "slides/R/09-tidyr.html#tidying-data",
    "href": "slides/R/09-tidyr.html#tidying-data",
    "title": "Tidying data",
    "section": "Tidying data",
    "text": "Tidying data\n\nWe will a wide format dataset as an example:\n\n\nlibrary(tidyverse) \nlibrary(dslabs)\npath &lt;- system.file(\"extdata\", package = \"dslabs\")\nfilename &lt;- file.path(path, \"fertility-two-countries-example.csv\")\nwide_data &lt;- read_csv(filename)\nselect(wide_data, 1:10)\n\n# A tibble: 2 × 10\n  country     `1960` `1961` `1962` `1963` `1964` `1965` `1966` `1967` `1968`\n  &lt;chr&gt;        &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1 Germany       2.41   2.44   2.47   2.49   2.49   2.48   2.44   2.37   2.28\n2 South Korea   6.16   5.99   5.79   5.57   5.36   5.16   4.99   4.85   4.73"
  },
  {
    "objectID": "slides/R/09-tidyr.html#pivot_longer",
    "href": "slides/R/09-tidyr.html#pivot_longer",
    "title": "Tidying data",
    "section": "pivot_longer",
    "text": "pivot_longer\n\nOne of the most used functions in tidyr is pivot_longer.\nThe first argument is a data frame, the one that will be converted.\nWe want to reshape rows represents a fertility observation.\nWe need three columns to store the year, country, and the observed value."
  },
  {
    "objectID": "slides/R/09-tidyr.html#pivot_longer-1",
    "href": "slides/R/09-tidyr.html#pivot_longer-1",
    "title": "Tidying data",
    "section": "pivot_longer",
    "text": "pivot_longer\n\nIn its current form, data from different years are in different columns with the year values stored in the column names.\nThe names_to and values_to argument tell pivot_longer the column names we want to assign to the columns containing the current column names and observations, respectively.\nThe default names are name and value, in our case a better choice is year and fertility."
  },
  {
    "objectID": "slides/R/09-tidyr.html#pivot_longer-2",
    "href": "slides/R/09-tidyr.html#pivot_longer-2",
    "title": "Tidying data",
    "section": "pivot_longer",
    "text": "pivot_longer\n\nThrough cols, the second argument, we specify the columns containing observed values; these are the columns that will be pivoted.\nThe default is to pivot all columns so, in most cases, we have to specify the columns. In our example we want columns 1960, 1961 up to 2015."
  },
  {
    "objectID": "slides/R/09-tidyr.html#pivot_longer-3",
    "href": "slides/R/09-tidyr.html#pivot_longer-3",
    "title": "Tidying data",
    "section": "pivot_longer",
    "text": "pivot_longer\nThe code to pivot the fertility data therefore looks like this:\n\nnew_tidy_data &lt;- wide_data |&gt;\n  pivot_longer(`1960`:`2015`, names_to = \"year\", values_to = \"fertility\")\nhead(new_tidy_data)\n\n# A tibble: 6 × 3\n  country year  fertility\n  &lt;chr&gt;   &lt;chr&gt;     &lt;dbl&gt;\n1 Germany 1960       2.41\n2 Germany 1961       2.44\n3 Germany 1962       2.47\n4 Germany 1963       2.49\n5 Germany 1964       2.49\n6 Germany 1965       2.48\n\n\n\nData have been converted to tidy format with columns year and fertility."
  },
  {
    "objectID": "slides/R/09-tidyr.html#pivot_longer-4",
    "href": "slides/R/09-tidyr.html#pivot_longer-4",
    "title": "Tidying data",
    "section": "pivot_longer",
    "text": "pivot_longer\n\nA quicker way to write this code is to specify which column will not include in the pivot:\n\n\nnew_tidy_data &lt;- wide_data |&gt;\n  pivot_longer(-country, names_to = \"year\", values_to = \"fertility\")"
  },
  {
    "objectID": "slides/R/09-tidyr.html#pivot_longer-5",
    "href": "slides/R/09-tidyr.html#pivot_longer-5",
    "title": "Tidying data",
    "section": "pivot_longer",
    "text": "pivot_longer\n\nNow that the data is tidy, we can use it with other tidyverse functions, such ggplot2:\n\n\nnew_tidy_data |&gt; \n  mutate(year = as.numeric(year)) |&gt;\n  ggplot(aes(year, fertility, color = country)) + \n  geom_line()"
  },
  {
    "objectID": "slides/R/09-tidyr.html#pivot_wider",
    "href": "slides/R/09-tidyr.html#pivot_wider",
    "title": "Tidying data",
    "section": "pivot_wider",
    "text": "pivot_wider\n\nIt is sometimes useful for data wrangling purposes to convert tidy data into wide data.\nWe often use this as an intermediate step in tidying up data.\nThe pivot_wider function is basically the inverse of pivot_longer."
  },
  {
    "objectID": "slides/R/09-tidyr.html#pivot_wider-1",
    "href": "slides/R/09-tidyr.html#pivot_wider-1",
    "title": "Tidying data",
    "section": "pivot_wider",
    "text": "pivot_wider\n\nThe first argument is for the data, but since we are using the pipe, we don’t show it.\nThe names_from argument tells pivot_wider which variable will be used as the column names.\nThe values_from argument specifies which variable to use to fill out the cells."
  },
  {
    "objectID": "slides/R/09-tidyr.html#pivot_wider-2",
    "href": "slides/R/09-tidyr.html#pivot_wider-2",
    "title": "Tidying data",
    "section": "pivot_wider",
    "text": "pivot_wider\nHere is some example code\n\nnew_wide_data &lt;- new_tidy_data |&gt; \n  pivot_wider(names_from = year, values_from = fertility)\nselect(new_wide_data, country, `1960`:`1967`)\n\n# A tibble: 2 × 9\n  country     `1960` `1961` `1962` `1963` `1964` `1965` `1966` `1967`\n  &lt;chr&gt;        &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1 Germany       2.41   2.44   2.47   2.49   2.49   2.48   2.44   2.37\n2 South Korea   6.16   5.99   5.79   5.57   5.36   5.16   4.99   4.85\n\n\nSimilar to pivot_wider, names_from and values_from default to name and value."
  },
  {
    "objectID": "slides/R/09-tidyr.html#example",
    "href": "slides/R/09-tidyr.html#example",
    "title": "Tidying data",
    "section": "Example",
    "text": "Example\nWe now demonstrate with a more complex example in which we have to use both pivot_longer and pivot_wider to tidy the data.\n\npath &lt;- system.file(\"extdata\", package = \"dslabs\")\n\nfilename &lt;- \"life-expectancy-and-fertility-two-countries-example.csv\"\nfilename &lt;-  file.path(path, filename)\n\nraw_dat &lt;- read_csv(filename)\nselect(raw_dat, 1:5)\n\n# A tibble: 2 × 5\n  country     `1960_fertility` `1960_life_expectancy` `1961_fertility`\n  &lt;chr&gt;                  &lt;dbl&gt;                  &lt;dbl&gt;            &lt;dbl&gt;\n1 Germany                 2.41                   69.3             2.44\n2 South Korea             6.16                   53.0             5.99\n# ℹ 1 more variable: `1961_life_expectancy` &lt;dbl&gt;"
  },
  {
    "objectID": "slides/R/09-tidyr.html#example-1",
    "href": "slides/R/09-tidyr.html#example-1",
    "title": "Tidying data",
    "section": "Example",
    "text": "Example\n\nNote that the data is in wide format.\nAlso that this table includes values for two variables, fertility and life expectancy, with the column name encoding which column represents which variable.\nEncoding information in the column names is not recommended but, unfortunately, it is quite common."
  },
  {
    "objectID": "slides/R/09-tidyr.html#example-2",
    "href": "slides/R/09-tidyr.html#example-2",
    "title": "Tidying data",
    "section": "Example",
    "text": "Example\n\nWe start with the pivot_longer function, but we should no longer use the column name year for the new column since it also contains the variable type.\nWe will call it name, the default, for now:\n\n\nraw_dat |&gt; pivot_longer(-country) |&gt; head()\n\n# A tibble: 6 × 3\n  country name                 value\n  &lt;chr&gt;   &lt;chr&gt;                &lt;dbl&gt;\n1 Germany 1960_fertility        2.41\n2 Germany 1960_life_expectancy 69.3 \n3 Germany 1961_fertility        2.44\n4 Germany 1961_life_expectancy 69.8 \n5 Germany 1962_fertility        2.47\n6 Germany 1962_life_expectancy 70.0"
  },
  {
    "objectID": "slides/R/09-tidyr.html#example-3",
    "href": "slides/R/09-tidyr.html#example-3",
    "title": "Tidying data",
    "section": "Example",
    "text": "Example\n\nThe result is not exactly what we refer to as tidy since each observation is associated with two, not one, rows.\nWe want to have the values from the two variables, fertility and life expectancy, in two separate columns.\nThe first challenge to achieve this is to separate the name column into the year and the variable type."
  },
  {
    "objectID": "slides/R/09-tidyr.html#example-4",
    "href": "slides/R/09-tidyr.html#example-4",
    "title": "Tidying data",
    "section": "Example",
    "text": "Example\n\nEncoding multiple variables in a column name is such a common problem that the tidyr package includes function to separate these columns into two or more:\n\n\nraw_dat |&gt; \n  pivot_longer(-country) |&gt; \n  separate_wider_delim(name, delim = \"_\",  names = c(\"year\", \"name\"), \n                       too_many = \"merge\") |&gt;\n  head()\n\n# A tibble: 6 × 4\n  country year  name            value\n  &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt;           &lt;dbl&gt;\n1 Germany 1960  fertility        2.41\n2 Germany 1960  life_expectancy 69.3 \n3 Germany 1961  fertility        2.44\n4 Germany 1961  life_expectancy 69.8 \n5 Germany 1962  fertility        2.47\n6 Germany 1962  life_expectancy 70.0"
  },
  {
    "objectID": "slides/R/09-tidyr.html#example-5",
    "href": "slides/R/09-tidyr.html#example-5",
    "title": "Tidying data",
    "section": "Example",
    "text": "Example\n\nBut we are not done yet.\nWe need to create a column for each variable and change year to a number.\nAs we learned, the pivot_wider function can do this."
  },
  {
    "objectID": "slides/R/09-tidyr.html#example-6",
    "href": "slides/R/09-tidyr.html#example-6",
    "title": "Tidying data",
    "section": "Example",
    "text": "Example\n\ndat &lt;- raw_dat |&gt; \n  pivot_longer(-country) |&gt; \n  separate_wider_delim(name, delim = \"_\", \n                       names = c(\"year\", \"name\"), \n                       too_many = \"merge\") |&gt;\n  pivot_wider() |&gt;\n  mutate(year = as.integer(year))\nhead(dat)\n\n# A tibble: 6 × 4\n  country  year fertility life_expectancy\n  &lt;chr&gt;   &lt;int&gt;     &lt;dbl&gt;           &lt;dbl&gt;\n1 Germany  1960      2.41            69.3\n2 Germany  1961      2.44            69.8\n3 Germany  1962      2.47            70.0\n4 Germany  1963      2.49            70.1\n5 Germany  1964      2.49            70.7\n6 Germany  1965      2.48            70.6"
  },
  {
    "objectID": "slides/R/09-tidyr.html#example-7",
    "href": "slides/R/09-tidyr.html#example-7",
    "title": "Tidying data",
    "section": "Example",
    "text": "Example\nThe data is now is now in tidy form and we can use with other packages:\n\np1 &lt;- dat |&gt; ggplot(aes(year, fertility, color = country)) + geom_line(show.legend = FALSE)\np2 &lt;- dat |&gt; ggplot(aes(year, life_expectancy, color = country)) + geom_line()\ngridExtra::grid.arrange(p1, p2, ncol = 2, widths = c(3,4))"
  },
  {
    "objectID": "slides/00-intro.html#general-information",
    "href": "slides/00-intro.html#general-information",
    "title": "Introduction",
    "section": "General Information",
    "text": "General Information\n\nBST 260 Introduction to Data Science\nInstructor: Rafael A. Irizarry\nTFs: Corri Sept, Nikhil Vytla, Yuan Wang\nMondays we have lectures, Wednesday we have labs.\nWe work on problem sets together, in lab."
  },
  {
    "objectID": "slides/00-intro.html#course-description",
    "href": "slides/00-intro.html#course-description",
    "title": "Introduction",
    "section": "Course Description",
    "text": "Course Description\nLecture notes: https://datasciencelabs.github.io/2024/\n\nPlease read the syllabus!"
  },
  {
    "objectID": "slides/00-intro.html#important-details",
    "href": "slides/00-intro.html#important-details",
    "title": "Introduction",
    "section": "Important details",
    "text": "Important details\n\nComplete readings before class.\nMidterms are in person. There are no makeups.\nMake sure you read messages sent via Canvas\nYou can select your own final project, but need approval.\nYou should start final project by October 23.\nHelp us pick office hours: https://forms.gle/GiQXqDTaeYVxaXd78"
  },
  {
    "objectID": "slides/00-intro.html#whats-coming",
    "href": "slides/00-intro.html#whats-coming",
    "title": "Introduction",
    "section": "What’s coming",
    "text": "What’s coming\n\nUNIX/Linux shell.\nReproducible document preparation\nVersion control with git and GitHub\nR programming\nData wrangling with dplyr and data.table\nData visualization with ggplot2\nProbability theory, inference and modeling\nHigh-dimensional data techniques\nMachine learning"
  },
  {
    "objectID": "slides/00-intro.html#lets-get-started",
    "href": "slides/00-intro.html#lets-get-started",
    "title": "Introduction",
    "section": "Let’s get started",
    "text": "Let’s get started\n\nInstall R.\nInstall RStudio.\nMake sure you have access to a terminal."
  },
  {
    "objectID": "slides/prob/20-intro-to-prob.html#probability",
    "href": "slides/prob/20-intro-to-prob.html#probability",
    "title": "Introduction to Probability",
    "section": "Probability",
    "text": "Probability\n\nThe term probability is used in everyday language.\nYet answering questions about probability is often hard, if not impossible.\nIn contrast probability has a very intuitive definition in games of chance.\nToday we discuss a mathematical definition of probability that allows us to give precise answers to certain questions."
  },
  {
    "objectID": "slides/prob/20-intro-to-prob.html#probability-1",
    "href": "slides/prob/20-intro-to-prob.html#probability-1",
    "title": "Introduction to Probability",
    "section": "Probability",
    "text": "Probability\n\nProbability Theory was born because certain mathematcial computations can give an advantage in games of chance.\nProbability continues to be highly useful in modern games of chance.\nProbability theory is also useful whenever our data is affected by chance in some manner.\nA knowledge of probability is indispensable for addressing most data analysis challenges."
  },
  {
    "objectID": "slides/prob/20-intro-to-prob.html#probability-2",
    "href": "slides/prob/20-intro-to-prob.html#probability-2",
    "title": "Introduction to Probability",
    "section": "Probability",
    "text": "Probability\n\nIn today’s lecture, we will use casino games to illustrate the fundamental concepts.\nInstead of diving into the mathematical theories, we will uses R to demonstrate these concepts.\nUnderstanding the connection between probability theory and real world data analysis is a bit more challenging. We will be discussing this connection throughout the rest of the course."
  },
  {
    "objectID": "slides/prob/20-intro-to-prob.html#definitions-and-notation",
    "href": "slides/prob/20-intro-to-prob.html#definitions-and-notation",
    "title": "Introduction to Probability",
    "section": "Definitions and Notation",
    "text": "Definitions and Notation\n\nEvents are fundamental concepts that help us understand and quantify uncertainty in various situations.\nAn event is defined as a specific outcome or a collection of outcomes from a random experiment."
  },
  {
    "objectID": "slides/prob/20-intro-to-prob.html#definitions-and-notation-1",
    "href": "slides/prob/20-intro-to-prob.html#definitions-and-notation-1",
    "title": "Introduction to Probability",
    "section": "Definitions and Notation",
    "text": "Definitions and Notation\n\nSimple examples of events can be constructed with urns.\nIf we have 2 red beads and 3 blue beads inside an urn, and we perform the random experiment of picking 1 bead, there are two outcomes: bead is red or blue.\n\n\nbeads &lt;- rep( c(\"red\", \"blue\"), times = c(2,3))\n\n\nThe four possible events: bead is red, bead is blue, bead is red or blue, and an event with no outcomes."
  },
  {
    "objectID": "slides/prob/20-intro-to-prob.html#definitions-and-notation-2",
    "href": "slides/prob/20-intro-to-prob.html#definitions-and-notation-2",
    "title": "Introduction to Probability",
    "section": "Definitions and Notation",
    "text": "Definitions and Notation\n\nIn more complex random experiment, we can define many more events.\nFor example if the random experiment is picking 2 beads, we can define events such as first bead is red, second bead is blue, both beads are red, and so on.\nIn a random experiment such as political poll, where we randomly phone 100 likely voters at random, we can form many million events, for example calling 48 Democrats and 52 Republicans."
  },
  {
    "objectID": "slides/prob/20-intro-to-prob.html#definitions-and-notation-3",
    "href": "slides/prob/20-intro-to-prob.html#definitions-and-notation-3",
    "title": "Introduction to Probability",
    "section": "Definitions and Notation",
    "text": "Definitions and Notation\n\nWe usually use capital letters \\(A\\), \\(B\\), \\(C\\), … to to denote events.\nIf we denote an event as \\(A\\) then we use the notation \\(\\mbox{Pr}(A)\\) to denote the probability of event \\(A\\) occurring."
  },
  {
    "objectID": "slides/prob/20-intro-to-prob.html#definitions-and-notation-4",
    "href": "slides/prob/20-intro-to-prob.html#definitions-and-notation-4",
    "title": "Introduction to Probability",
    "section": "Definitions and Notation",
    "text": "Definitions and Notation\n\nWe can combine events in different ways to form new events. For example, if event\n\\(A\\)=first bead is red and second bead is blue, and\n\\(B\\)=first bead is red and second bead is red\nthen \\(A \\cup B\\) (\\(A\\) or \\(B\\)) is the event first bead is red,\nwhile \\(A \\cap B\\) (\\(A\\) and \\(B\\)) is the empty event since both can’t happen."
  },
  {
    "objectID": "slides/prob/20-intro-to-prob.html#definitions-and-notation-5",
    "href": "slides/prob/20-intro-to-prob.html#definitions-and-notation-5",
    "title": "Introduction to Probability",
    "section": "Definitions and Notation",
    "text": "Definitions and Notation\n\nWith continuous variables, events will relate to questions, such as Is this person taller than 6 feet?\nIn these cases, we represent events in a more mathematical form: \\(A = X &gt; 6\\)."
  },
  {
    "objectID": "slides/prob/20-intro-to-prob.html#independence",
    "href": "slides/prob/20-intro-to-prob.html#independence",
    "title": "Introduction to Probability",
    "section": "Independence",
    "text": "Independence\n\nMany examples of events that are not independent come from card games.\nWhen we deal the first card, the probability of getting a King is 1/13 since there are thirteen possibilities: Ace, Deuce, Three, \\(\\dots\\), Ten, Jack, Queen, King, and Ace.\nIf we deal a King for the first card, the probability of a second card being a King decreases because there are only three Kings left: The probability is 3 out of 51."
  },
  {
    "objectID": "slides/prob/20-intro-to-prob.html#independence-1",
    "href": "slides/prob/20-intro-to-prob.html#independence-1",
    "title": "Introduction to Probability",
    "section": "Independence",
    "text": "Independence\n\nBy detault, the sample function samples without replacement\n\n\nset.seed(1996)\nx &lt;- sample(beads, 5) \n\n\nIf you have to guess the color of the first bead, you will predict blue since blue has a 60% chance."
  },
  {
    "objectID": "slides/prob/20-intro-to-prob.html#independence-2",
    "href": "slides/prob/20-intro-to-prob.html#independence-2",
    "title": "Introduction to Probability",
    "section": "Independence",
    "text": "Independence\n\nHowever, if I show you the result of the last four outcomes:\n\n\nx[2:5] \n\n[1] \"blue\" \"blue\" \"red\"  \"blue\"\n\n\n\nwould you still guess blue? Of course not."
  },
  {
    "objectID": "slides/prob/20-intro-to-prob.html#conditional-probabilities",
    "href": "slides/prob/20-intro-to-prob.html#conditional-probabilities",
    "title": "Introduction to Probability",
    "section": "Conditional probabilities",
    "text": "Conditional probabilities\n\nWhen events are not independent, conditional probabilities are useful.\nWe use the \\(|\\) to shorten conditional on. For example:\n\n\\[\n\\mbox{Pr}(\\mbox{Card 2 is a king} \\mid \\mbox{Card 1 is a king}) = 3/51\n\\]"
  },
  {
    "objectID": "slides/prob/20-intro-to-prob.html#conditional-probabilities-1",
    "href": "slides/prob/20-intro-to-prob.html#conditional-probabilities-1",
    "title": "Introduction to Probability",
    "section": "Conditional probabilities",
    "text": "Conditional probabilities\n\nWhen two events, say \\(A\\) and \\(B\\), are independent, we have:\n\n\\[\n\\mbox{Pr}(A \\mid B) = \\mbox{Pr}(A)  \n\\]\n\nIn fact, this can be considered the mathematical definition of independence."
  },
  {
    "objectID": "slides/prob/20-intro-to-prob.html#multiplication-rule",
    "href": "slides/prob/20-intro-to-prob.html#multiplication-rule",
    "title": "Introduction to Probability",
    "section": "Multiplication rule",
    "text": "Multiplication rule\n\nIf we want to determine the probability of two events, say \\(A\\) and \\(B\\), occurring, we can use the multiplication rule:\n\n\\[\n\\mbox{Pr}(A \\cup B) = \\mbox{Pr}(A)\\mbox{Pr}(B \\mid A)\n\\]"
  },
  {
    "objectID": "slides/prob/20-intro-to-prob.html#multiplication-rule-1",
    "href": "slides/prob/20-intro-to-prob.html#multiplication-rule-1",
    "title": "Introduction to Probability",
    "section": "Multiplication rule",
    "text": "Multiplication rule\n\nFor example:\n\n\\[\n\\mbox{Pr}(\\mbox{Blackjack in first hand}) = \\\\\n\\mbox{Pr}(\\mbox{Ace first})\\mbox{Pr}(\\mbox{Face card second}\\mid \\mbox{Ace first}) +\\\\\n\\mbox{Pr}(\\mbox{Face card first})\\mbox{Pr}(\\mbox{Ace}\\mid \\mbox{Face card second}) =\\\\\n\\frac{1}{13}\\frac{16}{51} + \\frac{4}{13}\\frac{4}{51} \\approx 0.0483\n\\]"
  },
  {
    "objectID": "slides/prob/20-intro-to-prob.html#multiplication-rule-2",
    "href": "slides/prob/20-intro-to-prob.html#multiplication-rule-2",
    "title": "Introduction to Probability",
    "section": "Multiplication rule",
    "text": "Multiplication rule\n\nWe can use induction to expand for more events:\n\n\\[\n\\mbox{Pr}(A \\cup B \\cup C) = \\mbox{Pr}(A)\\mbox{Pr}(B \\mid A)\\mbox{Pr}(C \\mid A \\cup B)\n\\]"
  },
  {
    "objectID": "slides/prob/20-intro-to-prob.html#multiplication-rule-3",
    "href": "slides/prob/20-intro-to-prob.html#multiplication-rule-3",
    "title": "Introduction to Probability",
    "section": "Multiplication rule",
    "text": "Multiplication rule\n\nWhen dealing with independent events, the multiplication rule becomes simpler:\n\n\\[\n\\mbox{Pr}(A \\cup B \\cup C) = \\mbox{Pr}(A)\\mbox{Pr}(B)\\mbox{Pr}(C)\n\\]\n\nHowever, we have to be very careful before using this version of the multiplication rule, since assuming independence can result in very different and incorrect probability calculations when events are not actually independent."
  },
  {
    "objectID": "slides/prob/20-intro-to-prob.html#multiplication-rule-example",
    "href": "slides/prob/20-intro-to-prob.html#multiplication-rule-example",
    "title": "Introduction to Probability",
    "section": "Multiplication rule example",
    "text": "Multiplication rule example\n\nImagine a court case in which the suspect was described as having a mustache and a beard.\nThe defendant has both and an “expert” testifies that 1/10 men have beards and 1/5 have mustaches.\nUsing the multiplication rule, he concludes that \\(1/10 \\times 1/5\\) or 0.02 have both.\nBut this assumes independence!\nIf the conditional probability of a man having a mustache, conditional on him having a beard, is .95, then the probability is: \\(1/10 \\times 95/100 = 0.095\\)"
  },
  {
    "objectID": "slides/prob/20-intro-to-prob.html#multiplication-rule-under",
    "href": "slides/prob/20-intro-to-prob.html#multiplication-rule-under",
    "title": "Introduction to Probability",
    "section": "Multiplication rule under",
    "text": "Multiplication rule under\n\nThe multiplication rule also gives us a general formula for computing conditional probabilities:\n\n\\[\n\\mbox{Pr}(B \\mid A) = \\frac{\\mbox{Pr}(A \\cup B)}{ \\mbox{Pr}(A)}\n\\]"
  },
  {
    "objectID": "slides/prob/20-intro-to-prob.html#addition-rule",
    "href": "slides/prob/20-intro-to-prob.html#addition-rule",
    "title": "Introduction to Probability",
    "section": "Addition rule",
    "text": "Addition rule\n\nThe addition rule tells us that:\n\n\\[\n\\mbox{Pr}(A \\cap B) = \\mbox{Pr}(A) + \\mbox{Pr}(B) - \\mbox{Pr}(A \\cup B)\n\\]"
  },
  {
    "objectID": "slides/prob/20-intro-to-prob.html#random-variables",
    "href": "slides/prob/20-intro-to-prob.html#random-variables",
    "title": "Introduction to Probability",
    "section": "Random Variables",
    "text": "Random Variables\n\nRandom variables are numeric outcomes resulting from random processes.\nWe can easily generate random variables using the simple examples we have shown.\nFor example, define X to be 1 if a bead is blue and red otherwise:\n\n\nbeads &lt;- rep( c(\"red\", \"blue\"), times = c(2,3))\nx &lt;- ifelse(sample(beads, 1) == \"blue\", 1, 0)"
  },
  {
    "objectID": "slides/prob/20-intro-to-prob.html#random-variables-1",
    "href": "slides/prob/20-intro-to-prob.html#random-variables-1",
    "title": "Introduction to Probability",
    "section": "Random Variables",
    "text": "Random Variables\n\nHere X is a random variable, changing randomly each time we select a new bead. Sometimes it’s 1 and sometimes it’s 0.\n\n\nifelse(sample(beads, 1) == \"blue\", 1, 0)\n\n[1] 0\n\nifelse(sample(beads, 1) == \"blue\", 1, 0)\n\n[1] 1\n\nifelse(sample(beads, 1) == \"blue\", 1, 0)\n\n[1] 0"
  },
  {
    "objectID": "slides/prob/20-intro-to-prob.html#random-variables-2",
    "href": "slides/prob/20-intro-to-prob.html#random-variables-2",
    "title": "Introduction to Probability",
    "section": "Random Variables",
    "text": "Random Variables\n\nMore interesting random variables are:\n\nthe number of times we win in a game of chance,\nthe number of democrats in a random sample of 1,000 voters, and\nthe proportion of patients randomly assigned to a control group in drug trial."
  },
  {
    "objectID": "slides/prob/20-intro-to-prob.html#discrete-probability",
    "href": "slides/prob/20-intro-to-prob.html#discrete-probability",
    "title": "Introduction to Probability",
    "section": "Discrete probability",
    "text": "Discrete probability\nIf I have 2 red beads and 3 blue beads inside an urn and I pick one at random, what is the probability of picking a red one? Our intuition tells us that the answer is 2/5 or 40%."
  },
  {
    "objectID": "slides/prob/20-intro-to-prob.html#discrete-probability-1",
    "href": "slides/prob/20-intro-to-prob.html#discrete-probability-1",
    "title": "Introduction to Probability",
    "section": "Discrete probability",
    "text": "Discrete probability\n\nA precise definition can be given by noting that there are five possible outcomes, of which two satisfy the condition necessary for the event pick a red bead.\nSince each of the five outcomes has an equal chance of occurring, we conclude that the probability is .4 for red and .6 for blue."
  },
  {
    "objectID": "slides/prob/20-intro-to-prob.html#discrete-probability-2",
    "href": "slides/prob/20-intro-to-prob.html#discrete-probability-2",
    "title": "Introduction to Probability",
    "section": "Discrete probability",
    "text": "Discrete probability\n\nA more tangible way to think about the probability of an event is as the proportion of times the event occurs when we repeat the experiment an infinite number of times, independently, and under the same conditions.\nThis is the frequentist way of thinking about probability."
  },
  {
    "objectID": "slides/prob/20-intro-to-prob.html#monte-carlo",
    "href": "slides/prob/20-intro-to-prob.html#monte-carlo",
    "title": "Introduction to Probability",
    "section": "Monte Carlo",
    "text": "Monte Carlo\n\nMonte Carlo simulations use computers to perform these experiments.\nRandom number generators permit us to mimic the process of picking at random.\nThe sample function in R uses a random number generator:\n\n\nbeads &lt;- rep(c(\"red\", \"blue\"), times = c(2,3))\nsample(beads, 1)\n\n[1] \"blue\""
  },
  {
    "objectID": "slides/prob/20-intro-to-prob.html#monte-carlo-1",
    "href": "slides/prob/20-intro-to-prob.html#monte-carlo-1",
    "title": "Introduction to Probability",
    "section": "Monte Carlo",
    "text": "Monte Carlo\n\nIf we repeat the experiment over and over, we can define the probability using the frequentists definition\n\n\nn &lt;- 10^7\nx &lt;- sample(beads, n, replace = TRUE)\ntable(x)/n\n\nx\n     blue       red \n0.6002232 0.3997768 \n\n\n\nNote the definition is for \\(n=\\infty\\). In practice we use very large numbers tp get very close."
  },
  {
    "objectID": "slides/prob/20-intro-to-prob.html#probability-distributions",
    "href": "slides/prob/20-intro-to-prob.html#probability-distributions",
    "title": "Introduction to Probability",
    "section": "Probability distributions",
    "text": "Probability distributions\nAn example of a probability distribution is:\n\n\n\nPr(picking a Republican)\n=\n0.44\n\n\nPr(picking a Democrat)\n=\n0.44\n\n\nPr(picking an undecided)\n=\n0.10\n\n\nPr(picking a Green)\n=\n0.02"
  },
  {
    "objectID": "slides/prob/20-intro-to-prob.html#setting-the-random-seed",
    "href": "slides/prob/20-intro-to-prob.html#setting-the-random-seed",
    "title": "Introduction to Probability",
    "section": "Setting the random seed",
    "text": "Setting the random seed\n\nBefore we continue, we will briefly explain the function set.seed\n\n\nset.seed(2020-10-13)  \n\n\nWhen using random number generators you get a different answer each time.\nThis is fine, but if you want to ensure that results are consistent with each run, you can set R’s random number generation seed to a specific number."
  },
  {
    "objectID": "slides/prob/20-intro-to-prob.html#combinations-and-permutations",
    "href": "slides/prob/20-intro-to-prob.html#combinations-and-permutations",
    "title": "Introduction to Probability",
    "section": "Combinations and permutations",
    "text": "Combinations and permutations\n\nBeing able to count combinations and permutations is an important part of performing discrete probability computations.\nWe will not cover this but you should know the function expand.grid\nand the gtools functions permutatios and combinations."
  },
  {
    "objectID": "slides/prob/20-intro-to-prob.html#combinations-and-permutations-1",
    "href": "slides/prob/20-intro-to-prob.html#combinations-and-permutations-1",
    "title": "Introduction to Probability",
    "section": "Combinations and permutations",
    "text": "Combinations and permutations\n\nHere is how we generate a deck of cards:\n\n\nsuits &lt;- c(\"Diamonds\", \"Clubs\", \"Hearts\", \"Spades\") \nnumbers &lt;- c(\"Ace\", \"Deuce\", \"Three\", \"Four\", \"Five\", \"Six\", \"Seven\",  \n             \"Eight\", \"Nine\", \"Ten\", \"Jack\", \"Queen\", \"King\") \ndeck &lt;- expand.grid(number = numbers, suit = suits) \ndeck &lt;- paste(deck$number, deck$suit)"
  },
  {
    "objectID": "slides/prob/20-intro-to-prob.html#combinations-and-permutations-2",
    "href": "slides/prob/20-intro-to-prob.html#combinations-and-permutations-2",
    "title": "Introduction to Probability",
    "section": "Combinations and permutations",
    "text": "Combinations and permutations\n\nHere are all the ways we can choose two numbers from a list consisting of 1,2,3:\n\n\nlibrary(gtools) \npermutations(3, 2) \n\n     [,1] [,2]\n[1,]    1    2\n[2,]    1    3\n[3,]    2    1\n[4,]    2    3\n[5,]    3    1\n[6,]    3    2\n\n\n\nThe order matters here: 3,1 is different than 1,3.\n(1,1), (2,2), and (3,3) do not appear because once we pick a number, it can’t appear again."
  },
  {
    "objectID": "slides/prob/20-intro-to-prob.html#combinations-and-permutations-3",
    "href": "slides/prob/20-intro-to-prob.html#combinations-and-permutations-3",
    "title": "Introduction to Probability",
    "section": "Combinations and permutations",
    "text": "Combinations and permutations\n\nTo compute all possible ways we can choose two cards when the order matters, we type, you can use the v option:\n\n\nhands &lt;- permutations(52, 2, v = deck)"
  },
  {
    "objectID": "slides/prob/20-intro-to-prob.html#combinations-and-permutations-4",
    "href": "slides/prob/20-intro-to-prob.html#combinations-and-permutations-4",
    "title": "Introduction to Probability",
    "section": "Combinations and permutations",
    "text": "Combinations and permutations\n\nWhat about if the order does not matter? For example, in Blackjack, if you obtain an Ace and a face card in the first draw, it is called a Natural 21, and you win automatically.\nIf we wanted to compute the probability of this happening, we would enumerate the combinations, not the permutations, since the order does not matter.\n\n\ncombinations(3,2) \n\n     [,1] [,2]\n[1,]    1    2\n[2,]    1    3\n[3,]    2    3"
  },
  {
    "objectID": "slides/prob/20-intro-to-prob.html#infinity-in-practice",
    "href": "slides/prob/20-intro-to-prob.html#infinity-in-practice",
    "title": "Introduction to Probability",
    "section": "Infinity in practice",
    "text": "Infinity in practice\n\nThe theory described here requires repeating experiments over and over indefinitely.\nIn practice, we can’t do this.\nIn the problem set you will be asked to explore how we implement asymptotic theory in practice."
  },
  {
    "objectID": "slides/prob/20-intro-to-prob.html#continuous-probability",
    "href": "slides/prob/20-intro-to-prob.html#continuous-probability",
    "title": "Introduction to Probability",
    "section": "Continuous probability",
    "text": "Continuous probability\n\nWhen summarizing a list of numeric values, such as heights, it is not useful to construct a distribution that defines a proportion to each possible outcome.\nSimilarly, for a random variable that can take any value in a continuous set, it impossible to assign a positive probabilities to the infinite number of possible values.\nHere, we outline the mathematical definitions of distributions for continuous random variables and useful approximations frequently employed in data analysis."
  },
  {
    "objectID": "slides/prob/20-intro-to-prob.html#cdf",
    "href": "slides/prob/20-intro-to-prob.html#cdf",
    "title": "Introduction to Probability",
    "section": "CDF",
    "text": "CDF\n\nWe used the heights of adult male students as an example:\n\n\nlibrary(tidyverse) \nlibrary(dslabs) \nx &lt;- heights %&gt;% filter(sex == \"Male\") %&gt;% pull(height) \n\n\nand defined the empirical cumulative distribution function (eCDF) as.\n\n\nF &lt;- function(a) mean(x &lt;= a) \n\n\nwhich, for any value a, gives the proportion of values in the list x that are smaller or equal than a."
  },
  {
    "objectID": "slides/prob/20-intro-to-prob.html#cdf-1",
    "href": "slides/prob/20-intro-to-prob.html#cdf-1",
    "title": "Introduction to Probability",
    "section": "CDF",
    "text": "CDF\n\nThere is a connection to the empirical CDF.\nIf I randomly pick one of the male students, what is the chance that he is taller than 70.5 inches?\nSince every student has the same chance of being picked, the answer is the proportion of students that are taller than 70.5 inches."
  },
  {
    "objectID": "slides/prob/20-intro-to-prob.html#cdf-2",
    "href": "slides/prob/20-intro-to-prob.html#cdf-2",
    "title": "Introduction to Probability",
    "section": "CDF",
    "text": "CDF\n\nUsing the eCDF we obtain an answer by typing:\n\n\n1 - F(70) \n\n[1] 0.3768473\n\n\n\nThe CDF is a version of the eCDF that assigns theoretical probabilities for each \\(a\\) rather than proportions computed from data."
  },
  {
    "objectID": "slides/prob/20-intro-to-prob.html#cdf-3",
    "href": "slides/prob/20-intro-to-prob.html#cdf-3",
    "title": "Introduction to Probability",
    "section": "CDF",
    "text": "CDF\n\nAlthough, as we just demonstrated, proportions computed from data can be used to define probabilities for a random variable.\nSpecifically, the CDF for a random outcome \\(X\\) defines, for any number \\(a\\), the probability of observing a value larger than \\(a\\).\n\n\\[ F(a) = \\mbox{Pr}(X \\leq a) \\]\n\nOnce a CDF is defined, we can use it to compute the probability of any subset of values."
  },
  {
    "objectID": "slides/prob/20-intro-to-prob.html#cdf-4",
    "href": "slides/prob/20-intro-to-prob.html#cdf-4",
    "title": "Introduction to Probability",
    "section": "CDF",
    "text": "CDF\n\nFor instance, the probability of a student being between height a and height b is:\n\n\\[\n\\mbox{Pr}(a &lt; X \\leq b) = F(b)-F(a)\n\\]\n\nSince we can compute the probability for any possible event using this approach, the CDF defines the probability distribution."
  },
  {
    "objectID": "slides/prob/20-intro-to-prob.html#probability-density-function",
    "href": "slides/prob/20-intro-to-prob.html#probability-density-function",
    "title": "Introduction to Probability",
    "section": "Probability density function",
    "text": "Probability density function\n\nA mathematical result that is very useful in practice is that, for most CDFs, we can define a function, call it \\(f(x)\\), that permits us to construct the CDF using Calculus, like this:\n\n\\[\nF(b) - F(a) = \\int_a^b f(x)\\,dx\n\\]\n\n\\(f(x)\\) is referred to as the probability density function."
  },
  {
    "objectID": "slides/prob/20-intro-to-prob.html#probability-density-function-1",
    "href": "slides/prob/20-intro-to-prob.html#probability-density-function-1",
    "title": "Introduction to Probability",
    "section": "Probability density function",
    "text": "Probability density function\n\nThe intuition is that even for continuous outcomes we can define tiny intervals, that are almost as small as points, that have positive probabilities.\nIf we think of the size of these intervals as the base of a rectangle, the probability density function \\(f\\) determines the height of the rectangle so that the summing up of the area of these rectangles approximate the probability \\(F(b) - F(a)\\)."
  },
  {
    "objectID": "slides/prob/20-intro-to-prob.html#probability-density-function-2",
    "href": "slides/prob/20-intro-to-prob.html#probability-density-function-2",
    "title": "Introduction to Probability",
    "section": "Probability density function",
    "text": "Probability density function\n\nThis sum can be written as Reimann sum that is approximated by an integral:"
  },
  {
    "objectID": "slides/prob/20-intro-to-prob.html#probability-density-function-3",
    "href": "slides/prob/20-intro-to-prob.html#probability-density-function-3",
    "title": "Introduction to Probability",
    "section": "Probability density function",
    "text": "Probability density function\n\nAn example of such a continuous distribution is the normal distribution.\nThe probability density function is given by:\n\n\\[f(x) = e^{-\\frac{1}{2}\\left( \\frac{x-m}{s} \\right)^2} \\]\n\nThe cumulative distribution for the normal distribution is defined by a mathematical formula which in R can be obtained with the function pnorm."
  },
  {
    "objectID": "slides/prob/20-intro-to-prob.html#probability-density-function-4",
    "href": "slides/prob/20-intro-to-prob.html#probability-density-function-4",
    "title": "Introduction to Probability",
    "section": "Probability density function",
    "text": "Probability density function\n\nWe say that a random quantity is normally distributed with average m and standard deviation s if its probability distribution is defined by:\n\n\nF(a) = pnorm(a, m, s)"
  },
  {
    "objectID": "slides/prob/20-intro-to-prob.html#probability-density-function-5",
    "href": "slides/prob/20-intro-to-prob.html#probability-density-function-5",
    "title": "Introduction to Probability",
    "section": "Probability density function",
    "text": "Probability density function\n\nThis is useful because, if we are willing to use the normal approximation we don’t need the entire dataset to answer questions such as: What is the probability that a randomly selected student is taller then 70 inches?\nWe just need the average height and standard deviation:\n\n\nm &lt;- mean(x) \ns &lt;- sd(x) \n1 - pnorm(70.5, m, s) \n\n[1] 0.371369"
  },
  {
    "objectID": "slides/prob/20-intro-to-prob.html#distributions-as-approximations",
    "href": "slides/prob/20-intro-to-prob.html#distributions-as-approximations",
    "title": "Introduction to Probability",
    "section": "Distributions as approximations",
    "text": "Distributions as approximations\n\nThe normal distribution is derived mathematically; we do not need data to define it.\nFor practicing data scientists, almost everything we do involves data.\nData is always, technically speaking, discrete.\nFor example, we could consider our height data categorical, with each specific height a unique category.\nThe probability distribution is defined by the proportion of students reporting each height."
  },
  {
    "objectID": "slides/prob/20-intro-to-prob.html#distributions-as-approximations-1",
    "href": "slides/prob/20-intro-to-prob.html#distributions-as-approximations-1",
    "title": "Introduction to Probability",
    "section": "Distributions as approximations",
    "text": "Distributions as approximations\n\nBelow is a plot of that probability distribution:"
  },
  {
    "objectID": "slides/prob/20-intro-to-prob.html#distributions-as-approximations-2",
    "href": "slides/prob/20-intro-to-prob.html#distributions-as-approximations-2",
    "title": "Introduction to Probability",
    "section": "Distributions as approximations",
    "text": "Distributions as approximations\n\nWhile most students rounded up their heights to the nearest inch, others reported values with more precision.\nOne student reported his height to be 69.6850393700787, which is 177 centimeters.\nThe probability assigned to this height is 0.0012315 or 1 in 812."
  },
  {
    "objectID": "slides/prob/20-intro-to-prob.html#distributions-as-approximations-3",
    "href": "slides/prob/20-intro-to-prob.html#distributions-as-approximations-3",
    "title": "Introduction to Probability",
    "section": "Distributions as approximations",
    "text": "Distributions as approximations\n\nThe probability for 70 inches is much higher at 0.1059113,\nDoes it really make sense to think of the probability of being exactly 70 inches as being different than 69.6850393700787?"
  },
  {
    "objectID": "slides/prob/20-intro-to-prob.html#distributions-as-approximations-4",
    "href": "slides/prob/20-intro-to-prob.html#distributions-as-approximations-4",
    "title": "Introduction to Probability",
    "section": "Distributions as approximations",
    "text": "Distributions as approximations\n\nClearly it is much more useful for data analytic purposes to treat this outcome as a continuous numeric variable, keeping in mind that very few people, or perhaps none, are exactly 70 inches, and that the reason we get more values at 70 is because people round to the nearest inch."
  },
  {
    "objectID": "slides/prob/20-intro-to-prob.html#distributions-as-approximations-5",
    "href": "slides/prob/20-intro-to-prob.html#distributions-as-approximations-5",
    "title": "Introduction to Probability",
    "section": "Distributions as approximations",
    "text": "Distributions as approximations\n\nWith continuous distributions, the probability of a singular value is not even defined.\nFor instance, it does not make sense to ask what is the probability that a normally distributed value is 70.\nInstead, we define probabilities for intervals."
  },
  {
    "objectID": "slides/prob/20-intro-to-prob.html#distributions-as-approximations-6",
    "href": "slides/prob/20-intro-to-prob.html#distributions-as-approximations-6",
    "title": "Introduction to Probability",
    "section": "Distributions as approximations",
    "text": "Distributions as approximations\n\nWe therefore could ask, what is the probability that someone is between 69.5 and 70.5?\nIn cases like height, in which the data is rounded, the normal approximation is particularly useful if we deal with intervals that include exactly one round number."
  },
  {
    "objectID": "slides/prob/20-intro-to-prob.html#distributions-as-approximations-7",
    "href": "slides/prob/20-intro-to-prob.html#distributions-as-approximations-7",
    "title": "Introduction to Probability",
    "section": "Distributions as approximations",
    "text": "Distributions as approximations\n\nFor example, the normal distribution is useful for approximating the proportion of students reporting values in intervals like the following three:\n\n\nmean(x &lt;= 68.5) - mean(x &lt;= 67.5) \n\n[1] 0.114532\n\nmean(x &lt;= 69.5) - mean(x &lt;= 68.5) \n\n[1] 0.1194581\n\nmean(x &lt;= 70.5) - mean(x &lt;= 69.5) \n\n[1] 0.1219212"
  },
  {
    "objectID": "slides/prob/20-intro-to-prob.html#distributions-as-approximations-8",
    "href": "slides/prob/20-intro-to-prob.html#distributions-as-approximations-8",
    "title": "Introduction to Probability",
    "section": "Distributions as approximations",
    "text": "Distributions as approximations\n\nNote how close we get with the normal approximation:\n\n\npnorm(68.5, m, s) - pnorm(67.5, m, s)  \n\n[1] 0.1031077\n\npnorm(69.5, m, s) - pnorm(68.5, m, s)  \n\n[1] 0.1097121\n\npnorm(70.5, m, s) - pnorm(69.5, m, s)  \n\n[1] 0.1081743\n\n\n\nHowever, the approximation is not as useful for other intervals."
  },
  {
    "objectID": "slides/prob/20-intro-to-prob.html#distributions-as-approximations-9",
    "href": "slides/prob/20-intro-to-prob.html#distributions-as-approximations-9",
    "title": "Introduction to Probability",
    "section": "Distributions as approximations",
    "text": "Distributions as approximations\n\nFor instance, notice how the approximation breaks down when we try to estimate:\n\n\nmean(x &lt;= 70.9) - mean(x &lt;= 70.1) \n\n[1] 0.02216749\n\n\n\nwith:\n\n\npnorm(70.9, m, s) - pnorm(70.1, m, s) \n\n[1] 0.08359562"
  },
  {
    "objectID": "slides/prob/20-intro-to-prob.html#distributions-as-approximations-10",
    "href": "slides/prob/20-intro-to-prob.html#distributions-as-approximations-10",
    "title": "Introduction to Probability",
    "section": "Distributions as approximations",
    "text": "Distributions as approximations\n\nIn general, we call this situation discretization.\nAlthough the true height distribution is continuous, the reported heights tend to be more common at discrete values, in this case, due to rounding.\nAs long as we are aware of how to deal with this reality, the normal approximation can still be a very useful tool."
  },
  {
    "objectID": "slides/prob/20-intro-to-prob.html#the-probability-density",
    "href": "slides/prob/20-intro-to-prob.html#the-probability-density",
    "title": "Introduction to Probability",
    "section": "The probability density",
    "text": "The probability density\n\nFor categorical distributions, we can define the probability of a category.\nFor example, a roll of a die, let’s call it \\(X\\), can be 1, 2, 3, 4, 5 or 6.\nThe probability of 4 is defined as:\n\n\\[\n\\mbox{Pr}(X=4) = 1/6\n\\]"
  },
  {
    "objectID": "slides/prob/20-intro-to-prob.html#the-probability-density-1",
    "href": "slides/prob/20-intro-to-prob.html#the-probability-density-1",
    "title": "Introduction to Probability",
    "section": "The probability density",
    "text": "The probability density\n\nThe CDF can then easily be defined:\n\n\\[\nF(4) = \\mbox{Pr}(X\\leq 4) =  \\mbox{Pr}(X = 4) +  \\mbox{Pr}(X = 3) +  \\mbox{Pr}(X = 2) +  \\mbox{Pr}(X = 1)  \n\\]"
  },
  {
    "objectID": "slides/prob/20-intro-to-prob.html#the-probability-density-2",
    "href": "slides/prob/20-intro-to-prob.html#the-probability-density-2",
    "title": "Introduction to Probability",
    "section": "The probability density",
    "text": "The probability density\n\nAlthough for continuous distributions the probability of a single value \\(\\mbox{Pr}(X=x)\\) is not defined, there is a theoretical definition that has a similar interpretation.\nThe probability density at \\(x\\) is defined as the function \\(f(a)\\) such that:\n\n\\[\nF(a) = \\mbox{Pr}(X\\leq a) = \\int_{-\\infty}^a f(x)\\, dx\n\\]"
  },
  {
    "objectID": "slides/prob/20-intro-to-prob.html#the-probability-density-3",
    "href": "slides/prob/20-intro-to-prob.html#the-probability-density-3",
    "title": "Introduction to Probability",
    "section": "The probability density",
    "text": "The probability density\n\nFor those that know calculus, remember that the integral is related to a sum: it is the sum of bars with widths approximating 0.\nIf you don’t know calculus, you can think of \\(f(x)\\) as a curve for which the area under that curve, up to the value \\(a\\), gives you the probability \\(\\mbox{Pr}(X\\leq a)\\)."
  },
  {
    "objectID": "slides/prob/20-intro-to-prob.html#the-probability-density-4",
    "href": "slides/prob/20-intro-to-prob.html#the-probability-density-4",
    "title": "Introduction to Probability",
    "section": "The probability density",
    "text": "The probability density\n\nFor example, to use the normal approximation to estimate the probability of someone being taller than 76 inches, we use:\n\n\n1 - pnorm(76, m, s) \n\n[1] 0.03206008"
  },
  {
    "objectID": "slides/prob/20-intro-to-prob.html#the-probability-density-5",
    "href": "slides/prob/20-intro-to-prob.html#the-probability-density-5",
    "title": "Introduction to Probability",
    "section": "The probability density",
    "text": "The probability density\n\nwhich mathematically is the grey area:"
  },
  {
    "objectID": "slides/prob/20-intro-to-prob.html#the-probability-density-6",
    "href": "slides/prob/20-intro-to-prob.html#the-probability-density-6",
    "title": "Introduction to Probability",
    "section": "The probability density",
    "text": "The probability density\n\nThe curve you see is the probability density for the normal distribution.\nIn R, we get this using the function dnorm.\nWhile it may not be immediately apparent why knowing about probability densities is useful, understanding this concept is essential for individuals aiming to fit models to data for which predefined functions are not available."
  },
  {
    "objectID": "slides/prob/20-intro-to-prob.html#monte-carlo-2",
    "href": "slides/prob/20-intro-to-prob.html#monte-carlo-2",
    "title": "Introduction to Probability",
    "section": "Monte Carlo",
    "text": "Monte Carlo\n\nR provides functions to generate normally distributed outcomes.\nSpecifically, the rnorm function takes three arguments: size, average (defaults to 0), and standard deviation (defaults to 1), and produces random numbers."
  },
  {
    "objectID": "slides/prob/20-intro-to-prob.html#monte-carlo-3",
    "href": "slides/prob/20-intro-to-prob.html#monte-carlo-3",
    "title": "Introduction to Probability",
    "section": "Monte Carlo",
    "text": "Monte Carlo\n\nHere is an example of how we could generate data that looks like our reported heights:\n\n\nn &lt;- length(x) \nm &lt;- mean(x) \ns &lt;- sd(x) \nsimulated_heights &lt;- rnorm(n, m, s)"
  },
  {
    "objectID": "slides/prob/20-intro-to-prob.html#monte-carlo-4",
    "href": "slides/prob/20-intro-to-prob.html#monte-carlo-4",
    "title": "Introduction to Probability",
    "section": "Monte Carlo",
    "text": "Monte Carlo\n\nNot surprisingly, the distribution looks normal:"
  },
  {
    "objectID": "slides/prob/20-intro-to-prob.html#monte-carlo-5",
    "href": "slides/prob/20-intro-to-prob.html#monte-carlo-5",
    "title": "Introduction to Probability",
    "section": "Monte Carlo",
    "text": "Monte Carlo\n\nThis is one of the most useful functions in R, as it will permit us to generate data that mimics natural events and answers questions related to what could happen by chance by running Monte Carlo simulations.\nIf, for example, we pick 800 males at random, what is the distribution of the tallest person? How rare is a seven-footer in a group of 800 males? The following Monte Carlo simulation helps us answer that question:"
  },
  {
    "objectID": "slides/prob/20-intro-to-prob.html#monte-carlo-6",
    "href": "slides/prob/20-intro-to-prob.html#monte-carlo-6",
    "title": "Introduction to Probability",
    "section": "Monte Carlo",
    "text": "Monte Carlo\n\nB &lt;- 10000 \ntallest &lt;- replicate(B, { \n  simulated_data &lt;- rnorm(800, m, s) \n  max(simulated_data) \n})"
  },
  {
    "objectID": "slides/prob/20-intro-to-prob.html#monte-carlo-7",
    "href": "slides/prob/20-intro-to-prob.html#monte-carlo-7",
    "title": "Introduction to Probability",
    "section": "Monte Carlo",
    "text": "Monte Carlo\n\nHaving a seven-footer is quite rare:\n\n\nmean(tallest &gt;= 7*12) \n\n[1] 0.0195"
  },
  {
    "objectID": "slides/prob/20-intro-to-prob.html#monte-carlo-8",
    "href": "slides/prob/20-intro-to-prob.html#monte-carlo-8",
    "title": "Introduction to Probability",
    "section": "Monte Carlo",
    "text": "Monte Carlo\n\nHere is the resulting distribution:\n\n\n\nNote that it does not look normal."
  },
  {
    "objectID": "slides/prob/20-intro-to-prob.html#continuous-distributions",
    "href": "slides/prob/20-intro-to-prob.html#continuous-distributions",
    "title": "Introduction to Probability",
    "section": "Continuous distributions",
    "text": "Continuous distributions\n\nThe normal distribution is not the only useful theoretical distribution.\nOther continuous distributions that we may encounter are the student-t, Chi-square, exponential, gamma, beta, and beta-binomial.\nR provides functions to compute the density, the quantiles, the cumulative distribution functions and to generate Monte Carlo simulations.\nR uses a convention that lets us remember the names, namely using the letters d, q, p, and r in front of a shorthand for the distribution."
  },
  {
    "objectID": "slides/prob/20-intro-to-prob.html#continuous-distributions-1",
    "href": "slides/prob/20-intro-to-prob.html#continuous-distributions-1",
    "title": "Introduction to Probability",
    "section": "Continuous distributions",
    "text": "Continuous distributions\n\nWe have already seen the functions dnorm, pnorm, and rnorm for the normal distribution.\nThe functions qnorm gives us the quantiles.\nWe can therefore draw a distribution like this:"
  },
  {
    "objectID": "slides/prob/20-intro-to-prob.html#continuous-distributions-2",
    "href": "slides/prob/20-intro-to-prob.html#continuous-distributions-2",
    "title": "Introduction to Probability",
    "section": "Continuous distributions",
    "text": "Continuous distributions\n\nx &lt;- seq(-4, 4, length.out = 100) \nqplot(x, f, geom = \"line\", data = data.frame(x, f = dnorm(x)))"
  },
  {
    "objectID": "slides/dataviz/18-distributions.html#visualizing-data-distributions",
    "href": "slides/dataviz/18-distributions.html#visualizing-data-distributions",
    "title": "Distributions",
    "section": "Visualizing data distributions",
    "text": "Visualizing data distributions\n\nSummarizing complex datasets is crucial in data analysis, allowing us to share insights drawn from the data more effectively.\nOne common method is to use the average value to summarize a list of numbers.\nFor instance, a high school’s quality might be represented by the average score in a standardized test.\nSometimes, an additional value, the standard deviation, is added."
  },
  {
    "objectID": "slides/dataviz/18-distributions.html#visualizing-data-distributions-1",
    "href": "slides/dataviz/18-distributions.html#visualizing-data-distributions-1",
    "title": "Distributions",
    "section": "Visualizing data distributions",
    "text": "Visualizing data distributions\n\nSo, a report might say the scores were 680 \\(\\pm\\) 50, boiling down a full set of scores to just two numbers.\nBut is this enough? Are we overlooking crucial information by relying solely on these summaries instead of the complete data?\nOur first data visualization building block is learning to summarize lists of numbers or categories.\nMore often than not, the best way to share or explore these summaries is through data visualization."
  },
  {
    "objectID": "slides/dataviz/18-distributions.html#visualizing-data-distributions-2",
    "href": "slides/dataviz/18-distributions.html#visualizing-data-distributions-2",
    "title": "Distributions",
    "section": "Visualizing data distributions",
    "text": "Visualizing data distributions\n\nThe most basic statistical summary of a list of objects or numbers is its distribution.\nOnce a data has been summarized as a distribution, there are several data visualization techniques to effectively relay this information.\nUnderstanding distributions is therefore essential for creating useful data visualizations.\nNote: understanding distributions is also essential for understanding inference and statistical models"
  },
  {
    "objectID": "slides/dataviz/18-distributions.html#case-study-describing-student-heights",
    "href": "slides/dataviz/18-distributions.html#case-study-describing-student-heights",
    "title": "Distributions",
    "section": "Case study: describing student heights",
    "text": "Case study: describing student heights\n\nPretend that we have to describe the heights of our classmates to someone that has never seen humans.\nWe ask students to report their height in inches.\nWe also ask them to report sex because there are two different height distributions.\n\n\n\n     sex height\n1   Male     75\n2   Male     70\n3   Male     68\n4   Male     74\n5   Male     61\n6 Female     65"
  },
  {
    "objectID": "slides/dataviz/18-distributions.html#case-study",
    "href": "slides/dataviz/18-distributions.html#case-study",
    "title": "Distributions",
    "section": "Case study",
    "text": "Case study\n\nOne way to convey the heights to ET is to simply send him this list of 1,050 heights.\nBut there are much more effective ways to convey this information, and understanding the concept of a distribution will be key.\nTo simplify the explanation, we first focus on male heights.\nWe examine the female height data later."
  },
  {
    "objectID": "slides/dataviz/18-distributions.html#distributions",
    "href": "slides/dataviz/18-distributions.html#distributions",
    "title": "Distributions",
    "section": "Distributions",
    "text": "Distributions\n\nThe most basic statistical summary of a list of objects or numbers is its distribution.\nFor example, with categorical data, the distribution simply describes the proportion of each unique category:\n\n\n\n\nFemale   Male \n 0.227  0.773"
  },
  {
    "objectID": "slides/dataviz/18-distributions.html#distributions-1",
    "href": "slides/dataviz/18-distributions.html#distributions-1",
    "title": "Distributions",
    "section": "Distributions",
    "text": "Distributions\n\nTo visualize this we simply use a barplot.\nHere is an example with US state regions:"
  },
  {
    "objectID": "slides/dataviz/18-distributions.html#histograms",
    "href": "slides/dataviz/18-distributions.html#histograms",
    "title": "Distributions",
    "section": "Histograms",
    "text": "Histograms\n\nWhen the data is numerical, the task of displaying distributions is more challenging.\nWhen data is not categorical, reporting the frequency of each entry, as we did for categorical data, is not an effective summary since most entries are unique.\nFor example, in our case study, while several students reported a height of 68 inches, only one student reported a height of 68.503937007874 inches and only one student reported a height 68.8976377952756 inches."
  },
  {
    "objectID": "slides/dataviz/18-distributions.html#histograms-1",
    "href": "slides/dataviz/18-distributions.html#histograms-1",
    "title": "Distributions",
    "section": "Histograms",
    "text": "Histograms\n\nA more useful way to define a distribution for numeric data is to define a function that reports the proportion of the data below \\(a\\) for all possible values of \\(a\\).\nThis function is called the empirical cumulative distribution function (eCDF), it can be plotted, and it provides a full description of the distribution of our data."
  },
  {
    "objectID": "slides/dataviz/18-distributions.html#histograms-2",
    "href": "slides/dataviz/18-distributions.html#histograms-2",
    "title": "Distributions",
    "section": "Histograms",
    "text": "Histograms\n\nHere is the eCDF for male student heights:"
  },
  {
    "objectID": "slides/dataviz/18-distributions.html#histograms-3",
    "href": "slides/dataviz/18-distributions.html#histograms-3",
    "title": "Distributions",
    "section": "Histograms",
    "text": "Histograms\n\nHowever, summarizing data by plotting the eCDF is actually not very popular in practice.\nThe main reason is that it does not easily convey characteristics of interest such as: at what value is the distribution centered? Is the distribution symmetric? What ranges contain 95% of the values?\nHistograms sacrifice just a bit of information to produce plots that are much easier to interpret."
  },
  {
    "objectID": "slides/dataviz/18-distributions.html#histograms-4",
    "href": "slides/dataviz/18-distributions.html#histograms-4",
    "title": "Distributions",
    "section": "Histograms",
    "text": "Histograms\nHere is the histogram for the height data splitting the range of values into one inch intervals: \\((49.5, 50.5]\\), \\((50.5, 51.5]\\), \\((51.5,52.5]\\), \\((52.5,53.5]\\), \\(...\\), \\((82.5,83.5]\\).\n\n\nFrom this plot one immediately learn some important properties about our data."
  },
  {
    "objectID": "slides/dataviz/18-distributions.html#smoothed-density",
    "href": "slides/dataviz/18-distributions.html#smoothed-density",
    "title": "Distributions",
    "section": "Smoothed density",
    "text": "Smoothed density\n\nSmooth density plots relay the same information as a histogram but are aesthetically more appealing:"
  },
  {
    "objectID": "slides/dataviz/18-distributions.html#smoothed-density-1",
    "href": "slides/dataviz/18-distributions.html#smoothed-density-1",
    "title": "Distributions",
    "section": "Smoothed density",
    "text": "Smoothed density\n\nIn this plot, we no longer have sharp edges at the interval boundaries and many of the local peaks have been removed.\nThe scale of the y-axis changed from counts to density. Values shown y-axis are chosen so that the area under the curve adds up to 1.\nTo fully understand smooth densities, we have to understand estimates, a concept we cover later in the course."
  },
  {
    "objectID": "slides/dataviz/18-distributions.html#smoothed-density-2",
    "href": "slides/dataviz/18-distributions.html#smoothed-density-2",
    "title": "Distributions",
    "section": "Smoothed density",
    "text": "Smoothed density\n\nHere is an example comparing male and female heights:"
  },
  {
    "objectID": "slides/dataviz/18-distributions.html#the-normal-distribution",
    "href": "slides/dataviz/18-distributions.html#the-normal-distribution",
    "title": "Distributions",
    "section": "The normal distribution",
    "text": "The normal distribution\n\nHistograms and density plots provide excellent summaries of a distribution.\nBut can we summarize even further?\nWe often see the average and standard deviation used as summary statistics\nTo understand what these summaries are and why they are so widely used, we need to understand the normal distribution."
  },
  {
    "objectID": "slides/dataviz/18-distributions.html#the-normal-distribution-1",
    "href": "slides/dataviz/18-distributions.html#the-normal-distribution-1",
    "title": "Distributions",
    "section": "The normal distribution",
    "text": "The normal distribution\n\nThe normal distribution, also known as the bell curve and as the Gaussian distribution."
  },
  {
    "objectID": "slides/dataviz/18-distributions.html#the-normal-distribution-2",
    "href": "slides/dataviz/18-distributions.html#the-normal-distribution-2",
    "title": "Distributions",
    "section": "The normal distribution",
    "text": "The normal distribution\n\nMany datasets can be approximated with normal distributions.\nThese include gambling winnings, heights, weights, blood pressure, standardized test scores, and experimental measurement errors.\nBut how can the same distribution approximate datasets with completely different ranges for values?"
  },
  {
    "objectID": "slides/dataviz/18-distributions.html#the-normal-distribution-3",
    "href": "slides/dataviz/18-distributions.html#the-normal-distribution-3",
    "title": "Distributions",
    "section": "The normal distribution",
    "text": "The normal distribution\n\nThe normal distribution can be adapted to different datasets by just adjusting two numbers, referred to as the average or mean and the standard deviation (SD).\nBecause we only need two numbers to adapt the normal distribution to a dataset implies that if our data distribution is approximated by a normal distribution, all the information needed to describe the distribution can be encoded by just two numbers.\nA normal distribution with average 0 and SD 1 is referred to as a standard normal."
  },
  {
    "objectID": "slides/dataviz/18-distributions.html#the-normal-distribution-4",
    "href": "slides/dataviz/18-distributions.html#the-normal-distribution-4",
    "title": "Distributions",
    "section": "The normal distribution",
    "text": "The normal distribution\n\nFor a list of numbers contained in a vector x:\n\n\nindex &lt;- heights$sex == \"Male\" \nx &lt;- heights$height[index] \n\n\nthe average is defined as.\n\n\nm &lt;- sum(x) / length(x) # or mean(x)\n\n\nand the SD is defined as:\n\n\ns &lt;- sqrt(sum((x - m)^2) / length(x)) # or sd(x)"
  },
  {
    "objectID": "slides/dataviz/18-distributions.html#the-normal-distribution-5",
    "href": "slides/dataviz/18-distributions.html#the-normal-distribution-5",
    "title": "Distributions",
    "section": "The normal distribution",
    "text": "The normal distribution\n\nHere is a plot of our male student height smooth density (blue) and the normal distribution (black) with mean = 69.3 and SD = 3.6:"
  },
  {
    "objectID": "slides/dataviz/18-distributions.html#boxplot",
    "href": "slides/dataviz/18-distributions.html#boxplot",
    "title": "Distributions",
    "section": "Boxplot",
    "text": "Boxplot\n\nSuppose we want to summarize the murder rate distribution."
  },
  {
    "objectID": "slides/dataviz/18-distributions.html#boxplots",
    "href": "slides/dataviz/18-distributions.html#boxplots",
    "title": "Distributions",
    "section": "Boxplots",
    "text": "Boxplots\n\nIn this case, the histogram above or a smooth density plot would serve as a relatively succinct summary.\nBut what if we want a more compact numerical summary?\nTwo summaries will not suffice here because the data is not normal."
  },
  {
    "objectID": "slides/dataviz/18-distributions.html#boxplots-1",
    "href": "slides/dataviz/18-distributions.html#boxplots-1",
    "title": "Distributions",
    "section": "Boxplots",
    "text": "Boxplots\n\nThe boxplot provides a five-number summary composed of the range (the minimum and maximum) along with the quartiles (the 25th, 50th, and 75th percentiles).\nThe R implementation of boxplots ignore outliers when computing the range and instead plot these as independent points.\nThe help file provides a specific definition of outliers."
  },
  {
    "objectID": "slides/dataviz/18-distributions.html#boxplots-2",
    "href": "slides/dataviz/18-distributions.html#boxplots-2",
    "title": "Distributions",
    "section": "Boxplots",
    "text": "Boxplots\nThe boxplot sumarizes with a box with whiskers:\n\n\n\n\n\n\n\n\n\n\n\n\nFrom just this simple plot, we know that:\n\nthe median is about 2.5,\nthat the distribution is not symmetric, and that\nthe range is 0 to 5 for the great majority of states with two exceptions."
  },
  {
    "objectID": "slides/dataviz/18-distributions.html#boxplots-3",
    "href": "slides/dataviz/18-distributions.html#boxplots-3",
    "title": "Distributions",
    "section": "Boxplots",
    "text": "Boxplots\n\nIn data analysis we often divide observations into groups based on the values of one or more variables associated with those observations.\nWe call this procedure stratification and refer to the resulting groups as strata.\nStratification is common in data visualization because we are often interested in how the distributions of variables differ across different subgroups.\nStratifying and then making boxplot is a common approach to visualizing these differences."
  },
  {
    "objectID": "slides/dataviz/18-distributions.html#case-study-continued",
    "href": "slides/dataviz/18-distributions.html#case-study-continued",
    "title": "Distributions",
    "section": "Case study continued",
    "text": "Case study continued\nHere are the heights for men and women:"
  },
  {
    "objectID": "slides/dataviz/18-distributions.html#case-study-continued-1",
    "href": "slides/dataviz/18-distributions.html#case-study-continued-1",
    "title": "Distributions",
    "section": "Case study continued",
    "text": "Case study continued\n\nThe plot immediately reveals that males are, on average, taller than females.\nHowever, exploratory plots reveal that the approximation is not as useful:"
  },
  {
    "objectID": "slides/dataviz/18-distributions.html#case-study-continued-2",
    "href": "slides/dataviz/18-distributions.html#case-study-continued-2",
    "title": "Distributions",
    "section": "Case study continued",
    "text": "Case study continued\n\nA likely for the second bump is that female as the default in the reporting tool.\nThe unexpected five smallest values are likely cases of 5'x'' reported as 5x\n\n\n\n[1] 51 53 55 52 52"
  },
  {
    "objectID": "psets.html",
    "href": "psets.html",
    "title": "Problem Sets",
    "section": "",
    "text": "Topic\n\n\nDue date (at 11:59 PM)\n\n\n\n\n\n\nProblem set 1\n\n\nWed, Sep 11\n\n\n\n\nProblem set 2\n\n\nThu, Sep 19\n\n\n\n\nProblem set 3\n\n\nFri, Sep 27\n\n\n\n\nProblem set 4\n\n\nFri, Oct 04\n\n\n\n\nProblem set 5\n\n\nFri, Oct 11\n\n\n\n\nProblem set 6\n\n\nFri, Oct 25\n\n\n\n\nProblem set 7\n\n\nMon, Nov 04\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "Problem Sets"
    ]
  },
  {
    "objectID": "slides.html",
    "href": "slides.html",
    "title": "Slides",
    "section": "",
    "text": "Topic\n\n\nTitle\n\n\nDate\n\n\n\n\n\n\nFirst day\n\n\nIntroduction\n\n\nWed, Sep 04\n\n\n\n\nProductivity Tools\n\n\nUnix\n\n\nWed, Sep 04\n\n\n\n\nProductivity Tools\n\n\nRStudio\n\n\nWed, Sep 04\n\n\n\n\nProductivity Tools\n\n\nQuarto\n\n\nMon, Sep 09\n\n\n\n\nProductivity Tools\n\n\nGit and GitHub\n\n\nMon, Sep 09\n\n\n\n\nR\n\n\nR Basics\n\n\nMon, Sep 16\n\n\n\n\nR\n\n\nVectorization\n\n\nWed, Sep 18\n\n\n\n\nR\n\n\nTidyverse\n\n\nMon, Sep 23\n\n\n\n\nR\n\n\nggplot2\n\n\nMon, Sep 23\n\n\n\n\nR\n\n\nTidying data\n\n\nWed, Sep 25\n\n\n\n\nWrangling\n\n\nIntroduction to Wrangling\n\n\nMon, Sep 30\n\n\n\n\nWrangling\n\n\nImporting files\n\n\nMon, Sep 30\n\n\n\n\nWrangling\n\n\nDates And Times\n\n\nMon, Sep 30\n\n\n\n\nWrangling\n\n\nLocales\n\n\nMon, Sep 30\n\n\n\n\nWrangling\n\n\nData APIs\n\n\nMon, Sep 30\n\n\n\n\nWrangling\n\n\nWeb Scraping\n\n\nMon, Sep 30\n\n\n\n\nWrangling\n\n\nJoining Tables\n\n\nMon, Sep 30\n\n\n\n\nData Visualization\n\n\nData Visualization Principles\n\n\nWed, Aug 07\n\n\n\n\nData Visualization\n\n\nDistributions\n\n\nFri, Aug 09\n\n\n\n\nData Visualization\n\n\nDataviz In Practice\n\n\nFri, Aug 09\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "Slides"
    ]
  },
  {
    "objectID": "psets/pset-06-prob.html",
    "href": "psets/pset-06-prob.html",
    "title": "Problem set 6",
    "section": "",
    "text": "Please answer each of the exercises below. For those asking for a mathematical calculation please use LaTeX to show your work.\nImportant: Make sure that your document renders in less than 5 minutes.\n\nWrite a function called same_birthday that takes a number n as an argument, randomly generates n birthdays and returns TRUE if two or more birthdays are the same. You can assume nobody is born on February 29.\n\nHint: use the functions sample, duplicated, and any.\n\nsame_birthday &lt;- function(n){ \n  ## Your code here\n} \n\n\nSuppose you are in a classroom with 50 people. If we assume this is a randomly selected group of 50 people, what is the chance that at least two people have the same birthday? Use a Monte Carlo simulation with $B=$1,000 trials based on the function same_birthday from the previous exercises.\n\n\nB &lt;- 10^3\n## Your code here\n\n\nRedo the previous exercises for several values on n to determine at what group size do the chances become greater than 50%. Set the seed at 1997.\n\n\nset.seed(1997)\ncompute_prob &lt;- function(n, B = 10^3){ \n ## Your code here\n} \n## Your code here\n\n\nThese probabilities can be computed exactly instead of relying on Monte Carlo approximations. We use the multiplication rule:\n\n\\[\n\\mbox{Pr}(n\\mbox{ different birthdays}) = 1 \\times \\frac{364}{365}\\times\\frac{363}{365} \\dots \\frac{365-n + 1}{365}\n\\]\nPlot the probabilities you obtained using Monte Carlos as a points and the exact probabilities with a red line.\nHint: use the function prod to compute the exact probabilities.\n\nexact_prob &lt;- function(n){ \n ## Your code here\n} \n## Your code here\n\n\nNote that the points don’t quite match the red line. This is because our Monte Carlos simulation was based on only 1,000 iterations. Repeat exercise 2 but for n = 23 and try B &lt;- seq(10, 250, 5)^2 number iterations. Plot the estimated probability against sqrt(b). Describe when it starts to stabilize in that the estimates are within 0.005 for the exact probability. Add horizontal lines around the exact probability \\(\\pm\\) 0.005. Note this could take several seconds to run. Set the seed to 1998.\n\n\nset.seed(1998)\nB &lt;- seq(10, 250, 5)^2\n## Your code here\n\n\nRepeat exercise 4 but use the the results of exercise 5 to select the number of iterations so that the points practically fall on the red curve.\n\nHint: If the number of iterations you chose is too large, you will achieve the correct plot but your document might not render in less than five minutes.\n\nn &lt;- seq(1,60) \n## Your code here\n\n\nIn American Roulette, with 18 red slots, 18 black slots, and 2 green slots (0 and 00), what is the probability of landing on a green slot?\n\n\\[\n\\mbox{Derivation here}\n\\]\n\nThe payout for winning on green is $17 dollars. This means that if you bet a dollar and it lands on green, you get $17. If it lands on red or black you lose your dollar. Create a sampling model using sample to simulate the random variable \\(X\\) for the Casino’s winnings.\n\n\nn &lt;- 1\n## Your code here\n\n\nNow create a random variable \\(S\\) of the Casino’s total winnings if $n = $1,000 people bet on green. Use Monte Carlo simulation to estimate the probability that the Casino loses money.\n\n\nn &lt;- 1000\n## Your code here\n\n\nWhat is the expected value of \\(X\\)?\n\n\\[\n\\mbox{Your derivation here.}\n\\]\n\nWhat is the standard error of \\(X\\)?\n\n\\[\n\\mbox{Your derivation here.}\n\\]\n\nWhat is the expected value of \\(S\\)? Does the Monte Carlo simulation confirm this?\n\n\\[\n\\mbox{Your dereviation here}\n\\]\n\n## Your code here\n\n\nWhat is the standard error of \\(S\\)? Does the Monte Carlos simulation confirm this?\n\n\\[\n\\mbox{Your derivation here.}\n\\]\n\n## Your code here\n\n\nUse data visualization to convince yourself that the distribution of \\(S\\) is approximately normal. Make a histogram and a QQ-plot of standardized values of \\(S\\). The QQ-plot should be on the identity line.\n\n\n## Your code here\n\n\nNotice that the normal approximation is slightly off for the tails of the distribution. What would make this better? Increasing the number of people playing \\(n\\) or the number of Monte Carlo iterations \\(B\\)?\n\nAnswer here\n\nNow approximate the probability estimated using CLT. Does it agree with the Monte Carlo simulation?\n\n\\[\n\\mbox{Your derivation here.}\n\\]\n\n## Your code here\n\n\nHow many people \\(n\\) must bet on green for the Casino to reduce the probability of losing money to 1%. Check your answer with a Monte Carlo simulation.\n\n\\[\n\\mbox{Your derivation here.}\n\\]\n\n## Your code here"
  },
  {
    "objectID": "psets/pset-05-dataviz.html",
    "href": "psets/pset-05-dataviz.html",
    "title": "Problem set 5",
    "section": "",
    "text": "In this problem set, we aim to use data visualization to explore the following questions:\n\nBased on SARS-Cov-2 cases, COVID-19 deaths and hospitalizations what periods defined the worst two waves of 2020-2021?\nDid states with higher vaccination rates experience lower COVID-19 death rates?\nWere there regional differences in vaccination rates?\n\nWe are not providing definitive answers to these questions but rather generating visualizations that may offer insights.\n\n\nWe will create a single data frame that contains relevant observations for each jurisdiction, for each Morbidity and Mortality Weekly Report (MMWR) period in 2020 and 2021. The key outcomes of interest are:\n\nSARS-CoV-2 cases\nCOVID-19 hospitalizations\nCOVID-19 deaths\nIndividuals receiving their first COVID-19 vaccine dose\nIndividuals receiving a booster dose\n\n\n\n\nYour task is divided into three parts:\n\nDownload the data: Retrieve population data from the US Census API and COVID-19 statistics from the CDC API.\nWrangle the data: Clean and join the datasets to create a final table containing all the necessary information.\nCreate visualizations: Generate graphs to explore potential insights into the questions posed above."
  },
  {
    "objectID": "psets/pset-05-dataviz.html#introduction",
    "href": "psets/pset-05-dataviz.html#introduction",
    "title": "Problem set 5",
    "section": "",
    "text": "In this problem set, we aim to use data visualization to explore the following questions:\n\nBased on SARS-Cov-2 cases, COVID-19 deaths and hospitalizations what periods defined the worst two waves of 2020-2021?\nDid states with higher vaccination rates experience lower COVID-19 death rates?\nWere there regional differences in vaccination rates?\n\nWe are not providing definitive answers to these questions but rather generating visualizations that may offer insights.\n\n\nWe will create a single data frame that contains relevant observations for each jurisdiction, for each Morbidity and Mortality Weekly Report (MMWR) period in 2020 and 2021. The key outcomes of interest are:\n\nSARS-CoV-2 cases\nCOVID-19 hospitalizations\nCOVID-19 deaths\nIndividuals receiving their first COVID-19 vaccine dose\nIndividuals receiving a booster dose\n\n\n\n\nYour task is divided into three parts:\n\nDownload the data: Retrieve population data from the US Census API and COVID-19 statistics from the CDC API.\nWrangle the data: Clean and join the datasets to create a final table containing all the necessary information.\nCreate visualizations: Generate graphs to explore potential insights into the questions posed above."
  },
  {
    "objectID": "psets/pset-05-dataviz.html#instructions",
    "href": "psets/pset-05-dataviz.html#instructions",
    "title": "Problem set 5",
    "section": "Instructions",
    "text": "Instructions\n\nCreate a Git repository that includes the following directories:\n\ndata\ncode\nfigs\n\nInside the code directory, include the following files:\n\nfuncs.R\nwrangle.R\nanalysis.qmd\n\nThe figs directory should contain three PNG files, with each file corresponding to one of the figures you are asked to create.\n\nDetailed instructions follow for each of the tasks."
  },
  {
    "objectID": "psets/pset-05-dataviz.html#download-data",
    "href": "psets/pset-05-dataviz.html#download-data",
    "title": "Problem set 5",
    "section": "Download data",
    "text": "Download data\nFor this part we want the following:\n\nSave all your code in a file called wrangle.R that produces the final data frame.\nWhen executed, this code should save the final data frame in an RDA file in the data directory.\n\n\nCopy the relevant code from the previous homework to create the population data frame. Put this code in the the wrangle.R file in the code directory. Comment the code so we know where the population is create, where the regions are read in, and where we combine these.\nIn the previous problem set we wrote the following script to download cases data:\n\n\napi &lt;- \"https://data.cdc.gov/resource/pwn4-m3yp.json\"\ncases_raw &lt;- request(api) |&gt; \n  req_url_query(\"$limit\" = 10000000) |&gt;\n  req_perform() |&gt; \n  resp_body_json(simplifyVector = TRUE)\n\nWe are now going to download three other datasets from CDC that provide hospitalization, provisional COVID deaths, and vaccine data. A different endpoint is provided for each one, but the requests are the same otherwise. To avoid rewriting the same code more than once, write a function called get_cdc_data that receives and endpoint and returns a data frame. Save this code in a file called functions.R.\n\nUse the get_cdc Download the cases, hospitalization, deaths, and vaccination data and save the data frames. We recommend saving them into objects called: cases_raw, hosp_raw, deaths_raw, and vax_raw.\n\n\ncases - https://data.cdc.gov/resource/pwn4-m3yp.json\nhospitalizations - https://data.cdc.gov/resource/39z2-9zu6.json\ndeaths - https://data.cdc.gov/resource/r8kw-7aab.json\nvaccinations https://data.cdc.gov/resource/rh2h-3yt2.json\n\nWe recommend saving them into objects called: cases_raw, hosp_raw, deaths_raw, and vax_raw. Add the code to the wranling.R file. Add comments to describe we read in data here."
  },
  {
    "objectID": "psets/pset-05-dataviz.html#wrangling-challenge",
    "href": "psets/pset-05-dataviz.html#wrangling-challenge",
    "title": "Problem set 5",
    "section": "Wrangling Challenge",
    "text": "Wrangling Challenge\nIn this section, you will wrangle the files downloaded in the previous step into a single data frame containing all the necessary information. We recommend using the following column names: date, state, cases, hosp, deaths, vax, booster, and population.\n\nKey Considerations\n\nAlign reporting periods: Ensure that the time periods for which each outcome is reported are consistent. Specifically, calculate the totals for each Morbidity and Mortality Weekly Report (MMWR) period.\nHarmonize variable names: To facilitate the joining of datasets, rename variables so that they match across all datasets.\n\n\nOne challenge is data frames use different column names to represent the same variable. Examine each data frame and report back 1) the name of the column with state abbreviations, 2) if the it’s yearly, monthly, or weekly, daily data, 3) all the column names that provide date information.\n\n\n\n\nOutcome\nJurisdiction variable name\nRate\ntime variable names\n\n\n\n\ncases\n\n\n\n\n\nhospitalizations\n\n\n\n\n\ndeaths\n\n\n\n\n\nvaccines\n\n\n\n\n\n\n\nWrangle the cases data frame to keep state MMWR year, MMWR week, and the total number of cases for that week in that state. Keep only states for which we have population estimates. Hint: Use as_date, ymd_hms, epiweek and epiyear functions in the lubridate package. Comment appropriately.\nNow repeat the same exercise for hospitalizations. Note that you will have to collapse the data into weekly data and keep the same columns as in the cases dataset, except keep total weekly hospitalizations instead of cases. Remove weeks with less than 7 days reporting. Add this code to wrangle.R and comment appropriately.\nRepeat what you did in the previous two exercises for provisional COVID-19 deaths. Add this code to wrangle.R and comment appropriately.\nRepeat this now for vaccination data. Keep the variables series_complete and booster along with state and date. Add this code to wrangle.R and comment appropriately.\nNow we are ready to join the tables. We will only consider 2020 and 2021 as we don’t have population sizes for 2022. However, because we want to guarantee that all dates are included we will create a data frame with all possible weeks. Add this code to your wrangle.R file. We can use this:\n\n\n## Make dates data frame\nall_dates &lt;- data.frame(date = seq(make_date(2020, 1, 25),\n                                   make_date(2021, 12, 31), \n                                   by = \"week\")) |&gt;\n  mutate(date = ceiling_date(date, unit = \"week\", week_start = 7) - days(1)) |&gt;\n  mutate(mmwr_year = epiyear(date), mmwr_week = epiweek(date)) \n\ndates_and_pop &lt;- cross_join(all_dates, data.frame(state = unique(population$state))) |&gt; left_join(population, by = c(\"state\", \"mmwr_year\" = \"year\"))\n\nNow join all the table to create your final table. Make sure it is ordered by date within each state. Call it dat and save an RDS file to the data directory. Add this code to wrangle.R and comment appropriately."
  },
  {
    "objectID": "psets/pset-05-dataviz.html#data-visualization-generate-some-plots",
    "href": "psets/pset-05-dataviz.html#data-visualization-generate-some-plots",
    "title": "Problem set 5",
    "section": "Data visualization generate some plots",
    "text": "Data visualization generate some plots\nWe are now ready to create some figures. In the analysis.qmd file create a section for each figure. You should load the dat object stored in the RDS file in the dat directory.\nYou can call these sections Figure 1, Figure 2, and so on. Inlcude a short description of what the figure is before the code chunk. The rendered file should show both the code and figure.\n\nPlot a trend plot for cases, hospitalizations and deaths. Plot rates per \\(100,000\\) people. Place the plots on top of each other. Hint: Use pivot_longer and facet_wrap.\nTo determine when vaccination started and when most of the population was vaccinated, compute the percent of the US population (including DC and Puerto Rico) were vaccinated by date. Do the same for the booster. Then plot both percentages.\nDescribe the distribution of vaccination rates on July 1, 2021.\nIs there a difference across region? Discuss what the plot shows?\nUsing the two previous figures, identify two time periods that meet the following criteria:\n\n\nA significant COVID-19 wave occurred across the United States.\nA sufficient number of people had been vaccinated.\n\nNext, follow these steps:\n\nFor each state, calculate the COVID-19 deaths per day per 100,000 people during the selected time period.\nDetermine the vaccination rate (primary series) in each state as of the last day of the period.\nCreate a scatter plot to visualize the relationship between these two variables:\n\nThe x-axis should represent the vaccination rate.\nThe y-axis should represent the deaths per day per 100,000 people.\n\n\n\nRepeat the exercise for the booster."
  },
  {
    "objectID": "psets/pset-03-tidyverse.html",
    "href": "psets/pset-03-tidyverse.html",
    "title": "Problem set 3",
    "section": "",
    "text": "In these exercises, we will explore a subset of the NHANES dataset to investigate potential differences in systolic blood pressure across groups defined by self reported race.\n\nInstructions\n\nFor each exercise, we want you to write a single line of code using the pipe (|&gt;) to chain together multiple operations. This doesn’t mean the code must fit within 80 characters or be written on a single physical line, but rather that the entire sequence of operations can be executed as one continuous line of code without needing to assign intermediate values or create new variables.\nFor example, these are three separate lines of code:\n\n\nx &lt;- 100; x &lt;- sqrt(x); log10(x)\n\nWhereas this is considered one line of code using the pipe:\n\n100 |&gt; \n  sqrt() |&gt; \n  log10()\n\n\nGenerate an html document that shows the code for each exercise.\nFor the exercises that ask to generate a graph, show the graph as well.\nFor exercises that require you to display tabular results, use the kable function to format the output as a clean, readable table. Do not display the raw dataframe directly—only show the nicely formatted table using kable.\nUse only two significant digits for the numbers displayed in the tables.\nSubmit both the html and the qmd files using Git.\nYou will need the following libraries:\n\n\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(forcats)\nlibrary(ggplot2)\nlibrary(knitr)\nlibrary(NHANES)\noptions(digits = 2)\n\n\nThe .qmd file must be able to render properly on the TFs’ computers. They will already have the necessary packages installed, so there is no need to include code for installing packages. Just focus on writing the code that uses these packages.\n\n\n\nExercises\n\nFilter the NHANES data to only include survey year 2011-2012. Save the resulting table in dat. This table should have 5,000 rows and 76 columns.\n\n\n## code here\n\n\nCompute the average and standard deviation (SD) for the combined systolic blood pressure (SBP) reading for males and females separately. Show us a data frame with two rows (female and male) and two columns (average and SD).\n\n\n## code here\n\n\nBecause of the large difference in the average between males and females, we will perform the rest of the analysis separately for males and females.\n\nCompute the average and SD for SBP for each race variable in column Race3 for females and males separately. The resulting table should have four columns for sex, race, average, and SD, respectively, and 12 rows (one for each strata). Arrange the result from highest to lowest average.\n\n## code here\n\n\nRepeat the previous exercise but add two columns to the final table to show a 95% confidence interval. Specifically, add columns with the lower and upper bounds of the interval with names lower and upper, respectively. The formula for these values is\n\n\\[\n\\bar{X} \\pm 1.96 \\, s / \\sqrt{n}\n\\] with \\(\\bar{X}\\) the sample average and \\(s\\) the sample standard deviation. This table will simply add two more columns to the table generated in the previous exercise: one column for the lower and upper bound, respectively.\n\n## code here\n\n\nMake a graph of showing the results from the previous exercise. Specifically, plot the averages for each group as points and confidence intervals as error bars (use the geometry geom_errorbar). Order the groups from lowest to highest average (the average of the males and females averages). Use facet_wrap to make a separate plot for females and males. Label your axes with Race and Average respectively, add the title Comparing systolic blood pressure across groups, and the caption Bars represent 95% confidence intervals.\n\n\n## code here\n\n\nIn the plot above we see that the confidence intervals don’t overlap when comparing the White and Mexican groups. We also see a substantial difference between Mexican and Hispnanic. Before concluding that there is a difference between groups, we will explore if differences in age, a very common confounder, explain the differences.\n\nCreate table like the one in the previous exercise but show the average SBP by sex and age group (AgeDecade). The the groups are order chronologically. As before make a separate plot for males and females. Make sure to filter our observations with no AgeDecade listed.\n\n## code here\n\n\nWe note that for both males and females the SBP increases with age. To explore if age is indeed a confounder we need to check if the groups have different age distributions.\n\nExplore the age distributions of each Race3 group to determine if the groups are comparable. Make a histogram of Age for each Race3 group and stack them vertically. Generate two columns of graphs for males and females, respectively. In the histograms, create bins increments of 5 years up to 80.\nBelow the graph, comment on what notice about the age distributions and how this can explain the difference between the White and Mexican groups.\n\n## code here\n\n\nSummarize the results shown in the graph by compute the median age for each Race3 group and the percent of individuals that are younger than 18. Order the rows by median age. The resulting data frame should have 6 rows (one for each group) and three columns to denote group, median age, and children respectively.\n\n\n## code here\n\nGiven these results provide an explanation for the difference in systolic pressure is lower when comparing the White and Mexican groups.\n\nWhen the age distribution between two populations we can’t conclude that there are differences in SBP based just on the population averages. The observed differences are likely due to age differences rather than genetic differences. We will therefore stratify by group and then compare SBP. But before we do this, we might need redefine dat to avoid small groups.\n\nWrite a function that computes the number of observations in each gender, age group and race combination. Show the groups with less than five observations. Make sure to remove the rows with no BPSysAve measurments before calculating the number of observations. Show a table with four columns representing gender, age strate, group, and the number of individuals in that group. Make sure to include combinations with 0 individuals (hint: use complete).\n\n## code here\n\n\nBased on the observations made in the previous exercise, we will redefine dat but with the following:\n\nAs before, include only survey year 2011-2012.\nRemove the observations with no age group reported.\nRemove the 0-9 age group.\nCombine the 60-69 and 70+ ageroups into a 60+ group.\nRemove observations reporting Other in Race3.\nRename the variable Race3 to Race.\n\nHints:\n\nNote that the levels in AgeDecade start with a space.\nYou can use the fct_collapse function in the forcats to combine factors.\n\n\n\n## code here\n\n\nCrete a plot that shows the averege BPS for each age decade. Show the different race groups with color and lines joining them. Generate a two plots, one for males and one for females.\n\n\n## code here\n\n\nBased on the plot above pick two groups that you think are consistently different and remake the plot from the previous exercise but just for these two groups, add confidence intervals, and remove the lines. Put the confidence intervals for each age strata next to each other and use color to represent the two groups. Comment on your finding.\n\n\n## code here\n\n\nFor the two groups that you selected above compute the difference in average BPS between the two groups for each age strata. Show a table with three columns representing age strata, difference for females, difference for males.\n\n\n## code here"
  },
  {
    "objectID": "psets/pset-01-unix-quarto.html",
    "href": "psets/pset-01-unix-quarto.html",
    "title": "Problem set 1",
    "section": "",
    "text": "After finishing the homework, you are to turn in all the code to GitHub using git.\n\nStart an RStudio project. Pick a good name following a naming convention. Start a Quarto document called beginning.qmd.\nCreate a directory called img and save a screen shot of your RStudio session for the project. Include your screenshot in the Quarto document.\nNext, in your Quarto document, define variables \\(a=1, b=-1, c=-2\\) and print out the solutions to \\(f(x) = ax^2+bx+c=0\\). Do not report complex solutions, only real numbers.\nInclude a graph of \\(f(x)\\) versus \\(x\\) for \\(x \\in (-5,5)\\).\n\n\nx &lt;- seq(-5, 5, length = 100)\n# Hint: Use the plot function\n\n\nCreate a directory called docs. Use the command quarto render to create a PDF and save it to the docs directory. Show us the command you typed:\n\n# Your code here\n\nUse Unix to create a directory called data in the project home directory. Include the Unix command you used to create the directory.\n\n# Your code here\n\nUse a terminal-based text editor to create a file coefs.txt in the data directory and save three coefficients, 1 -1 -2 for example. Show us the Unix commands you used to achieve this:\n\n# Your code here\n\nMake a directory called code. Use Unix to copy the file beginning.qmd to a file called quadratic.qmd in the code directory. Show us the Unix commands you used.\n\n# Your code here\n\nEdit the quadratic.qmd file to read in a, b, and c from the file coefs.txt. Make sure to use a relative path when reading the file. As before, print out the solutions to \\(f(x) = ax^2+bx+c=0\\). Do not report complex solutions, only real numbers.\nChange the path of the file you are reading to the full path you get when you type file.path(getwd(), \"data/coefs.txt\"). Confirm that the file still renders. Then move the entire pset-01-rmarkdown project to a directory called RtmpyDknq4. Does the file render? Change the path back to a relative path and see if it renders."
  },
  {
    "objectID": "psets/pset-07-election.html",
    "href": "psets/pset-07-election.html",
    "title": "Problem set 7",
    "section": "",
    "text": "For this problem set we want you to predict the election. You will enter you predictions to this form. You you will report a prediction of the number of electoral votes for Harris and an interval. You will do the same for the popular vote. We will give prizes for those that report the shortest interval but with the true result inside the interval.\n\nRead in the data provided here:\n\n\nurl &lt;- \"https://projects.fivethirtyeight.com/polls/data/president_polls.csv\"\n\nExamine the data frame paying particular attention to the poll_id question_id, population, and candidate. Note that some polls have more than one question based on different population types.\n\nlibrary(tidyverse)\nlibrary(rvest)\nraw_dat &lt;- ### Your code here\n\n\nPolls are based on either likely voters (lv), registered voters (rv), all voters (a), or voters (v). Polls based on ‘voters’ are exit polls. We want to remove these because exit polls are too old or might be biased due to differences in the likelihood of early voter by party. We prefer likely voter (lv) polls because they are more predictive. Registered voter polls are more predictive than all voter (a) polls. Remove the exit poll (v) polls and then redefine population to be a factor ordered from best to worse predictive power: (lv, rv, a). You should also remove hypothetical polls and make the date columns into date objects. Name the resulting data frame dat.\n\n\ndat &lt;- raw_dat |&gt; \n  ## Your code here\n\n\nSome polls asked more than one questions. So if you filter to one poll ID in our dataset, you might see more than one question ID associated with the same poll. The most common reason for this is that they asked a head-to-head question (Harris versus Trump) and, in the same poll, a question about all candidates. We want to prioritize the head-to-head questions.\n\nAdd a column that tells us, for each question, how many candidates where mentioned in that question.\nAdd a new column n to dat that provides the number of candidates mentioned for each question. For example the relevant column of your final table will looks something like this:\n\n\n\npoll_id\nquestion_id\ncandidate\nn\n\n\n\n\n1\n1\nHarris\n2\n\n\n1\n1\nTrump\n2\n\n\n1\n2\nHarris\n3\n\n\n1\n2\nTrump\n3\n\n\n1\n2\nStein\n3\n\n\n\n\ndat &lt;- dat |&gt; \n    ## Your code here\n\n\nWe are going to focus on the Harris versus Trump comparison. Redefine dat to only include the rows providing information for Harris and Trump. Then pivot the dataset so that the percentages for Harris and Trump are in their own columns. Note that for pivot to work you will have to remove some columns. To avoid this keep only the columns you are pivoting and along with poll_id, question_id, state, pollster, start_date, end_date, numeric_grade, sample_size. Once you accomplish the pivot, add a column called spread with the difference between Harris and Trump.\n\nNote that the values stored in spread are estimates of the popular vote difference that we will use to predict for the competition:\nspread = % of the popular vote for Harris - % of the popular vote for Trump\nHowever, for the calculations in the rest of problem set to be consistent with the sampling model we have been discussing in class, save spread as a proportion, not a percentage. But remember to turn it back to a percentage when submitting your entry to the competition.\n\ndat &lt;- dat |&gt;\n  ## Your code here\n\n\nNote that some polls have multiple questions. We want to keep only one question per poll. We will keep likely voter (lv) polls when available, and prefer register voter (rv) over all voter polls (a). If more than one question was asked in one poll, take the most targeted question (smallest n). Save the resulting tabledat. Note that now each after you do this each row will represents exactly one poll/question, so can remove n, poll_id and question_id.\n\n\ndat &lt;- dat |&gt;\n  ## Your code here\n\n\nSeparate dat into two data frames: one with popular vote polls and one with state level polls. Call them popular_vote and polls respectively.\n\n\npopular_vote &lt;- ## Your code here\npolls &lt;- ## Your code here\n\n\nFor the popular vote, plot the spread reported by each poll against start date for polls starting after July 21, 2024. Rename all the pollsters with less than 5 polls during this period as Other. Use color to denote pollster. Make separate plots for likely voters and registered voters. Do not use all voter polls (a). Use geom_smooth with method loess to show a curve going through the points. You can change how adaptive the curve is to that through the span argument.\n\n\npopular_vote |&gt; \n  filter(start_date &gt; make_date(2024, 7, 21) & population != \"a\") |&gt;\n  ### Your code here\n\n\nTo show the pollster effect, make boxplots for the the spread for each popular vote poll. Include only likely voter polls starting after July 21, 2024. Rename all the pollsters with less than 5 polls during that time period as Other.\n\n\npopular_vote |&gt; \n  filter(start_date &gt; make_date(2024, 7, 21) & population == \"lv\") |&gt;\n  ## Your code here\n\n\nCompute a prediction and an interval for the competition and submit here Include the code you used to create your confidence interval for the popular vote here:\n\n\n## Your code here\n\nWe now move on to predicting the electoral votes.\n\nTo obtain the number of electoral votes for each state we will visit this website:\n\n\nurl &lt;- \"https://state.1keydata.com/state-electoral-votes.php\"\n\nWe can use the rvest package to download and extract the relevant table:\n\nlibrary(rvest)\nh &lt;- read_html(url) |&gt;\n  html_table() \n\nev &lt;- h[[4]]\n\nWrangle the data in ev to only have two columns state and electoral_votes. Make sure the electoral vote column is numeric. Add the electoral votes for Maine CD-1 (1), Maine CD-2 (1), Nebraska CD-2 (1), and District of Columbia (3) by hand.\n\n### Your code here\n\n\nThe presidential race in some states is a forgone conclusion. Because their is practically no uncertainty in who will win, polls are not taken. We will therefore assume that the party that won in 2020 will win again in 2024 if no polls are being collected for a state.\n\nDownload the following sheet:\n\nlibrary(gsheet)\nsheet_url &lt;- \"https://docs.google.com/spreadsheets/d/1D-edaVHTnZNhVU840EPUhz3Cgd7m39Urx7HM8Pq6Pus/edit?gid=29622862\"\nraw_res_2020 &lt;- gsheet2tbl(sheet_url) \n\nTidy the raw_res_2020 dataset so that you have two columns state and party, with D and R in the party column to indicate who won in 2020. Add Maine CD-1 (D), Maine CD-2 (R), Nebraska CD-2 (D), and District of Columbia (D) by hand. Save the result to res_2020. Hint use the janitor row_to_names function.\n\nlibrary(janitor)\nres_2020 &lt;- raw_res_2020[,c(1,4)] |&gt;  \n ### Your code here\n\n\nDecide on a period that you will use to compute your prediction. We will use spread as the outcome. Make sure the the outcomes is saved as a proportion not percentage. Create a results data frame with columns state, avg, sd, n and electoral_votes, with one row per state.\n\nSome ideas and recommendations:\n\nIf a state has enough polls, consider a short period, such as a week. For states with few polls you might need to increase the interval to increase the number of polls.\nDecide which polls to prioritize based on the population and numeric_grade columns.\nYou might want to weigh them differently, in which you might also consider using sample_size.\nIf you use fewer than 5 polls to calculate an average, your estimate of the standard deviation (SD) may be unreliable. With only one poll, you wont be able to estimate the SD at all. In these cases, consider using the SD from similar states to avoid unusual or inaccurate estimates.\n\n\nresults &lt;- polls |&gt; \n  ### Your code here\n\n\nNote you will not have polls for all states. Assume that lack of polls implies the state is not in play. Use the res_2020 data frame to compute the electoral votes Harris is practically guaranteed to have.\n\n\nharris_start &lt;- ## Your code here\n\n\nUse a Bayesian approach to compute posterior means and standard deviations for each state in results. Plot the posterior mean versus the observed average with the size of the point proportional to the number of polls.\n\n\n### Your code heer\n\n\nCompute a prediction and an interval for Harris’ electoral votes and submit to the competition here. Include the code you used to create your estimate and interval below.\n\n\n### Your code here"
  },
  {
    "objectID": "psets/pset-02-r-vectorization.html",
    "href": "psets/pset-02-r-vectorization.html",
    "title": "Problem set 2",
    "section": "",
    "text": "For these exercises, do not load any packages other than dslabs.\nMake sure to use vectorization whenever possible.\n\nWhat is the sum of the first 100 positive integers? Use the functions seq and sum to compute the sum with R for any n.\n\n\n# Your code here\n\n\nLoad the US murders dataset from the dslabs package. Use the function str to examine the structure of the murders object. What are the column names used by the data frame for these five variables? Show the subset of murders showing states with less than 1 per 100,000 deaths. Show all variables.\n\n\nlibrary(dslabs)\nstr(murders)\n\n'data.frame':   51 obs. of  5 variables:\n $ state     : chr  \"Alabama\" \"Alaska\" \"Arizona\" \"Arkansas\" ...\n $ abb       : chr  \"AL\" \"AK\" \"AZ\" \"AR\" ...\n $ region    : Factor w/ 4 levels \"Northeast\",\"South\",..: 2 4 4 2 4 4 1 2 2 2 ...\n $ population: num  4779736 710231 6392017 2915918 37253956 ...\n $ total     : num  135 19 232 93 1257 ...\n\n\n\n# Your code here\n\n\nShow the subset of murders showing states with less than 1 per 100,000 deaths and in the West of the US. Don’t show the region variable.\n\n\n# Your code here\n\n\nShow the largest state with a rate less than 1 per 100,000.\n\n\n# Your code here\n\n\nShow the state with a population of more than 10 million with the lowest rate.\n\n\n# Your code here\n\n\nCompute the rate for each region of the US.\n\n\n# Your code here\n\n\nCreate a vector of numbers that starts at 6, does not pass 55, and adds numbers in increments of 4/7: 6, 6 + 4/7, 6 + 8/7, and so on. How many numbers does the list have? Hint: use seq and length.\n\n\n# Your code here\n\n\nMake this data frame:\n\n\ntemp &lt;- c(35, 88, 42, 84, 81, 30)\ncity &lt;- c(\"Beijing\", \"Lagos\", \"Paris\", \"Rio de Janeiro\", \n          \"San Juan\", \"Toronto\")\ncity_temps &lt;- data.frame(name = city, temperature = temp)\n\nConvert the temperatures to Celsius.\n\n# Your code here\n\n\nWrite a function euler that compute the following sum for any \\(n\\):\n\n\\[\nS_n = 1+1/2^2 + 1/3^2 + \\dots 1/n^2\n\\]\n\n# Your code here\n\n\nShow that as \\(n\\) gets bigger we get closer \\(\\pi^2/6\\) by plotting \\(S_n\\) versus \\(n\\) with a horizontal dashed line at \\(\\pi^2/6\\).\n\n\n# Your code here\n\n\nUse the %in% operator and the predefined object state.abb to create a logical vector that answers the question: which of the following are actual abbreviations: MA, ME, MI, MO, MU?\n\n\n# Your code here\n\n\nExtend the code you used in the previous exercise to report the one entry that is not an actual abbreviation. Hint: use the ! operator, which turns FALSE into TRUE and vice versa, then which to obtain an index.\n\n\n# Your code here\n\n\nIn the murders dataset, use %in% to show all variables for New York, California, and Texas, in that order.\n\n\n# Your code here\n\n\nWrite a function called vandermonde_helper that for any \\(x\\) and \\(n\\), returns the vector \\((1, x, x^2, x^3, \\dots, x^n)\\). Show the results for \\(x=3\\) and \\(n=5\\).\n\n\n# Your code here\n\n\nCreate a vector using:\n\n\nn &lt;- 10000\np &lt;- 0.5\nset.seed(2024-9-6)\nx &lt;- sample(c(0,1), n, prob = c(1 - p, p), replace = TRUE)\n\nCompute the length of each stretch of 1s and then plot the distribution of these values. Check to see if the distribution follows a geometric distribution as the theory predicts. Do not use a loop!\n\n# Your code here"
  },
  {
    "objectID": "psets/pset-04-wrangling.html",
    "href": "psets/pset-04-wrangling.html",
    "title": "Problem set 4",
    "section": "",
    "text": "In the next problem set, we plan to explore the relationship between COVID-19 death rates and vaccination rates across US states by visually examining their correlation. This analysis will involve gathering COVID-19 related data from the CDC’s API and then extensively processing it to merge the various datasets. Since the population sizes of states vary significantly, we will focus on comparing rates rather than absolute numbers. To facilitate this, we will also source population data from the US Census to accurately calculate these rates.\nIn this problem set we will learn how to extract and wrangle data from the data US Census and CDC APIs.\n\nGet an API key from the US Census at https://api.census.gov/data/key_signup.html. You can’t share this public key. But your code has to run on a TFs computer. Assume the TF will have a file in their working directory named census-key.R with the following one line of code:\n\ncensus_key &lt;- \"A_CENSUS_KEY_THAT_WORKS\"\nWrite a first line of code for your problem set that defines census_key by running the code in the file census-key.R.\n\n## Your code here\n\n\nThe US Census API User Guide provides details on how to leverage this valuable resource. We are interested in vintage population estimates for years 2021 and 2022. From the documentation we find that the endpoint is:\n\n\nurl &lt;- \"https://api.census.gov/data/2021/pep/population\"\n\nUse the httr2 package to construct the following GET request.\nhttps://api.census.gov/data/2021/pep/population?get=POP_2020,POP_2021,NAME&for=state:*&key=YOURKEYHERE\nCreate an object called request of class httr2_request with this URL as an endpoint. Hint: Print out request to check that the URL matches what we want.\n\nlibrary(httr2)\n#request &lt;- \n\n\nMake a request to the US Census API using the request object. Save the response to and object named response. Check the response status of your request and make sure it was successful. You can learn about status codes here.\n\n\n#response &lt;- \n\n\nUse a function from the httr2 package to determine the content type of your response.\n\n\n# Your code here\n\n\nUse just one line of code and one function to extract the data into a matrix. Hints: 1) Use the resp_body_json function. 2) The first row of the matrix will be the variable names and this OK as we will fix in the next exercise.\n\n\n#population &lt;- \n\n\nExamine the population matrix you just created. Notice that 1) it is not tidy, 2) the column types are not what we want, and 3) the first row is a header. Convert population to a tidy dataset. Remove the state ID column and change the name of the column with state names to state_name. Add a column with state abbreviations called state. Make sure you assign the abbreviations for DC and PR correctly. Hint: Use the janitor package to make the first row the header.\n\n\nlibrary(tidyverse)\nlibrary(janitor)\n#population &lt;- population |&gt; ## Use janitor row to names function\n  # convert to tibble\n  # remove stat column\n  # rename state column to state_name\n  # use pivot_longer to tidy\n  # remove POP_ from year\n  # parese all relevant colunns to numeric\n  # add state abbreviations using state.abb variable\n  # use case_when to add abbreviations for DC and PR\n\n\nAs a check, make a barplot of states’ 2021 and 2022 populations. Show the state names in the y-axis ordered by population size. Hint: You will need to use reorder and use facet_wrap.\n\n\n# population |&gt; \n  # reorder state\n  # assign aesthetic mapping\n  # use geom_col to plot barplot\n  # flip coordinates\n  # facet by year\n\n\nThe following URL:\n\n\nurl &lt;- \"https://github.com/datasciencelabs/2024/raw/refs/heads/main/data/regions.json\"\n\npoints to a JSON file that lists the states in the 10 Public Health Service (PHS) defined by CDC. We want to add these regions to the population dataset. To facilitate this create a data frame called regions that has two columns state_name, region, region_name. One of the regions has a long name. Change it to something shorter.\n\nlibrary(jsonlite)\nlibrary(purrr)\nurl &lt;- \"https://github.com/datasciencelabs/2024/raw/refs/heads/main/data/regions.json\"\n# regions &lt;- use jsonlit JSON parser \n# regions &lt;- convert list to data frame. You can use map_df in purrr package \n\n\nAdd a region and region name columns to the population data frame.\n\n\n# population &lt;- \n\n\nFrom reading https://data.cdc.gov/ we learn the endpoint https://data.cdc.gov/resource/pwn4-m3yp.json provides state level data from SARS-COV2 cases. Use the httr2 tools you have learned to download this into a data frame. Is all the data there? If not, comment on why.\n\n\napi &lt;- \"https://data.cdc.gov/resource/pwn4-m3yp.json\"\n# cases_raw &lt;- \n\nWe see exactly 1,000 rows. We should be seeing over \\(52 \\times 3\\) rows per state.\n\nThe reason you see exactly 1,000 rows is because CDC has a default limit. You can change this limit by adding $limit=10000000000 to the request. Rewrite the previous request to ensure that you receive all the data. Then wrangle the resulting data frame to produce a data frame with columns state, date (should be the end date) and cases. Make sure the cases are numeric and the dates are in Date ISO-8601 format.\n\n\napi &lt;- \"https://data.cdc.gov/resource/pwn4-m3yp.json\"\n# cases_raw &lt;- \n\n\nFor 2020 and 2021, make a time series plot of cases per 100,000 versus time for each state. Stratify the plot by region name. Make sure to label you graph appropriately.\n\n\n#cases |&gt;"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "BST 260 Introduction to Data Science",
    "section": "",
    "text": "Instructor: Rafael A.Irizarry\nTeaching fellows: Corri Sept, Nikhil Vytla, and Yuan Wang\nLocation: Kresge 202A and 202B, Harvard School of Public Health\nDate and time: Mon & Wed 9.45 - 11:15am\nTextbooks: https://github.com/rafalab/dsbook-part-1, https://github.com/rafalab/dsbook-part-2\nSlack: https://bst260fall2024.slack.com/\nCanvas: https://canvas.harvard.edu/courses/143922/pages/Course%20Information\nGitHub repo: https://github.com/datasciencelabs/2024\nRemember to read the syllabus, listen to SD.",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "index.html#course-information",
    "href": "index.html#course-information",
    "title": "BST 260 Introduction to Data Science",
    "section": "",
    "text": "Instructor: Rafael A.Irizarry\nTeaching fellows: Corri Sept, Nikhil Vytla, and Yuan Wang\nLocation: Kresge 202A and 202B, Harvard School of Public Health\nDate and time: Mon & Wed 9.45 - 11:15am\nTextbooks: https://github.com/rafalab/dsbook-part-1, https://github.com/rafalab/dsbook-part-2\nSlack: https://bst260fall2024.slack.com/\nCanvas: https://canvas.harvard.edu/courses/143922/pages/Course%20Information\nGitHub repo: https://github.com/datasciencelabs/2024\nRemember to read the syllabus, listen to SD.",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "index.html#lectures",
    "href": "index.html#lectures",
    "title": "BST 260 Introduction to Data Science",
    "section": "Lectures",
    "text": "Lectures\nLecture slides, class notes, and problem sets are linked below. New material is added approximately on a weekly basis.\n\n\n\nDates\nTopic\nSlides\nReading\n\n\n\n\nSep 04\nProductivity Tools\nIntro, Unix\nInstalling R and RStudio on Windows or Mac, Getting Started, Unix\n\n\nSep 09, Sep 11\nProductivity Tools\nRStudio, Quarto, Git and GitHub\nRStudio Projects, Quarto, Git\n\n\nSep 16, Sep 19\nR\nR basics, Vectorization\nR Basics, Vectorization\n\n\nSep 23\nR\nTidyverse, ggplot2\ndplyr, ggplot2\n\n\nSep 25\nR\nTyding data\nReshaping Data\n\n\nSep 30, Oct 02\nWrangling\nIntro, Data Importing, Dates and Times, Locales, Data APIs, Web scraping, Joining tables\nImporting data, dates and times, Locales, Joining Tables, Extracting data from the web\n\n\nOct 07, Oct 09\nData visualization\nData Viz Principles, Distributions, Dataviz in practice\nDistributions, Dataviz Principles\n\n\nOct 16\nMidterm 1\n\nCovers material from Sep 04-Oct 11\n\n\nOct 21\nProbability\nIntro, Foundations for Inference\nMonte Carlo, Random Variables & CLT\n\n\nOct 23\nInference\nIntro, Parameter and estimates, Confidence Intervals\nParameters & Estimates, Confidence Intervals\n\n\nOct 28, Oct 30\nStatistical Models\n\nData-driven Models, Bayesian Statistics, Hierarchical Models\n\n\nNov 04, Nov 06\nLinear models\n\nRegression, Multivariate Regression\n\n\nNov 13\nLinear models\n\nMeasurement Error Models, Treatment Effect Models, Association Tests, Association Not Causation\n\n\nNov 18, Nov 20\nHigh dimensional data\n\nMatrices in R, Applied Linear Algebra, Dimension Reduction\n\n\nNov 25\nMidterm 2\n\nMidterm 2: cover material from Sep 04-Nov 22\n\n\nDec 02, Dec 04\nMachine Learning\n\nNotation and terminology, Evaluation Metrics, conditional probabilities, smoothing\n\n\nDec 09, Dec 11\nMachine Learning\n\nResampling methods, ML algorithms, ML in practice\n\n\nDec 16, Dec 18\nOther topics",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "index.html#problem-sets",
    "href": "index.html#problem-sets",
    "title": "BST 260 Introduction to Data Science",
    "section": "Problem sets",
    "text": "Problem sets\n\n\n\nProblem set\nTopic\nDue Date\nDifficulty\n\n\n\n\n01\nUnix, Quarto\nSep 11\neasy\n\n\n02\nR\nSep 19\neasy\n\n\n03\nTidyverse\nSep 27\nmedium\n\n\n04\nWrangling\nOct 4\nmedium\n\n\n05\nCovid 19 data visualization\nOct 11\nmedium\n\n\n06\nProbability\nOct 25\neasy\n\n\n07\nPredict the election\nNov 04\nhard\n\n\n08\nConfidence intervals for excess mortality\nNov 15\nhard\n\n\n09\nMatrices\nNov 22\neasy\n\n\n10\nDigit reading\nDec 13\nhard\n\n\nFinal Project\nYour choice\nDec 20\nhard",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "index.html#office-hour-times",
    "href": "index.html#office-hour-times",
    "title": "BST 260 Introduction to Data Science",
    "section": "Office hour times",
    "text": "Office hour times\n\n\n\nMeeting\nTime\nLocation\n\n\n\n\nRafael Irizarry\nMon 8:45-9:45AM\nKresge 203\n\n\nCorri Sept\nTue 3:00-4:00PM\nKresge 201\n\n\nNikhil Vytla\nWed 2:00-3:00PM\nKresge 201\n\n\nYuan Wang\nFri 1:00-2:00PM\nZoom",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "index.html#acknowledgments",
    "href": "index.html#acknowledgments",
    "title": "BST 260 Introduction to Data Science",
    "section": "Acknowledgments",
    "text": "Acknowledgments\nWe thank Maria Tackett and Mine Çetinkaya-Rundel for sharing their web page template, which we used in creating this website.",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "slides/dataviz/19-dataviz-in-practice.html#data-visualization-in-practice",
    "href": "slides/dataviz/19-dataviz-in-practice.html#data-visualization-in-practice",
    "title": "Dataviz In Practice",
    "section": "Data visualization in practice",
    "text": "Data visualization in practice\n\nIn this chapter, we will demonstrate how relatively simple ggplot2 code can create insightful and aesthetically pleasing plots.\nAs motivation we will create plots that help us better understand trends in world health and economics.\nAs we go through our case study, we will describe relevant general data visualization principles and learn concepts such as faceting, time series plots, transformations, and ridge plots."
  },
  {
    "objectID": "slides/dataviz/19-dataviz-in-practice.html#case-study-1",
    "href": "slides/dataviz/19-dataviz-in-practice.html#case-study-1",
    "title": "Dataviz In Practice",
    "section": "Case study 1",
    "text": "Case study 1\n\nHans Rosling was the co-founder of the Gapminder Foundation, an organization dedicated to educating the public by using data to dispel common myths about the so-called developing world.\nThe organization uses data to show how actual trends in health and economics contradict the narratives that emanate from sensationalist media coverage of catastrophes, tragedies, and other unfortunate events."
  },
  {
    "objectID": "slides/dataviz/19-dataviz-in-practice.html#case-study-1-1",
    "href": "slides/dataviz/19-dataviz-in-practice.html#case-study-1-1",
    "title": "Dataviz In Practice",
    "section": "Case study 1",
    "text": "Case study 1\n\nAs stated in the Gapminder Foundation’s website:\n\n\nJournalists and lobbyists tell dramatic stories. That’s their job. They tell stories about extraordinary events and unusual people. The piles of dramatic stories pile up in peoples’ minds into an over-dramatic worldview and strong negative stress feelings: “The world is getting worse!”, “It’s we vs them!”, “Other people are strange!”, “The population just keeps growing!” and “Nobody cares!”."
  },
  {
    "objectID": "slides/dataviz/19-dataviz-in-practice.html#case-study-1-2",
    "href": "slides/dataviz/19-dataviz-in-practice.html#case-study-1-2",
    "title": "Dataviz In Practice",
    "section": "Case study 1",
    "text": "Case study 1\n\nThis talk is based on two talks by Hans Rosling, one on education and The Best Stats You’ve Ever Seen\nWe use data to attempt to answer the following two questions:\n\nIs it a fair characterization of today’s world to say it is divided into western rich nations and the developing world in Africa, Asia, and Latin America?\nHas income inequality across countries worsened during the last 40 years?"
  },
  {
    "objectID": "slides/dataviz/19-dataviz-in-practice.html#case-study-1-3",
    "href": "slides/dataviz/19-dataviz-in-practice.html#case-study-1-3",
    "title": "Dataviz In Practice",
    "section": "Case study 1",
    "text": "Case study 1\n\nTo answer these questions, we will be using the gapminder dataset provided in dslabs.\n\n\nlibrary(tidyverse) \nlibrary(dslabs) \nds_theme_set()\noptions(digits = 3)\ngapminder |&gt; as_tibble() |&gt; head()\n\n# A tibble: 6 × 9\n  country    year infant_mortality life_expectancy fertility population      gdp\n  &lt;fct&gt;     &lt;int&gt;            &lt;dbl&gt;           &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;\n1 Albania    1960            115.             62.9      6.19    1636054 NA      \n2 Algeria    1960            148.             47.5      7.65   11124892  1.38e10\n3 Angola     1960            208              36.0      7.32    5270844 NA      \n4 Antigua …  1960             NA              63.0      4.43      54681 NA      \n5 Argentina  1960             59.9            65.4      3.11   20619075  1.08e11\n6 Armenia    1960             NA              66.9      4.55    1867396 NA      \n# ℹ 2 more variables: continent &lt;fct&gt;, region &lt;fct&gt;"
  },
  {
    "objectID": "slides/dataviz/19-dataviz-in-practice.html#case-study-1-4",
    "href": "slides/dataviz/19-dataviz-in-practice.html#case-study-1-4",
    "title": "Dataviz In Practice",
    "section": "Case study 1",
    "text": "Case study 1\n\nAs done in the New Insights on Poverty video, we start by testing our knowledge.\nWhich country do you think had the highest child mortality rates in 2015?\n\nSri Lanka or Turkey.\nPoland or South Korea.\nMalaysia or Russia.\nPakistan or Vietnam.\nThailand or South Africa."
  },
  {
    "objectID": "slides/dataviz/19-dataviz-in-practice.html#case-study-1-5",
    "href": "slides/dataviz/19-dataviz-in-practice.html#case-study-1-5",
    "title": "Dataviz In Practice",
    "section": "Case study 1",
    "text": "Case study 1\nHere is the data:\n\n\n\n\n\ncountry\ninf_mort\ncountry\ninf_mort\n\n\n\n\nSri Lanka\n8.4\nTurkey\n11.6\n\n\nPoland\n4.5\nSouth Korea\n2.9\n\n\nMalaysia\n6.0\nRussia\n8.2\n\n\nPakistan\n65.8\nVietnam\n17.3\n\n\nThailand\n10.5\nSouth Africa\n33.6"
  },
  {
    "objectID": "slides/dataviz/19-dataviz-in-practice.html#scatterplots",
    "href": "slides/dataviz/19-dataviz-in-practice.html#scatterplots",
    "title": "Dataviz In Practice",
    "section": "Scatterplots",
    "text": "Scatterplots\n\nWe start by looking at data from about 50 years ago, when perhaps this view was first cemented in our minds.\n\n\nfilter(gapminder, year == 1962) |&gt; \n  ggplot(aes(fertility, life_expectancy)) + \n  geom_point()"
  },
  {
    "objectID": "slides/dataviz/19-dataviz-in-practice.html#scatterplots-1",
    "href": "slides/dataviz/19-dataviz-in-practice.html#scatterplots-1",
    "title": "Dataviz In Practice",
    "section": "Scatterplots",
    "text": "Scatterplots"
  },
  {
    "objectID": "slides/dataviz/19-dataviz-in-practice.html#scatterplots-2",
    "href": "slides/dataviz/19-dataviz-in-practice.html#scatterplots-2",
    "title": "Dataviz In Practice",
    "section": "Scatterplots",
    "text": "Scatterplots\n\nTo confirm that indeed these countries are from the regions we expect, we can use color to represent continent.\n\n\nfilter(gapminder, year == 1962) |&gt; \n  ggplot( aes(fertility, life_expectancy, color = continent)) + \n  geom_point()"
  },
  {
    "objectID": "slides/dataviz/19-dataviz-in-practice.html#scatterplots-3",
    "href": "slides/dataviz/19-dataviz-in-practice.html#scatterplots-3",
    "title": "Dataviz In Practice",
    "section": "Scatterplots",
    "text": "Scatterplots"
  },
  {
    "objectID": "slides/dataviz/19-dataviz-in-practice.html#faceting",
    "href": "slides/dataviz/19-dataviz-in-practice.html#faceting",
    "title": "Dataviz In Practice",
    "section": "Faceting",
    "text": "Faceting\n\nTo make comparisons, however, side by side plots are preferable.\n\n\nfilter(gapminder, year %in% c(1962, 2012)) |&gt; \n  ggplot(aes(fertility, life_expectancy, col = continent)) + \n  geom_point() + \n  facet_grid(year~continent)"
  },
  {
    "objectID": "slides/dataviz/19-dataviz-in-practice.html#faceting-1",
    "href": "slides/dataviz/19-dataviz-in-practice.html#faceting-1",
    "title": "Dataviz In Practice",
    "section": "Faceting",
    "text": "Faceting"
  },
  {
    "objectID": "slides/dataviz/19-dataviz-in-practice.html#faceting-2",
    "href": "slides/dataviz/19-dataviz-in-practice.html#faceting-2",
    "title": "Dataviz In Practice",
    "section": "Faceting",
    "text": "Faceting\n\nIn this case, there is just one variable and we use . to let facet know that we are not using a second variable:\n\n\nfilter(gapminder, year %in% c(1962, 2012)) |&gt; \n  ggplot(aes(fertility, life_expectancy, col = continent)) + \n  geom_point() + \n  facet_grid(. ~ year)"
  },
  {
    "objectID": "slides/dataviz/19-dataviz-in-practice.html#faceting-3",
    "href": "slides/dataviz/19-dataviz-in-practice.html#faceting-3",
    "title": "Dataviz In Practice",
    "section": "Faceting",
    "text": "Faceting\nThis plot clearly shows that the majority of countries have moved from the developing world cluster to the western world one."
  },
  {
    "objectID": "slides/dataviz/19-dataviz-in-practice.html#facet_wrap",
    "href": "slides/dataviz/19-dataviz-in-practice.html#facet_wrap",
    "title": "Dataviz In Practice",
    "section": "facet_wrap",
    "text": "facet_wrap\nThe function facet_wrap permits automatically wrap the series of plots so that each display has viewable dimensions:\n\nyears &lt;- c(1962, 1980, 1990, 2000, 2012) \ncontinents &lt;- c(\"Europe\", \"Asia\") \ngapminder |&gt;  \n  filter(year %in% years & continent %in% continents) |&gt; \n  ggplot( aes(fertility, life_expectancy, col = continent)) + \n  geom_point() + \n  facet_wrap(~year)"
  },
  {
    "objectID": "slides/dataviz/19-dataviz-in-practice.html#facet_wrap-1",
    "href": "slides/dataviz/19-dataviz-in-practice.html#facet_wrap-1",
    "title": "Dataviz In Practice",
    "section": "facet_wrap",
    "text": "facet_wrap"
  },
  {
    "objectID": "slides/dataviz/19-dataviz-in-practice.html#faceting-4",
    "href": "slides/dataviz/19-dataviz-in-practice.html#faceting-4",
    "title": "Dataviz In Practice",
    "section": "Faceting",
    "text": "Faceting\n\nBy default axes ranges are the same across panes.\nWe can make the axes adapt using scales = \"free\".\n\n\nyears &lt;- c(1962, 1980, 1990, 2000, 2012) \ncontinents &lt;- c(\"Europe\", \"Asia\") \ngapminder |&gt;  \n  filter(year %in% years & continent %in% continents) |&gt; \n  ggplot( aes(fertility, life_expectancy, col = continent)) + \n  geom_point() + \n  facet_wrap(~year, scales = \"free\")  \n\n\nYou will notice that it is harder to see the pattern."
  },
  {
    "objectID": "slides/dataviz/19-dataviz-in-practice.html#faceting-5",
    "href": "slides/dataviz/19-dataviz-in-practice.html#faceting-5",
    "title": "Dataviz In Practice",
    "section": "Faceting",
    "text": "Faceting"
  },
  {
    "objectID": "slides/dataviz/19-dataviz-in-practice.html#gganimate",
    "href": "slides/dataviz/19-dataviz-in-practice.html#gganimate",
    "title": "Dataviz In Practice",
    "section": "gganimate",
    "text": "gganimate\n\nCodeWrangleAnimation\n\n\n\nlibrary(gganimate)\nyears &lt;- c(1960:2016)\np &lt;- filter(gapminder, year %in% years & !is.na(group) & \n              !is.na(fertility) & !is.na(life_expectancy)) |&gt;\n  mutate(population_in_millions = population/10^6) |&gt;\n  ggplot(aes(fertility, y = life_expectancy, col = group, size = population_in_millions)) +\n  geom_point(alpha = 0.8) +\n  guides(size = \"none\") +\n  theme(legend.title = element_blank()) + \n  coord_cartesian(ylim = c(30, 85)) + \n  labs(title = 'Year: {frame_time}', \n       x = 'Fertility rate (births per woman)', y = 'Life expectancy') +\n  transition_time(year) +\n  ease_aes('linear')\n\nanimate(p, end_pause = 15)\n\n\n\n\nwest &lt;- c(\"Western Europe\",\"Northern Europe\",\"Southern Europe\",\n          \"Northern America\",\"Australia and New Zealand\")\n\ngapminder &lt;- gapminder |&gt; \n  mutate(group = case_when(\n    region %in% west ~ \"The West\",\n    region %in% c(\"Eastern Asia\", \"South-Eastern Asia\") ~ \"East Asia\",\n    region %in% c(\"Caribbean\", \"Central America\", \"South America\") ~ \"Latin America\",\n    continent == \"Africa\" & region != \"Northern Africa\" ~ \"Sub-Saharan Africa\",\n    TRUE ~ \"Others\"))\ngapminder &lt;- gapminder |&gt; \n  mutate(group = factor(group, levels = rev(c(\"Others\", \"Latin America\", \"East Asia\",\"Sub-Saharan Africa\", \"The West\"))))"
  },
  {
    "objectID": "slides/dataviz/19-dataviz-in-practice.html#time-series-plots",
    "href": "slides/dataviz/19-dataviz-in-practice.html#time-series-plots",
    "title": "Dataviz In Practice",
    "section": "Time series plots",
    "text": "Time series plots\nHere is a trend plot of United States fertility rates:\n\ngapminder |&gt;  \n  filter(country == \"United States\") |&gt;  \n  ggplot(aes(year, fertility)) + \n  geom_point()"
  },
  {
    "objectID": "slides/dataviz/19-dataviz-in-practice.html#time-series-plots-1",
    "href": "slides/dataviz/19-dataviz-in-practice.html#time-series-plots-1",
    "title": "Dataviz In Practice",
    "section": "Time series plots",
    "text": "Time series plots"
  },
  {
    "objectID": "slides/dataviz/19-dataviz-in-practice.html#time-series-plots-2",
    "href": "slides/dataviz/19-dataviz-in-practice.html#time-series-plots-2",
    "title": "Dataviz In Practice",
    "section": "Time series plots",
    "text": "Time series plots\n\nWhen the points are regularly and densely spaced, as they are here, we create curves by joining the points with lines, to convey that these data are from a single series, here a country:\n\n\ngapminder |&gt;  \n  filter(country == \"United States\") |&gt;  \n  ggplot(aes(year, fertility)) + \n  geom_line()"
  },
  {
    "objectID": "slides/dataviz/19-dataviz-in-practice.html#time-series-plots-3",
    "href": "slides/dataviz/19-dataviz-in-practice.html#time-series-plots-3",
    "title": "Dataviz In Practice",
    "section": "Time series plots",
    "text": "Time series plots"
  },
  {
    "objectID": "slides/dataviz/19-dataviz-in-practice.html#time-series-plots-4",
    "href": "slides/dataviz/19-dataviz-in-practice.html#time-series-plots-4",
    "title": "Dataviz In Practice",
    "section": "Time series plots",
    "text": "Time series plots\n\nThis is particularly helpful when we look at two countries.\n\n\ncountries &lt;- c(\"South Korea\", \"Germany\") \ngapminder |&gt; filter(country %in% countries) |&gt;  \n  ggplot(aes(year,fertility)) + \n  geom_line()"
  },
  {
    "objectID": "slides/dataviz/19-dataviz-in-practice.html#time-series-plots-5",
    "href": "slides/dataviz/19-dataviz-in-practice.html#time-series-plots-5",
    "title": "Dataviz In Practice",
    "section": "Time series plots",
    "text": "Time series plots"
  },
  {
    "objectID": "slides/dataviz/19-dataviz-in-practice.html#time-series-plots-6",
    "href": "slides/dataviz/19-dataviz-in-practice.html#time-series-plots-6",
    "title": "Dataviz In Practice",
    "section": "Time series plots",
    "text": "Time series plots\n\nThis is not the plot that we want.\nTo let ggplot know that there are two curves that need to be made separately, we assign each point to a group, one for each country:\n\n\ncountries &lt;- c(\"South Korea\",\"Germany\") \ngapminder |&gt; filter(country %in% countries & !is.na(fertility)) |&gt;  \n  ggplot(aes(year, fertility, group = country)) + \n  geom_line()"
  },
  {
    "objectID": "slides/dataviz/19-dataviz-in-practice.html#time-series-plots-7",
    "href": "slides/dataviz/19-dataviz-in-practice.html#time-series-plots-7",
    "title": "Dataviz In Practice",
    "section": "Time series plots",
    "text": "Time series plots"
  },
  {
    "objectID": "slides/dataviz/19-dataviz-in-practice.html#time-series-plots-8",
    "href": "slides/dataviz/19-dataviz-in-practice.html#time-series-plots-8",
    "title": "Dataviz In Practice",
    "section": "Time series plots",
    "text": "Time series plots\n\nBut which line goes with which country? We can assign colors to make this distinction.\n\n\ncountries &lt;- c(\"South Korea\",\"Germany\") \ngapminder |&gt; filter(country %in% countries & !is.na(fertility)) |&gt;  \n  ggplot(aes(year,fertility, col = country)) + \n  geom_line()"
  },
  {
    "objectID": "slides/dataviz/19-dataviz-in-practice.html#time-series-plots-9",
    "href": "slides/dataviz/19-dataviz-in-practice.html#time-series-plots-9",
    "title": "Dataviz In Practice",
    "section": "Time series plots",
    "text": "Time series plots"
  },
  {
    "objectID": "slides/dataviz/19-dataviz-in-practice.html#time-series-plots-10",
    "href": "slides/dataviz/19-dataviz-in-practice.html#time-series-plots-10",
    "title": "Dataviz In Practice",
    "section": "Time series plots",
    "text": "Time series plots\n\nWe define a data table with the label locations and then use a second mapping just for these labels:\n\n\nlibrary(geomtextpath) \ngapminder |&gt;  \n  filter(country %in% countries) |&gt;  \n  ggplot(aes(year, life_expectancy, col = country, label = country)) + \n  geom_textpath() + \n  theme(legend.position = \"none\")"
  },
  {
    "objectID": "slides/dataviz/19-dataviz-in-practice.html#time-series-plots-11",
    "href": "slides/dataviz/19-dataviz-in-practice.html#time-series-plots-11",
    "title": "Dataviz In Practice",
    "section": "Time series plots",
    "text": "Time series plots"
  },
  {
    "objectID": "slides/dataviz/19-dataviz-in-practice.html#data-transformations",
    "href": "slides/dataviz/19-dataviz-in-practice.html#data-transformations",
    "title": "Dataviz In Practice",
    "section": "Data transformations",
    "text": "Data transformations\n\nWe now shift our attention to the the commonly held notion that wealth distribution across the world has become worse during the last decades.\nWhen general audiences are asked if poor countries have become poorer and rich countries become richer, the majority answers yes.\nBy using stratification, histograms, smooth densities, and boxplots, we will be able to understand if this is in fact the case.\nFirst we learn how transformations can sometimes help provide more informative summaries and plots."
  },
  {
    "objectID": "slides/dataviz/19-dataviz-in-practice.html#data-transformations-1",
    "href": "slides/dataviz/19-dataviz-in-practice.html#data-transformations-1",
    "title": "Dataviz In Practice",
    "section": "Data transformations",
    "text": "Data transformations\n\nGDP measures the market value of goods and services produced by a country in a year.\nThe GDP per person is often used as a rough summary of a country’s wealth.\nGapmider adjusts GDP values for inflation and represent current US dollars.\nWe divide this quantity by 365 to obtain the more interpretable measure dollars per day.\n\n\ngapminder &lt;- gapminder |&gt;   \n  mutate(dollars_per_day = gdp/population/365)"
  },
  {
    "objectID": "slides/dataviz/19-dataviz-in-practice.html#log-transformation",
    "href": "slides/dataviz/19-dataviz-in-practice.html#log-transformation",
    "title": "Dataviz In Practice",
    "section": "Log transformation",
    "text": "Log transformation\n\nHere is a histogram of per day incomes from 1970:\n\n\npast_year &lt;- 1970 \ngapminder |&gt;  \n  filter(year == past_year & !is.na(gdp)) |&gt; \n  ggplot(aes(dollars_per_day)) +  \n  geom_histogram(binwidth = 1, color = \"black\")"
  },
  {
    "objectID": "slides/dataviz/19-dataviz-in-practice.html#log-transformation-1",
    "href": "slides/dataviz/19-dataviz-in-practice.html#log-transformation-1",
    "title": "Dataviz In Practice",
    "section": "Log transformation",
    "text": "Log transformation"
  },
  {
    "objectID": "slides/dataviz/19-dataviz-in-practice.html#log-transformation-2",
    "href": "slides/dataviz/19-dataviz-in-practice.html#log-transformation-2",
    "title": "Dataviz In Practice",
    "section": "Log transformation",
    "text": "Log transformation\n\nIt might be more informative to quickly be able to see how many countries have average daily incomes of about $1 (extremely poor), $2 (very poor), $4 (poor), $8 (middle), $16 (well off), $32 (rich), $64 (very rich) per day.\nHere is the distribution if we apply a log base 2 transform:\n\n\ngapminder |&gt;  \n  filter(year == past_year & !is.na(gdp)) |&gt; \n  ggplot(aes(log2(dollars_per_day))) +  \n  geom_histogram(binwidth = 1, color = \"black\")"
  },
  {
    "objectID": "slides/dataviz/19-dataviz-in-practice.html#log-transformation-3",
    "href": "slides/dataviz/19-dataviz-in-practice.html#log-transformation-3",
    "title": "Dataviz In Practice",
    "section": "Log transformation",
    "text": "Log transformation"
  },
  {
    "objectID": "slides/dataviz/19-dataviz-in-practice.html#which-base",
    "href": "slides/dataviz/19-dataviz-in-practice.html#which-base",
    "title": "Dataviz In Practice",
    "section": "Which base?",
    "text": "Which base?\n\nIn the dollars per day example, we used base 2 instead of base 10 because the resulting range is easier to interpret.\nThe range of the untransformed values is 0.327, 48.885.\nIn base 10, this turns into a range that includes very few integers: just 0 and 1.\nWith base 2, our range includes -2, -1, 0, 1, 2, 3, 4, and 5."
  },
  {
    "objectID": "slides/dataviz/19-dataviz-in-practice.html#which-base-1",
    "href": "slides/dataviz/19-dataviz-in-practice.html#which-base-1",
    "title": "Dataviz In Practice",
    "section": "Which base?",
    "text": "Which base?\n\nIt is easier to compute \\(2^x\\) and \\(10^x\\) when \\(x\\) is an integer and between -10 and 10, so we prefer to have smaller integers in the scale.\nAnother consequence of a limited range is that choosing the binwidth is more challenging.\nWith log base 2, we know that a binwidth of 1 will translate to a bin with range \\(x\\) to \\(2x\\)."
  },
  {
    "objectID": "slides/dataviz/19-dataviz-in-practice.html#which-base-2",
    "href": "slides/dataviz/19-dataviz-in-practice.html#which-base-2",
    "title": "Dataviz In Practice",
    "section": "Which base?",
    "text": "Which base?\n\nFor an example in which base 10 makes more sense, consider population sizes:\n\n\ngapminder |&gt;  \n  filter(year == past_year) |&gt; \n  ggplot(aes(log10(population))) + \n  geom_histogram(binwidth = 0.5, color = \"black\")"
  },
  {
    "objectID": "slides/dataviz/19-dataviz-in-practice.html#which-base-3",
    "href": "slides/dataviz/19-dataviz-in-practice.html#which-base-3",
    "title": "Dataviz In Practice",
    "section": "Which base?",
    "text": "Which base?"
  },
  {
    "objectID": "slides/dataviz/19-dataviz-in-practice.html#transform-values-or-scale",
    "href": "slides/dataviz/19-dataviz-in-practice.html#transform-values-or-scale",
    "title": "Dataviz In Practice",
    "section": "Transform values or scale?",
    "text": "Transform values or scale?\nSuppose we define \\(z = \\log10(x)\\) and want to know what is the value of \\(z\\) if we see it at the mark ^:\n----1----^----2--------3----.\nWe know that the \\(z\\) is about 1.5.\nBut what If the scales are logged, what value of \\(x\\) marked by ^?\n----10---^---100------1000---\nWe need to compute \\(10^{1.5}\\), which is a bit of extra work."
  },
  {
    "objectID": "slides/dataviz/19-dataviz-in-practice.html#transform-values-or-scale-1",
    "href": "slides/dataviz/19-dataviz-in-practice.html#transform-values-or-scale-1",
    "title": "Dataviz In Practice",
    "section": "Transform values or scale?",
    "text": "Transform values or scale?\n\nHowever, the advantage of showing logged scales is that the original values are displayed in the plot, which are easier to interpret.\nFor example, we would see “32 dollars a day” instead of “5 log base 2 dollars a day”."
  },
  {
    "objectID": "slides/dataviz/19-dataviz-in-practice.html#transform-values-or-scale-2",
    "href": "slides/dataviz/19-dataviz-in-practice.html#transform-values-or-scale-2",
    "title": "Dataviz In Practice",
    "section": "Transform values or scale?",
    "text": "Transform values or scale?\n\nTo show logged sclaes, instead of logging the values first, we apply this layer:\n\n\ngapminder |&gt;  \n  filter(year == past_year & !is.na(gdp)) |&gt; \n  ggplot(aes(dollars_per_day)) +  \n  geom_histogram(binwidth = 1, color = \"black\") + \n  scale_x_continuous(trans = \"log2\")"
  },
  {
    "objectID": "slides/dataviz/19-dataviz-in-practice.html#transform-values-or-scale-3",
    "href": "slides/dataviz/19-dataviz-in-practice.html#transform-values-or-scale-3",
    "title": "Dataviz In Practice",
    "section": "Transform values or scale?",
    "text": "Transform values or scale?"
  },
  {
    "objectID": "slides/dataviz/19-dataviz-in-practice.html#comparing-distributions",
    "href": "slides/dataviz/19-dataviz-in-practice.html#comparing-distributions",
    "title": "Dataviz In Practice",
    "section": "Comparing distributions",
    "text": "Comparing distributions\n\nWe reorder the regions by the median value and use a log scale.\n\n\ngapminder |&gt;  \n  filter(year == past_year & !is.na(gdp)) |&gt; \n  mutate(region = reorder(region, dollars_per_day, FUN = median)) |&gt; \n  ggplot(aes(dollars_per_day, region)) + \n  geom_point() + \n  scale_x_continuous(trans = \"log2\")"
  },
  {
    "objectID": "slides/dataviz/19-dataviz-in-practice.html#comparing-distributions-1",
    "href": "slides/dataviz/19-dataviz-in-practice.html#comparing-distributions-1",
    "title": "Dataviz In Practice",
    "section": "Comparing distributions",
    "text": "Comparing distributions"
  },
  {
    "objectID": "slides/dataviz/19-dataviz-in-practice.html#comparing-distributions-2",
    "href": "slides/dataviz/19-dataviz-in-practice.html#comparing-distributions-2",
    "title": "Dataviz In Practice",
    "section": "Comparing distributions",
    "text": "Comparing distributions\n\ngapminder &lt;- gapminder |&gt;  \n  mutate(group = case_when( \n    region %in% c(\"Western Europe\", \"Northern Europe\",\"Southern Europe\",  \n                    \"Northern America\",  \n                  \"Australia and New Zealand\") ~ \"West\", \n    region %in% c(\"Eastern Asia\", \"South-Eastern Asia\") ~ \"East Asia\", \n    region %in% c(\"Caribbean\", \"Central America\",  \n                  \"South America\") ~ \"Latin America\", \n    continent == \"Africa\" &  \n      region != \"Northern Africa\" ~ \"Sub-Saharan\", \n    TRUE ~ \"Others\")) |&gt;  \n  mutate(group = factor(group, levels = c(\"Others\", \"Latin America\",  \n                                          \"East Asia\", \"Sub-Saharan\", \n                                          \"West\")))"
  },
  {
    "objectID": "slides/dataviz/19-dataviz-in-practice.html#boxplots",
    "href": "slides/dataviz/19-dataviz-in-practice.html#boxplots",
    "title": "Dataviz In Practice",
    "section": "Boxplots",
    "text": "Boxplots\n\np &lt;- gapminder |&gt;  \n  filter(year == past_year & !is.na(gdp)) |&gt; \n  mutate(group = reorder(group, dollars_per_day, FUN = median)) |&gt; \n  ggplot(aes(group, dollars_per_day)) + \n  geom_boxplot() + \n  scale_y_continuous(trans = \"log2\") + \n  xlab(\"\") + \n  theme(axis.text.x = element_text(angle = 90, hjust = 1))  \np"
  },
  {
    "objectID": "slides/dataviz/19-dataviz-in-practice.html#boxplots-1",
    "href": "slides/dataviz/19-dataviz-in-practice.html#boxplots-1",
    "title": "Dataviz In Practice",
    "section": "Boxplots",
    "text": "Boxplots"
  },
  {
    "objectID": "slides/dataviz/19-dataviz-in-practice.html#boxplots-2",
    "href": "slides/dataviz/19-dataviz-in-practice.html#boxplots-2",
    "title": "Dataviz In Practice",
    "section": "Boxplots",
    "text": "Boxplots\n\nBoxplots have the limitation that by summarizing the data into five numbers, we might miss important characteristics of the data.\nOne way to avoid this is by showing the data.\n\n\np + geom_point(alpha = 0.5)"
  },
  {
    "objectID": "slides/dataviz/19-dataviz-in-practice.html#boxplots-3",
    "href": "slides/dataviz/19-dataviz-in-practice.html#boxplots-3",
    "title": "Dataviz In Practice",
    "section": "Boxplots",
    "text": "Boxplots"
  },
  {
    "objectID": "slides/dataviz/19-dataviz-in-practice.html#ridge-plots",
    "href": "slides/dataviz/19-dataviz-in-practice.html#ridge-plots",
    "title": "Dataviz In Practice",
    "section": "Ridge plots",
    "text": "Ridge plots\n\nShowing each individual point does not always reveal important characteristics of the distribution.\nBoxplots help with this by providing a five-number summary, but this has limitations too.\nFor example, boxplots will not permit us to discover bimodal distributions."
  },
  {
    "objectID": "slides/dataviz/19-dataviz-in-practice.html#ridge-plots-1",
    "href": "slides/dataviz/19-dataviz-in-practice.html#ridge-plots-1",
    "title": "Dataviz In Practice",
    "section": "Ridge plots",
    "text": "Ridge plots\nHere is an simulated example:"
  },
  {
    "objectID": "slides/dataviz/19-dataviz-in-practice.html#ridge-plots-2",
    "href": "slides/dataviz/19-dataviz-in-practice.html#ridge-plots-2",
    "title": "Dataviz In Practice",
    "section": "Ridge plots",
    "text": "Ridge plots\n\nHere is the income data shown above with boxplots but with a ridge plot.\n\n\nlibrary(ggridges) \np &lt;- gapminder |&gt;  \n  filter(year == past_year & !is.na(dollars_per_day)) |&gt; \n  mutate(group = reorder(group, dollars_per_day, FUN = median)) |&gt; \n  ggplot(aes(dollars_per_day, group)) +  \n  scale_x_continuous(trans = \"log2\")  \np  + geom_density_ridges()"
  },
  {
    "objectID": "slides/dataviz/19-dataviz-in-practice.html#ridge-plots-3",
    "href": "slides/dataviz/19-dataviz-in-practice.html#ridge-plots-3",
    "title": "Dataviz In Practice",
    "section": "Ridge plots",
    "text": "Ridge plots"
  },
  {
    "objectID": "slides/dataviz/19-dataviz-in-practice.html#ridge-plots-4",
    "href": "slides/dataviz/19-dataviz-in-practice.html#ridge-plots-4",
    "title": "Dataviz In Practice",
    "section": "Ridge plots",
    "text": "Ridge plots\n\nIf the number of data points is small enough, we can add them to the ridge plot using the following code:\n\n\np + geom_density_ridges(jittered_points = TRUE)"
  },
  {
    "objectID": "slides/dataviz/19-dataviz-in-practice.html#ridge-plots-5",
    "href": "slides/dataviz/19-dataviz-in-practice.html#ridge-plots-5",
    "title": "Dataviz In Practice",
    "section": "Ridge plots",
    "text": "Ridge plots"
  },
  {
    "objectID": "slides/dataviz/19-dataviz-in-practice.html#ridge-plots-6",
    "href": "slides/dataviz/19-dataviz-in-practice.html#ridge-plots-6",
    "title": "Dataviz In Practice",
    "section": "Ridge plots",
    "text": "Ridge plots\n\nTo show data points, but without using jitter we can use the following code to add what is referred to as a rug representation of the data.\n\n\np + geom_density_ridges(jittered_points = TRUE,  \n                        position = position_points_jitter(height = 0), \n                        point_shape = '|', point_size = 3,  \n                        point_alpha = 1, alpha = 0.7)"
  },
  {
    "objectID": "slides/dataviz/19-dataviz-in-practice.html#ridge-plots-7",
    "href": "slides/dataviz/19-dataviz-in-practice.html#ridge-plots-7",
    "title": "Dataviz In Practice",
    "section": "Ridge plots",
    "text": "Ridge plots"
  },
  {
    "objectID": "slides/dataviz/19-dataviz-in-practice.html#case-study-1-6",
    "href": "slides/dataviz/19-dataviz-in-practice.html#case-study-1-6",
    "title": "Dataviz In Practice",
    "section": "Case study 1",
    "text": "Case study 1\nWe keep countries that exist both in 1970 and 2010:\n\npast_year &lt;- 1970 \npresent_year &lt;- 2010 \nyears &lt;- c(past_year, present_year) \ncountry_list &lt;- gapminder |&gt;  \n  filter(year %in% c(present_year, past_year)) |&gt; \n  group_by(country) |&gt; \n  summarize(n = sum(!is.na(dollars_per_day)), .groups = \"drop\") |&gt; \n  filter(n == 2) |&gt; \n  pull(country)"
  },
  {
    "objectID": "slides/dataviz/19-dataviz-in-practice.html#case-study-1-7",
    "href": "slides/dataviz/19-dataviz-in-practice.html#case-study-1-7",
    "title": "Dataviz In Practice",
    "section": "Case study 1",
    "text": "Case study 1\n\nWe can compare the distributions using this code:\n\n\ngapminder |&gt;  \n  filter(year %in% years & country %in% country_list) |&gt; \n  mutate(west = ifelse(group == \"West\", \"West\", \"Developing\")) |&gt; \n  ggplot(aes(dollars_per_day)) + \n  geom_histogram(binwidth = 1, color = \"black\") + \n  scale_x_continuous(trans = \"log2\") +  \n  facet_grid(year ~ west)"
  },
  {
    "objectID": "slides/dataviz/19-dataviz-in-practice.html#case-study-1-8",
    "href": "slides/dataviz/19-dataviz-in-practice.html#case-study-1-8",
    "title": "Dataviz In Practice",
    "section": "Case study 1",
    "text": "Case study 1"
  },
  {
    "objectID": "slides/dataviz/19-dataviz-in-practice.html#case-study-1-9",
    "href": "slides/dataviz/19-dataviz-in-practice.html#case-study-1-9",
    "title": "Dataviz In Practice",
    "section": "Case study 1",
    "text": "Case study 1\nTo see which specific regions improved the most, we can remake the boxplots we made above, but now adding the year 2010 and then using facet to compare the two years.\n\ngapminder |&gt;  \n  filter(year %in% years & country %in% country_list) |&gt; \n  mutate(group = reorder(group, dollars_per_day, FUN = median)) |&gt; \n  ggplot(aes(group, dollars_per_day)) + \n  geom_boxplot() + \n  theme(axis.text.x = element_text(angle = 90, hjust = 1)) + \n  scale_y_continuous(trans = \"log2\") + \n  xlab(\"\") + \n  facet_grid(. ~ year)"
  },
  {
    "objectID": "slides/dataviz/19-dataviz-in-practice.html#case-study-1-10",
    "href": "slides/dataviz/19-dataviz-in-practice.html#case-study-1-10",
    "title": "Dataviz In Practice",
    "section": "Case study 1",
    "text": "Case study 1"
  },
  {
    "objectID": "slides/dataviz/19-dataviz-in-practice.html#case-study-1-11",
    "href": "slides/dataviz/19-dataviz-in-practice.html#case-study-1-11",
    "title": "Dataviz In Practice",
    "section": "Case study 1",
    "text": "Case study 1\nTo add color:\n\ngapminder |&gt;  \n  filter(year %in% years & country %in% country_list) |&gt; \n  mutate(group = reorder(group, dollars_per_day, FUN = median),\n         year = factor(year)) |&gt; \n  ggplot(aes(group, dollars_per_day, fill = year)) + \n  geom_boxplot() + \n  theme(axis.text.x = element_text(angle = 90, hjust = 1)) + \n  scale_y_continuous(trans = \"log2\") + \n  xlab(\"\")"
  },
  {
    "objectID": "slides/dataviz/19-dataviz-in-practice.html#case-study-1-12",
    "href": "slides/dataviz/19-dataviz-in-practice.html#case-study-1-12",
    "title": "Dataviz In Practice",
    "section": "Case study 1",
    "text": "Case study 1"
  },
  {
    "objectID": "slides/dataviz/19-dataviz-in-practice.html#case-study-1-13",
    "href": "slides/dataviz/19-dataviz-in-practice.html#case-study-1-13",
    "title": "Dataviz In Practice",
    "section": "Case study 1",
    "text": "Case study 1\nLet’s start by noting that density plots for income distribution in 1970 and 2010 deliver the message that the gap is closing:\n\ngapminder |&gt;  \n  filter(year %in% years & country %in% country_list) |&gt; \n  ggplot(aes(dollars_per_day)) + \n  geom_density(fill = \"grey\") +  \n  scale_x_continuous(trans = \"log2\") +  \n  facet_grid(. ~ year)"
  },
  {
    "objectID": "slides/dataviz/19-dataviz-in-practice.html#case-study-1-14",
    "href": "slides/dataviz/19-dataviz-in-practice.html#case-study-1-14",
    "title": "Dataviz In Practice",
    "section": "Case study 1",
    "text": "Case study 1"
  },
  {
    "objectID": "slides/dataviz/19-dataviz-in-practice.html#accessing-computed-variables",
    "href": "slides/dataviz/19-dataviz-in-practice.html#accessing-computed-variables",
    "title": "Dataviz In Practice",
    "section": "Accessing computed variables",
    "text": "Accessing computed variables\nUse after_stat to access density.\n\np &lt;- gapminder |&gt;  \n  filter(year %in% years & country %in% country_list) |&gt; \n  mutate(group = ifelse(group == \"West\", \"West\", \"Developing\")) |&gt; \n  ggplot(aes(dollars_per_day, y = after_stat(count), fill = group)) + \n  scale_x_continuous(trans = \"log2\", limits = c(0.125, 300)) \np + geom_density(alpha = 0.2) + facet_grid(year ~ .)"
  },
  {
    "objectID": "slides/dataviz/19-dataviz-in-practice.html#accessing-computed-variables-1",
    "href": "slides/dataviz/19-dataviz-in-practice.html#accessing-computed-variables-1",
    "title": "Dataviz In Practice",
    "section": "Accessing computed variables",
    "text": "Accessing computed variables"
  },
  {
    "objectID": "slides/dataviz/19-dataviz-in-practice.html#changing-smoothness",
    "href": "slides/dataviz/19-dataviz-in-practice.html#changing-smoothness",
    "title": "Dataviz In Practice",
    "section": "Changing smoothness",
    "text": "Changing smoothness\nWe can change the smoothness. We selected 0.75 after trying out several values.\n\np + geom_density(alpha = 0.2, bw = 0.75) + facet_grid(year ~ .)"
  },
  {
    "objectID": "slides/dataviz/19-dataviz-in-practice.html#multiple-ridge-plot",
    "href": "slides/dataviz/19-dataviz-in-practice.html#multiple-ridge-plot",
    "title": "Dataviz In Practice",
    "section": "Multiple ridge plot",
    "text": "Multiple ridge plot\nTo visualize if any of the groups defined above are driving this we can quickly make a ridge plot:\n\ngapminder |&gt;  \n  filter(year %in% years & !is.na(dollars_per_day)) |&gt; \n  mutate(group = reorder(group, dollars_per_day, FUN = median)) |&gt;\n  ggplot(aes(dollars_per_day, group)) +  \n  scale_x_continuous(trans = \"log2\") +  \n  geom_density_ridges(bandwidth = 1.5) + \n  facet_grid(. ~ year)"
  },
  {
    "objectID": "slides/dataviz/19-dataviz-in-practice.html#multiple-ridge-plot-1",
    "href": "slides/dataviz/19-dataviz-in-practice.html#multiple-ridge-plot-1",
    "title": "Dataviz In Practice",
    "section": "Multiple ridge plot",
    "text": "Multiple ridge plot"
  },
  {
    "objectID": "slides/dataviz/19-dataviz-in-practice.html#stacking-densities",
    "href": "slides/dataviz/19-dataviz-in-practice.html#stacking-densities",
    "title": "Dataviz In Practice",
    "section": "Stacking densities",
    "text": "Stacking densities\n\nAnother way to achieve this is by stacking the densities on top of each other:\n\n\ngapminder |&gt;  \n    filter(year %in% years & country %in% country_list) |&gt; \n  group_by(year) |&gt; \n  mutate(weight = population/sum(population)*2) |&gt; \n  ungroup() |&gt; \n  ggplot(aes(dollars_per_day, fill = group)) + \n  scale_x_continuous(trans = \"log2\", limits = c(0.125, 300)) +  \n  geom_density(alpha = 0.2, bw = 0.75, position = \"stack\") +  \n  facet_grid(year ~ .)"
  },
  {
    "objectID": "slides/dataviz/19-dataviz-in-practice.html#stacking-densities-1",
    "href": "slides/dataviz/19-dataviz-in-practice.html#stacking-densities-1",
    "title": "Dataviz In Practice",
    "section": "Stacking densities",
    "text": "Stacking densities"
  },
  {
    "objectID": "slides/dataviz/19-dataviz-in-practice.html#weighted-densities",
    "href": "slides/dataviz/19-dataviz-in-practice.html#weighted-densities",
    "title": "Dataviz In Practice",
    "section": "Weighted densities",
    "text": "Weighted densities\nHere we weigh the countries by size:\n\ngapminder |&gt;  \n  filter(year %in% years & country %in% country_list) |&gt; \n  group_by(year) |&gt; \n  mutate(weight = population/sum(population)*2) |&gt; \n  ungroup() |&gt; \n  ggplot(aes(dollars_per_day, fill = group, weight = weight)) + \n  scale_x_continuous(trans = \"log2\", limits = c(0.125, 300)) +  \n  geom_density(alpha = 0.2, bw = 0.75, position = \"stack\") + \n  facet_grid(year ~ .)"
  },
  {
    "objectID": "slides/dataviz/19-dataviz-in-practice.html#weighted-densities-1",
    "href": "slides/dataviz/19-dataviz-in-practice.html#weighted-densities-1",
    "title": "Dataviz In Practice",
    "section": "Weighted densities",
    "text": "Weighted densities"
  },
  {
    "objectID": "slides/dataviz/19-dataviz-in-practice.html#the-ecological-fallacy",
    "href": "slides/dataviz/19-dataviz-in-practice.html#the-ecological-fallacy",
    "title": "Dataviz In Practice",
    "section": "The ecological fallacy",
    "text": "The ecological fallacy"
  },
  {
    "objectID": "slides/dataviz/19-dataviz-in-practice.html#show-the-data",
    "href": "slides/dataviz/19-dataviz-in-practice.html#show-the-data",
    "title": "Dataviz In Practice",
    "section": "Show the data",
    "text": "Show the data"
  },
  {
    "objectID": "slides/dataviz/19-dataviz-in-practice.html#case-study-2",
    "href": "slides/dataviz/19-dataviz-in-practice.html#case-study-2",
    "title": "Dataviz In Practice",
    "section": "Case study 2",
    "text": "Case study 2\n\nthe_disease &lt;- \"Measles\" \ndat &lt;- us_contagious_diseases |&gt; \n  filter(!state %in% c(\"Hawaii\",\"Alaska\") & disease == the_disease) |&gt; \n  mutate(rate = count / population * 10000 * 52 / weeks_reporting) |&gt;  \n  mutate(state = reorder(state, ifelse(year &lt;= 1963, rate, NA),  \n                         median, na.rm = TRUE))"
  },
  {
    "objectID": "slides/dataviz/19-dataviz-in-practice.html#heatmaps",
    "href": "slides/dataviz/19-dataviz-in-practice.html#heatmaps",
    "title": "Dataviz In Practice",
    "section": "Heatmaps",
    "text": "Heatmaps\n\nlibrary(RColorBrewer)\ndat |&gt; ggplot(aes(year, state, fill = rate)) + \n  geom_tile(color = \"grey50\") + \n  scale_x_continuous(expand = c(0,0)) + \n  scale_fill_gradientn(colors = brewer.pal(9, \"Reds\"), trans = \"sqrt\") + \n  geom_vline(xintercept = 1963, col = \"blue\") + \n  theme_minimal() +   \n  theme(panel.grid = element_blank(),  \n        legend.position = \"bottom\",  \n        text = element_text(size = 8)) + \n  labs(title = the_disease, x = \"\", y = \"\")"
  },
  {
    "objectID": "slides/dataviz/19-dataviz-in-practice.html#heatmaps-1",
    "href": "slides/dataviz/19-dataviz-in-practice.html#heatmaps-1",
    "title": "Dataviz In Practice",
    "section": "Heatmaps",
    "text": "Heatmaps"
  },
  {
    "objectID": "slides/dataviz/19-dataviz-in-practice.html#using-position",
    "href": "slides/dataviz/19-dataviz-in-practice.html#using-position",
    "title": "Dataviz In Practice",
    "section": "Using position",
    "text": "Using position\nWe will show each state and the avearge:\n\navg &lt;- us_contagious_diseases |&gt; \n  filter(disease == the_disease) |&gt; group_by(year) |&gt; \n  summarize(us_rate = sum(count, na.rm = TRUE) /  \n              sum(population, na.rm = TRUE) * 10000)"
  },
  {
    "objectID": "slides/dataviz/19-dataviz-in-practice.html#using-position-1",
    "href": "slides/dataviz/19-dataviz-in-practice.html#using-position-1",
    "title": "Dataviz In Practice",
    "section": "Using position",
    "text": "Using position\n\ndat |&gt;  \n  filter(!is.na(rate)) |&gt; \n    ggplot() + \n  geom_line(aes(year, rate, group = state),  color = \"grey50\",  \n            show.legend = FALSE, alpha = 0.2, linewidth = 1) + \n  geom_line(mapping = aes(year, us_rate),  data = avg, linewidth = 1) + \n  scale_y_continuous(trans = \"sqrt\", breaks = c(5, 25, 125, 300)) +  \n  ggtitle(\"Cases per 10,000 by state\") +  \n  xlab(\"\") + ylab(\"\") + \n  geom_text(data = data.frame(x = 1955, y = 50),  \n            mapping = aes(x, y, label = \"US average\"),  \n            color = \"black\") +  \n  geom_vline(xintercept = 1963, col = \"blue\")"
  },
  {
    "objectID": "slides/dataviz/19-dataviz-in-practice.html#using-position-2",
    "href": "slides/dataviz/19-dataviz-in-practice.html#using-position-2",
    "title": "Dataviz In Practice",
    "section": "Using position",
    "text": "Using position"
  },
  {
    "objectID": "slides/dataviz/17-dataviz-principles.html#some-motivation",
    "href": "slides/dataviz/17-dataviz-principles.html#some-motivation",
    "title": "Data Visualization Principles",
    "section": "Some motivation",
    "text": "Some motivation\n\nThe next few slides are examples of infogrpahics that don’t follow data visualization principles.\nWe use them as motivation.\nSeveral of the examples come from here: https://venngage.com/blog/bad-infographics/"
  },
  {
    "objectID": "slides/dataviz/17-dataviz-principles.html#some-motivation-1",
    "href": "slides/dataviz/17-dataviz-principles.html#some-motivation-1",
    "title": "Data Visualization Principles",
    "section": "Some motivation",
    "text": "Some motivation"
  },
  {
    "objectID": "slides/dataviz/17-dataviz-principles.html#some-motivation-2",
    "href": "slides/dataviz/17-dataviz-principles.html#some-motivation-2",
    "title": "Data Visualization Principles",
    "section": "Some motivation",
    "text": "Some motivation"
  },
  {
    "objectID": "slides/dataviz/17-dataviz-principles.html#some-motivation-3",
    "href": "slides/dataviz/17-dataviz-principles.html#some-motivation-3",
    "title": "Data Visualization Principles",
    "section": "Some motivation",
    "text": "Some motivation"
  },
  {
    "objectID": "slides/dataviz/17-dataviz-principles.html#some-motivation-4",
    "href": "slides/dataviz/17-dataviz-principles.html#some-motivation-4",
    "title": "Data Visualization Principles",
    "section": "Some motivation",
    "text": "Some motivation"
  },
  {
    "objectID": "slides/dataviz/17-dataviz-principles.html#some-motivation-5",
    "href": "slides/dataviz/17-dataviz-principles.html#some-motivation-5",
    "title": "Data Visualization Principles",
    "section": "Some motivation",
    "text": "Some motivation"
  },
  {
    "objectID": "slides/dataviz/17-dataviz-principles.html#some-motivation-6",
    "href": "slides/dataviz/17-dataviz-principles.html#some-motivation-6",
    "title": "Data Visualization Principles",
    "section": "Some motivation",
    "text": "Some motivation"
  },
  {
    "objectID": "slides/dataviz/17-dataviz-principles.html#some-motivation-7",
    "href": "slides/dataviz/17-dataviz-principles.html#some-motivation-7",
    "title": "Data Visualization Principles",
    "section": "Some motivation",
    "text": "Some motivation"
  },
  {
    "objectID": "slides/dataviz/17-dataviz-principles.html#data-visualization-principles",
    "href": "slides/dataviz/17-dataviz-principles.html#data-visualization-principles",
    "title": "Data Visualization Principles",
    "section": "Data visualization principles",
    "text": "Data visualization principles\n\nWe provide some general principles we can use as a guide for effective data visualization.\nMuch of this section is based on a talk by Karl Broman titled Creating Effective Figures and Tables and includes some of the figures which were made with code that Karl makes available on his GitHub repository, as well as class notes from Peter Aldhous’ Introduction to Data Visualization course."
  },
  {
    "objectID": "slides/dataviz/17-dataviz-principles.html#data-visualization-principles-1",
    "href": "slides/dataviz/17-dataviz-principles.html#data-visualization-principles-1",
    "title": "Data Visualization Principles",
    "section": "Data visualization principles",
    "text": "Data visualization principles\n\nFollowing Karl’s approach, we show some examples of plot styles we should avoid, explain how to improve them, and use these as motivation for a list of principles.\nWe compare and contrast plots that follow these principles to those that don’t."
  },
  {
    "objectID": "slides/dataviz/17-dataviz-principles.html#data-visualization-principles-2",
    "href": "slides/dataviz/17-dataviz-principles.html#data-visualization-principles-2",
    "title": "Data Visualization Principles",
    "section": "Data visualization principles",
    "text": "Data visualization principles\n\nThe principles are mostly based on research related to how humans detect patterns and make visual comparisons.\nThe preferred approaches are those that best fit the way our brains process visual information.\nWhen deciding on a visualization approach, it is also important to keep our goal in mind."
  },
  {
    "objectID": "slides/dataviz/17-dataviz-principles.html#data-visualization-principles-3",
    "href": "slides/dataviz/17-dataviz-principles.html#data-visualization-principles-3",
    "title": "Data Visualization Principles",
    "section": "Data visualization principles",
    "text": "Data visualization principles\nWe may be comparing a\n\nViewable number of quantities.\nDescribing distributions for categories or numeric values.\nComparing the data from two groups.\nDescribing the relationship between two variables."
  },
  {
    "objectID": "slides/dataviz/17-dataviz-principles.html#encoding-data-using-visual-cues",
    "href": "slides/dataviz/17-dataviz-principles.html#encoding-data-using-visual-cues",
    "title": "Data Visualization Principles",
    "section": "Encoding data using visual cues",
    "text": "Encoding data using visual cues\nWe start by describing some principles for visualy encoding numerical values:\n\naligned lengths\nposition\nangles\narea\nbrightness\ncolor hue"
  },
  {
    "objectID": "slides/dataviz/17-dataviz-principles.html#encoding-data-using-visual-cues-1",
    "href": "slides/dataviz/17-dataviz-principles.html#encoding-data-using-visual-cues-1",
    "title": "Data Visualization Principles",
    "section": "Encoding data using visual cues",
    "text": "Encoding data using visual cues\nExample:\n\nSuppose we want to report the results from two hypothetical polls regarding browser preference taken in 2000 and then 2015.\nFor each year, we are simply comparing five quantities – the five percentages for Opera, Safari, Firefox,IE, and Chrome."
  },
  {
    "objectID": "slides/dataviz/17-dataviz-principles.html#encoding-data-using-visual-cues-2",
    "href": "slides/dataviz/17-dataviz-principles.html#encoding-data-using-visual-cues-2",
    "title": "Data Visualization Principles",
    "section": "Encoding data using visual cues",
    "text": "Encoding data using visual cues\nA widely used graphical representation of percentages, popularized by Microsoft Excel, is the pie chart:"
  },
  {
    "objectID": "slides/dataviz/17-dataviz-principles.html#encoding-data-using-visual-cues-3",
    "href": "slides/dataviz/17-dataviz-principles.html#encoding-data-using-visual-cues-3",
    "title": "Data Visualization Principles",
    "section": "Encoding data using visual cues",
    "text": "Encoding data using visual cues\n\nHere we are representing quantities with both areas and angles, since both the angle and area of each pie slice are proportional to the quantity the slice represents.\nThis turns out to be a sub-optimal choice since, as demonstrated by perception studies, humans are not good at precisely quantifying angles and are even worse when area is the only available visual cue."
  },
  {
    "objectID": "slides/dataviz/17-dataviz-principles.html#encoding-data-using-visual-cues-4",
    "href": "slides/dataviz/17-dataviz-principles.html#encoding-data-using-visual-cues-4",
    "title": "Data Visualization Principles",
    "section": "Encoding data using visual cues",
    "text": "Encoding data using visual cues\nThe donut chart uses only area:"
  },
  {
    "objectID": "slides/dataviz/17-dataviz-principles.html#compare-2000-to-2015",
    "href": "slides/dataviz/17-dataviz-principles.html#compare-2000-to-2015",
    "title": "Data Visualization Principles",
    "section": "Compare 2000 to 2015",
    "text": "Compare 2000 to 2015\n\nCan you determine the actual percentages and rank the browsers’ popularity?\nCan you see how they changed from 2000 to 2015?"
  },
  {
    "objectID": "slides/dataviz/17-dataviz-principles.html#show-the-numbers",
    "href": "slides/dataviz/17-dataviz-principles.html#show-the-numbers",
    "title": "Data Visualization Principles",
    "section": "Show the numbers",
    "text": "Show the numbers\nA better approach is to simply show the numbers. It is not only clearer, but would also save on printing costs if printing a paper copy:\n\n\n\n\n\nBrowser\n2000\n2015\n\n\n\n\nOpera\n3\n2\n\n\nSafari\n21\n22\n\n\nFirefox\n23\n21\n\n\nChrome\n26\n29\n\n\nIE\n28\n27"
  },
  {
    "objectID": "slides/dataviz/17-dataviz-principles.html#barplots",
    "href": "slides/dataviz/17-dataviz-principles.html#barplots",
    "title": "Data Visualization Principles",
    "section": "Barplots",
    "text": "Barplots\nLength is the best visual cue:"
  },
  {
    "objectID": "slides/dataviz/17-dataviz-principles.html#if-foreced-to-make-a-pie-chart",
    "href": "slides/dataviz/17-dataviz-principles.html#if-foreced-to-make-a-pie-chart",
    "title": "Data Visualization Principles",
    "section": "If foreced to make a pie chart",
    "text": "If foreced to make a pie chart\nLabel each pie slice with its respective percentage so viewers do not have to infer them:"
  },
  {
    "objectID": "slides/dataviz/17-dataviz-principles.html#know-when-to-include-0",
    "href": "slides/dataviz/17-dataviz-principles.html#know-when-to-include-0",
    "title": "Data Visualization Principles",
    "section": "Know when to include 0",
    "text": "Know when to include 0\n\nWhen using barplots, it is misinformative not to start the bars at 0.\nThis is because, by using a barplot, we are implying the length is proportional to the quantities being displayed.\nBy avoiding 0, relatively small differences can be made to look much bigger than they actually are.\nThis approach is often used by politicians or media organizations trying to exaggerate a difference."
  },
  {
    "objectID": "slides/dataviz/17-dataviz-principles.html#know-when-to-include-0-1",
    "href": "slides/dataviz/17-dataviz-principles.html#know-when-to-include-0-1",
    "title": "Data Visualization Principles",
    "section": "Know when to include 0",
    "text": "Know when to include 0\nBelow is an illustrative example used by Peter Aldhous in this lecture.\n\n\n\n\n\n(Source: Fox News, via Media Matters.)"
  },
  {
    "objectID": "slides/dataviz/17-dataviz-principles.html#know-when-to-include-0-2",
    "href": "slides/dataviz/17-dataviz-principles.html#know-when-to-include-0-2",
    "title": "Data Visualization Principles",
    "section": "Know when to include 0",
    "text": "Know when to include 0\nHere is the correct plot:"
  },
  {
    "objectID": "slides/dataviz/17-dataviz-principles.html#know-when-to-include-0-3",
    "href": "slides/dataviz/17-dataviz-principles.html#know-when-to-include-0-3",
    "title": "Data Visualization Principles",
    "section": "Know when to include 0",
    "text": "Know when to include 0\nAnother examples:\n\n\n\n\n\n(Source: Fox News, via Flowing Data.)"
  },
  {
    "objectID": "slides/dataviz/17-dataviz-principles.html#know-when-to-include-0-4",
    "href": "slides/dataviz/17-dataviz-principles.html#know-when-to-include-0-4",
    "title": "Data Visualization Principles",
    "section": "Know when to include 0",
    "text": "Know when to include 0\nAnd here is the correct plot:"
  },
  {
    "objectID": "slides/dataviz/17-dataviz-principles.html#know-when-to-include-0-5",
    "href": "slides/dataviz/17-dataviz-principles.html#know-when-to-include-0-5",
    "title": "Data Visualization Principles",
    "section": "Know when to include 0",
    "text": "Know when to include 0\nOne more example:\n\n\n\n\n\n(Source: Venezolana de Televisión via Pakistan Today and Diego Mariano.)"
  },
  {
    "objectID": "slides/dataviz/17-dataviz-principles.html#know-when-to-include-0-6",
    "href": "slides/dataviz/17-dataviz-principles.html#know-when-to-include-0-6",
    "title": "Data Visualization Principles",
    "section": "Know when to include 0",
    "text": "Know when to include 0\nHere is the appropriate plot:"
  },
  {
    "objectID": "slides/dataviz/17-dataviz-principles.html#know-when-to-include-0-7",
    "href": "slides/dataviz/17-dataviz-principles.html#know-when-to-include-0-7",
    "title": "Data Visualization Principles",
    "section": "Know when to include 0",
    "text": "Know when to include 0\n\nWhen using position rather than length, it is not necessary to include 0.\nIn particularly when comparing between to within groups variability."
  },
  {
    "objectID": "slides/dataviz/17-dataviz-principles.html#do-not-distort-quantities",
    "href": "slides/dataviz/17-dataviz-principles.html#do-not-distort-quantities",
    "title": "Data Visualization Principles",
    "section": "Do not distort quantities",
    "text": "Do not distort quantities\nPresident Obama used the following chart to compare the US GDP to the GDP of four competing nations:\n\n\n\n\n\n(Source: The 2011 State of the Union Address)"
  },
  {
    "objectID": "slides/dataviz/17-dataviz-principles.html#do-not-distort-quantities-1",
    "href": "slides/dataviz/17-dataviz-principles.html#do-not-distort-quantities-1",
    "title": "Data Visualization Principles",
    "section": "Do not distort quantities",
    "text": "Do not distort quantities\nHere is comparison of using radius versus area:"
  },
  {
    "objectID": "slides/dataviz/17-dataviz-principles.html#do-not-distort-quantities-2",
    "href": "slides/dataviz/17-dataviz-principles.html#do-not-distort-quantities-2",
    "title": "Data Visualization Principles",
    "section": "Do not distort quantities",
    "text": "Do not distort quantities\n\nggplot2 defaults to using area rather than radius.\nOf course, in this case, we really should be using length:"
  },
  {
    "objectID": "slides/dataviz/17-dataviz-principles.html#order-categories-by-a-meaningful-value",
    "href": "slides/dataviz/17-dataviz-principles.html#order-categories-by-a-meaningful-value",
    "title": "Data Visualization Principles",
    "section": "Order categories by a meaningful value",
    "text": "Order categories by a meaningful value\n\nWhen one of the axes is used to show categories the default ggplot2 behavior is to order the categories alphabetically when they are defined by character strings.\nIf they are defined by factors, they are ordered by the factor levels.\nWe rarely want to use alphabetical order.\nInstead, we should order by a meaningful quantity."
  },
  {
    "objectID": "slides/dataviz/17-dataviz-principles.html#order-categories-by-a-meaningful-value-1",
    "href": "slides/dataviz/17-dataviz-principles.html#order-categories-by-a-meaningful-value-1",
    "title": "Data Visualization Principles",
    "section": "Order categories by a meaningful value",
    "text": "Order categories by a meaningful value\nNote that the plot on the right is more informative:"
  },
  {
    "objectID": "slides/dataviz/17-dataviz-principles.html#order-categories-by-a-meaningful-value-2",
    "href": "slides/dataviz/17-dataviz-principles.html#order-categories-by-a-meaningful-value-2",
    "title": "Data Visualization Principles",
    "section": "Order categories by a meaningful value",
    "text": "Order categories by a meaningful value\nHere is another example:"
  },
  {
    "objectID": "slides/dataviz/17-dataviz-principles.html#show-the-data",
    "href": "slides/dataviz/17-dataviz-principles.html#show-the-data",
    "title": "Data Visualization Principles",
    "section": "Show the data",
    "text": "Show the data\n\nWe have focused on displaying single quantities across categories. We now shift our attention to displaying data, with a focus on comparing groups.\nSuppose we want to describe height data to an extra-terrestrial."
  },
  {
    "objectID": "slides/dataviz/17-dataviz-principles.html#show-the-data-1",
    "href": "slides/dataviz/17-dataviz-principles.html#show-the-data-1",
    "title": "Data Visualization Principles",
    "section": "Show the data",
    "text": "Show the data\nA commonly used plot, popularized by Microsoft Excel, is a barplot like this:"
  },
  {
    "objectID": "slides/dataviz/17-dataviz-principles.html#show-the-data-2",
    "href": "slides/dataviz/17-dataviz-principles.html#show-the-data-2",
    "title": "Data Visualization Principles",
    "section": "Show the data",
    "text": "Show the data"
  },
  {
    "objectID": "slides/dataviz/17-dataviz-principles.html#show-the-data-3",
    "href": "slides/dataviz/17-dataviz-principles.html#show-the-data-3",
    "title": "Data Visualization Principles",
    "section": "Show the data",
    "text": "Show the data\nUse jitter to avoid over-plotting"
  },
  {
    "objectID": "slides/dataviz/17-dataviz-principles.html#histograms",
    "href": "slides/dataviz/17-dataviz-principles.html#histograms",
    "title": "Data Visualization Principles",
    "section": "Histograms",
    "text": "Histograms\nSince there are so many points, it is more effective to show distributions rather than individual points. We therefore show histograms for each group:"
  },
  {
    "objectID": "slides/dataviz/17-dataviz-principles.html#ease-comparisons",
    "href": "slides/dataviz/17-dataviz-principles.html#ease-comparisons",
    "title": "Data Visualization Principles",
    "section": "Ease comparisons",
    "text": "Ease comparisons\n\nUse common axes\nIf horizontal comparison, stack graphs vertically\nIf vertical comparison, stack graphs horizontally"
  },
  {
    "objectID": "slides/dataviz/17-dataviz-principles.html#stack-vertically",
    "href": "slides/dataviz/17-dataviz-principles.html#stack-vertically",
    "title": "Data Visualization Principles",
    "section": "Stack vertically",
    "text": "Stack vertically"
  },
  {
    "objectID": "slides/dataviz/17-dataviz-principles.html#same-axis",
    "href": "slides/dataviz/17-dataviz-principles.html#same-axis",
    "title": "Data Visualization Principles",
    "section": "Same axis",
    "text": "Same axis"
  },
  {
    "objectID": "slides/dataviz/17-dataviz-principles.html#boxplot-is-a-vertical",
    "href": "slides/dataviz/17-dataviz-principles.html#boxplot-is-a-vertical",
    "title": "Data Visualization Principles",
    "section": "Boxplot is a vertical",
    "text": "Boxplot is a vertical\nStack horizontally"
  },
  {
    "objectID": "slides/dataviz/17-dataviz-principles.html#contrast-and-compare",
    "href": "slides/dataviz/17-dataviz-principles.html#contrast-and-compare",
    "title": "Data Visualization Principles",
    "section": "Contrast and compare",
    "text": "Contrast and compare"
  },
  {
    "objectID": "slides/dataviz/17-dataviz-principles.html#consider-transformations",
    "href": "slides/dataviz/17-dataviz-principles.html#consider-transformations",
    "title": "Data Visualization Principles",
    "section": "Consider transformations",
    "text": "Consider transformations\nHere is a terrible plot comparing population across continents"
  },
  {
    "objectID": "slides/dataviz/17-dataviz-principles.html#two-countries-drive-average",
    "href": "slides/dataviz/17-dataviz-principles.html#two-countries-drive-average",
    "title": "Data Visualization Principles",
    "section": "Two countries drive average",
    "text": "Two countries drive average"
  },
  {
    "objectID": "slides/dataviz/17-dataviz-principles.html#transformations",
    "href": "slides/dataviz/17-dataviz-principles.html#transformations",
    "title": "Data Visualization Principles",
    "section": "Transformations",
    "text": "Transformations\nHere a log transformation provides a much more informative plot:"
  },
  {
    "objectID": "slides/dataviz/17-dataviz-principles.html#visual-cues-to-be-compared-should-be-adjacent",
    "href": "slides/dataviz/17-dataviz-principles.html#visual-cues-to-be-compared-should-be-adjacent",
    "title": "Data Visualization Principles",
    "section": "Visual cues to be compared should be adjacent",
    "text": "Visual cues to be compared should be adjacent\nNote that it is hard to compare 1970 to 2020 by country:"
  },
  {
    "objectID": "slides/dataviz/17-dataviz-principles.html#visual-cues-to-be-compared-should-be-adjacent-1",
    "href": "slides/dataviz/17-dataviz-principles.html#visual-cues-to-be-compared-should-be-adjacent-1",
    "title": "Data Visualization Principles",
    "section": "Visual cues to be compared should be adjacent",
    "text": "Visual cues to be compared should be adjacent\nMuch easier if they are adjacent"
  },
  {
    "objectID": "slides/dataviz/17-dataviz-principles.html#use-color",
    "href": "slides/dataviz/17-dataviz-principles.html#use-color",
    "title": "Data Visualization Principles",
    "section": "Use color",
    "text": "Use color\nThe comparison becomes even easier to make if we use color to denote the two things we want to compare:"
  },
  {
    "objectID": "slides/dataviz/17-dataviz-principles.html#think-of-the-color-blind",
    "href": "slides/dataviz/17-dataviz-principles.html#think-of-the-color-blind",
    "title": "Data Visualization Principles",
    "section": "Think of the color blind",
    "text": "Think of the color blind\n\nApproximately 1 in 12 men (8%) and 1 in 200 women (0.5%) worldwide are color blind.\nThe most common type of color blindness is red-green color blindness, which affects around 99% of all color blind individuals.\nThe prevalence of blue-yellow color blindness and total color blindness (achromatopsia) is much lower.\nAn example of how we can use a color blind friendly palette is described here."
  },
  {
    "objectID": "slides/dataviz/17-dataviz-principles.html#think-of-the-color-blind-1",
    "href": "slides/dataviz/17-dataviz-principles.html#think-of-the-color-blind-1",
    "title": "Data Visualization Principles",
    "section": "Think of the color blind",
    "text": "Think of the color blind\n\nExample of color-blind-friendly color palette:"
  },
  {
    "objectID": "slides/dataviz/17-dataviz-principles.html#plots-for-two-variables",
    "href": "slides/dataviz/17-dataviz-principles.html#plots-for-two-variables",
    "title": "Data Visualization Principles",
    "section": "Plots for two variables",
    "text": "Plots for two variables\nIn general, you should use scatterplots to visualize the relationship between two variables.\nHowever, there are some exceptions.\n\nWe describe two alternative plots here:\n\nslope chart\nBland-Altman plot"
  },
  {
    "objectID": "slides/dataviz/17-dataviz-principles.html#slope-charts",
    "href": "slides/dataviz/17-dataviz-principles.html#slope-charts",
    "title": "Data Visualization Principles",
    "section": "Slope charts",
    "text": "Slope charts\nSlope charts adds angle as a visual cue, useful when comparing two groups and each element across two variables, such as years."
  },
  {
    "objectID": "slides/dataviz/17-dataviz-principles.html#scatterplot-version",
    "href": "slides/dataviz/17-dataviz-principles.html#scatterplot-version",
    "title": "Data Visualization Principles",
    "section": "Scatterplot version",
    "text": "Scatterplot version"
  },
  {
    "objectID": "slides/dataviz/17-dataviz-principles.html#bland-altman-plot",
    "href": "slides/dataviz/17-dataviz-principles.html#bland-altman-plot",
    "title": "Data Visualization Principles",
    "section": "Bland-Altman plot",
    "text": "Bland-Altman plot\nShows difference in the y-axis and average on the x-axis."
  },
  {
    "objectID": "slides/dataviz/17-dataviz-principles.html#encoding-a-third-variable",
    "href": "slides/dataviz/17-dataviz-principles.html#encoding-a-third-variable",
    "title": "Data Visualization Principles",
    "section": "Encoding a third variable",
    "text": "Encoding a third variable\nWe can use\n\ndifferent colors or shapes for categoris\nareas, brightness or hue for continuous values"
  },
  {
    "objectID": "slides/dataviz/17-dataviz-principles.html#encoding-a-third-variable-1",
    "href": "slides/dataviz/17-dataviz-principles.html#encoding-a-third-variable-1",
    "title": "Data Visualization Principles",
    "section": "Encoding a third variable",
    "text": "Encoding a third variable\nWe encode OPEC membership, region, and population."
  },
  {
    "objectID": "slides/dataviz/17-dataviz-principles.html#point-shapes-available-in-r",
    "href": "slides/dataviz/17-dataviz-principles.html#point-shapes-available-in-r",
    "title": "Data Visualization Principles",
    "section": "Point shapes available in R",
    "text": "Point shapes available in R"
  },
  {
    "objectID": "slides/dataviz/17-dataviz-principles.html#using-intensity-or-hue",
    "href": "slides/dataviz/17-dataviz-principles.html#using-intensity-or-hue",
    "title": "Data Visualization Principles",
    "section": "Using intensity or hue",
    "text": "Using intensity or hue\nWhen selecting colors to quantify a numeric variable, we choose between two options: sequential and diverging."
  },
  {
    "objectID": "slides/dataviz/17-dataviz-principles.html#sequential-colors",
    "href": "slides/dataviz/17-dataviz-principles.html#sequential-colors",
    "title": "Data Visualization Principles",
    "section": "Sequential colors",
    "text": "Sequential colors\nSequential colors are suited for data that goes from high to low. High values are clearly distinguished from low values. Here are some examples offered by the package RColorBrewer:"
  },
  {
    "objectID": "slides/dataviz/17-dataviz-principles.html#diverging-colors",
    "href": "slides/dataviz/17-dataviz-principles.html#diverging-colors",
    "title": "Data Visualization Principles",
    "section": "Diverging colors",
    "text": "Diverging colors\nDiverging colors are used to represent values that diverge from a center. We put equal emphasis on both ends of the data range: higher than the center and lower than the center."
  },
  {
    "objectID": "slides/dataviz/17-dataviz-principles.html#avoid-pseudo-3d-plots",
    "href": "slides/dataviz/17-dataviz-principles.html#avoid-pseudo-3d-plots",
    "title": "Data Visualization Principles",
    "section": "Avoid pseudo-3D plots",
    "text": "Avoid pseudo-3D plots\nThe figure below, taken from the scientific literature, shows three variables: dose, drug type and survival:"
  },
  {
    "objectID": "slides/dataviz/17-dataviz-principles.html#avoid-pseudo-3d-plots-1",
    "href": "slides/dataviz/17-dataviz-principles.html#avoid-pseudo-3d-plots-1",
    "title": "Data Visualization Principles",
    "section": "Avoid pseudo-3D plots",
    "text": "Avoid pseudo-3D plots\n\nHumans are not good at seeing in three dimensions and our limitation is even worse with regard to pseudo-three-dimensions."
  },
  {
    "objectID": "slides/dataviz/17-dataviz-principles.html#avoid-pseudo-3d-plots-2",
    "href": "slides/dataviz/17-dataviz-principles.html#avoid-pseudo-3d-plots-2",
    "title": "Data Visualization Principles",
    "section": "Avoid pseudo-3D plots",
    "text": "Avoid pseudo-3D plots\n\nWhen does the purple ribbon intersects the red?"
  },
  {
    "objectID": "slides/dataviz/17-dataviz-principles.html#avoid-pseudo-3d-plots-3",
    "href": "slides/dataviz/17-dataviz-principles.html#avoid-pseudo-3d-plots-3",
    "title": "Data Visualization Principles",
    "section": "Avoid pseudo-3D plots",
    "text": "Avoid pseudo-3D plots\nColor is enough to represent the categorical variable:"
  },
  {
    "objectID": "slides/dataviz/17-dataviz-principles.html#avoid-pseudo-3d-plots-4",
    "href": "slides/dataviz/17-dataviz-principles.html#avoid-pseudo-3d-plots-4",
    "title": "Data Visualization Principles",
    "section": "Avoid pseudo-3D plots",
    "text": "Avoid pseudo-3D plots\nPseudo-3D is sometimes used completely gratuitously: plots are made to look 3D even when the 3rd dimension does not represent a quantity. This only adds confusion and makes it harder to relay your message. We show two examples:"
  },
  {
    "objectID": "slides/dataviz/17-dataviz-principles.html#avoid-pseudo-3d-plots-5",
    "href": "slides/dataviz/17-dataviz-principles.html#avoid-pseudo-3d-plots-5",
    "title": "Data Visualization Principles",
    "section": "Avoid pseudo-3D plots",
    "text": "Avoid pseudo-3D plots\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(Images courtesy of Karl Broman)"
  },
  {
    "objectID": "slides/dataviz/17-dataviz-principles.html#avoid-too-many-significant-digits",
    "href": "slides/dataviz/17-dataviz-principles.html#avoid-too-many-significant-digits",
    "title": "Data Visualization Principles",
    "section": "Avoid too many significant digits",
    "text": "Avoid too many significant digits\n\nBy default, statistical software like R returns many significant digits.\nThe default behavior in R is to show 7 significant digits.\nThat many digits often adds no information and the added visual clutter can make it hard for the viewer to understand the message."
  },
  {
    "objectID": "slides/dataviz/17-dataviz-principles.html#avoid-too-many-significant-digits-1",
    "href": "slides/dataviz/17-dataviz-principles.html#avoid-too-many-significant-digits-1",
    "title": "Data Visualization Principles",
    "section": "Avoid too many significant digits",
    "text": "Avoid too many significant digits\nAs an example, here are the per 10,000 disease rates, computed from totals and population in R, for California across the five decades:\n\n\n\n\n\nstate\nyear\nMeasles\nPertussis\nPolio\n\n\n\n\nCalifornia\n1940\n37.8826320\n18.3397861\n0.8266512\n\n\nCalifornia\n1950\n13.9124205\n4.7467350\n1.9742639\n\n\nCalifornia\n1960\n14.1386471\nNA\n0.2640419\n\n\nCalifornia\n1970\n0.9767889\nNA\nNA\n\n\nCalifornia\n1980\n0.3743467\n0.0515466\nNA"
  },
  {
    "objectID": "slides/dataviz/17-dataviz-principles.html#avoid-too-many-significant-digits-2",
    "href": "slides/dataviz/17-dataviz-principles.html#avoid-too-many-significant-digits-2",
    "title": "Data Visualization Principles",
    "section": "Avoid too many significant digits",
    "text": "Avoid too many significant digits\n\nWe are reporting precision up to 0.00001 cases per 10,000, a very small value in the context of the changes that are occurring across the dates.\n\n\n\n\n\n\nstate\nyear\nMeasles\nPertussis\nPolio\n\n\n\n\nCalifornia\n1940\n37.8826320\n18.3397861\n0.8266512\n\n\nCalifornia\n1950\n13.9124205\n4.7467350\n1.9742639\n\n\nCalifornia\n1960\n14.1386471\nNA\n0.2640419\n\n\nCalifornia\n1970\n0.9767889\nNA\nNA\n\n\nCalifornia\n1980\n0.3743467\n0.0515466\nNA"
  },
  {
    "objectID": "slides/dataviz/17-dataviz-principles.html#avoid-too-many-significant-digits-3",
    "href": "slides/dataviz/17-dataviz-principles.html#avoid-too-many-significant-digits-3",
    "title": "Data Visualization Principles",
    "section": "Avoid too many significant digits",
    "text": "Avoid too many significant digits\n\nIn this case, two significant figures is more than enough and clearly makes the point that rates are decreasing:\n\n\n\n\n\n\nstate\nyear\nMeasles\nPertussis\nPolio\n\n\n\n\nCalifornia\n1940\n37.9\n18.3\n0.8\n\n\nCalifornia\n1950\n13.9\n4.7\n2.0\n\n\nCalifornia\n1960\n14.1\nNA\n0.3\n\n\nCalifornia\n1970\n1.0\nNA\nNA\n\n\nCalifornia\n1980\n0.4\n0.1\nNA"
  },
  {
    "objectID": "slides/dataviz/17-dataviz-principles.html#avoid-too-many-significant-digits-4",
    "href": "slides/dataviz/17-dataviz-principles.html#avoid-too-many-significant-digits-4",
    "title": "Data Visualization Principles",
    "section": "Avoid too many significant digits",
    "text": "Avoid too many significant digits\nUseful ways to change the number of significant digits or to round numbers are\n\nsignif\nround\n\nYou can define the number of significant digits globally by setting options like this: options(digits = 3)."
  },
  {
    "objectID": "slides/dataviz/17-dataviz-principles.html#values-compared-in-columns",
    "href": "slides/dataviz/17-dataviz-principles.html#values-compared-in-columns",
    "title": "Data Visualization Principles",
    "section": "Values compared in columns",
    "text": "Values compared in columns\nAnother principle related to displaying tables is to place values being compared on columns rather than rows. Compare these two presentations:\n\n\n\n\n\nstate\ndisease\n1940\n1950\n1960\n1970\n1980\n\n\n\n\nCalifornia\nMeasles\n37.9\n13.9\n14.1\n1\n0.4\n\n\nCalifornia\nPertussis\n18.3\n4.7\nNA\nNA\n0.1\n\n\nCalifornia\nPolio\n0.8\n2.0\n0.3\nNA\nNA"
  },
  {
    "objectID": "slides/dataviz/17-dataviz-principles.html#values-compared-in-columns-1",
    "href": "slides/dataviz/17-dataviz-principles.html#values-compared-in-columns-1",
    "title": "Data Visualization Principles",
    "section": "Values compared in columns",
    "text": "Values compared in columns\nAnother principle related to displaying tables is to place values being compared on columns rather than rows. Compare these two presentations:\n\n\n\n\n\nstate\nyear\nMeasles\nPertussis\nPolio\n\n\n\n\nCalifornia\n1940\n37.9\n18.3\n0.8\n\n\nCalifornia\n1950\n13.9\n4.7\n2.0\n\n\nCalifornia\n1960\n14.1\nNA\n0.3\n\n\nCalifornia\n1970\n1.0\nNA\nNA\n\n\nCalifornia\n1980\n0.4\n0.1\nNA"
  },
  {
    "objectID": "slides/dataviz/17-dataviz-principles.html#know-your-audience",
    "href": "slides/dataviz/17-dataviz-principles.html#know-your-audience",
    "title": "Data Visualization Principles",
    "section": "Know your audience",
    "text": "Know your audience\nGraphs can be used for\n\nour own exploratory data analysis,\nto convey a message to experts, or\nto help tell a story to a general audience.\n\nMake sure that the intended audience understands each element of the plot."
  },
  {
    "objectID": "slides/prob/21-inference-foundations.html#sampling-models",
    "href": "slides/prob/21-inference-foundations.html#sampling-models",
    "title": "Foundations of Statistical Inference",
    "section": "Sampling models",
    "text": "Sampling models\n\nMany data generation procedures can be effectively modeled as draws from an urn.\nWe can model the process of polling likely voters as drawing 0s for one party and 1s for the other.\nEpidemiologist assume subjects in their studies are a random sample from the population of interest."
  },
  {
    "objectID": "slides/prob/21-inference-foundations.html#sampling-models-1",
    "href": "slides/prob/21-inference-foundations.html#sampling-models-1",
    "title": "Foundations of Statistical Inference",
    "section": "Sampling models",
    "text": "Sampling models\n\nIn general, the data related to a specific outcome can be modeled as a random sample from an urn containing the outcomes for the entire population of interest."
  },
  {
    "objectID": "slides/prob/21-inference-foundations.html#sampling-models-2",
    "href": "slides/prob/21-inference-foundations.html#sampling-models-2",
    "title": "Foundations of Statistical Inference",
    "section": "Sampling models",
    "text": "Sampling models\n\nSimilarly, in experimental research, we often assume that the individual organisms we are studying, for example worms, flies, or mice, are a random sample from a larger population.\nRandomized experiments can be modeled by draws from an urn, reflecting the way individuals are assigned into group; when getting assigned, individuals draw their group at random."
  },
  {
    "objectID": "slides/prob/21-inference-foundations.html#sampling-models-3",
    "href": "slides/prob/21-inference-foundations.html#sampling-models-3",
    "title": "Foundations of Statistical Inference",
    "section": "Sampling models",
    "text": "Sampling models\n\nSampling models are therefore ubiquitous in data science.\nCasino games offer a plethora of real-world cases in which sampling models are used to answer specific questions.\nWe will therefore start with these examples."
  },
  {
    "objectID": "slides/prob/21-inference-foundations.html#sampling-models-4",
    "href": "slides/prob/21-inference-foundations.html#sampling-models-4",
    "title": "Foundations of Statistical Inference",
    "section": "Sampling models",
    "text": "Sampling models\n\nSuppose a very small casino hires you to consult on whether they should set up roulette wheels.\nWe will assume that 1,000 people will play, and that the only game available on the roulette wheel is to bet on red or black.\nThe casino wants you to predict how much money they will make or lose.\nThey want a range of values and, in particular, they want to know what’s the chance of losing money."
  },
  {
    "objectID": "slides/prob/21-inference-foundations.html#sampling-models-5",
    "href": "slides/prob/21-inference-foundations.html#sampling-models-5",
    "title": "Foundations of Statistical Inference",
    "section": "Sampling models",
    "text": "Sampling models\n\nIf this probability is too high, they will decide against installing roulette wheels.\nWe are going to define a random variable \\(S\\) that will represent the casino’s total winnings."
  },
  {
    "objectID": "slides/prob/21-inference-foundations.html#sampling-models-6",
    "href": "slides/prob/21-inference-foundations.html#sampling-models-6",
    "title": "Foundations of Statistical Inference",
    "section": "Sampling models",
    "text": "Sampling models\nThis is a roullette:"
  },
  {
    "objectID": "slides/prob/21-inference-foundations.html#sampling-models-7",
    "href": "slides/prob/21-inference-foundations.html#sampling-models-7",
    "title": "Foundations of Statistical Inference",
    "section": "Sampling models",
    "text": "Sampling models\n\nLet’s start by constructing the urn.\nA roulette wheel has 18 red pockets, 18 black pockets and 2 green ones.\nSo playing a color in one game of roulette is equivalent to drawing from this urn:\n\n\ncolor &lt;- rep(c(\"Black\", \"Red\", \"Green\"), c(18, 18, 2))"
  },
  {
    "objectID": "slides/prob/21-inference-foundations.html#sampling-models-8",
    "href": "slides/prob/21-inference-foundations.html#sampling-models-8",
    "title": "Foundations of Statistical Inference",
    "section": "Sampling models",
    "text": "Sampling models\n\nThe 1,000 outcomes from 1,000 people playing are independent draws from this urn.\nIf red comes up, the gambler wins, and the casino loses a dollar, resulting random variable being -$1.\nOtherwise, the casino wins a dollar, and the random variable is $1."
  },
  {
    "objectID": "slides/prob/21-inference-foundations.html#sampling-models-9",
    "href": "slides/prob/21-inference-foundations.html#sampling-models-9",
    "title": "Foundations of Statistical Inference",
    "section": "Sampling models",
    "text": "Sampling models\n\nTo construct our random variable \\(S\\), we can use this code:\n\n\nn &lt;- 1000 \nx &lt;- sample(ifelse(color == \"Red\", -1, 1),  n, replace = TRUE) \nx[1:10] \n#&gt;  [1]  1 -1  1 -1  1  1 -1  1  1  1"
  },
  {
    "objectID": "slides/prob/21-inference-foundations.html#sampling-models-10",
    "href": "slides/prob/21-inference-foundations.html#sampling-models-10",
    "title": "Foundations of Statistical Inference",
    "section": "Sampling models",
    "text": "Sampling models\n\nBecause we know the proportions of 1s and -1s, we can generate the draws without defining color.\n\n\nx &lt;- sample(c(-1, 1), n, replace = TRUE, prob = c(9/19, 10/19))"
  },
  {
    "objectID": "slides/prob/21-inference-foundations.html#sampling-models-11",
    "href": "slides/prob/21-inference-foundations.html#sampling-models-11",
    "title": "Foundations of Statistical Inference",
    "section": "Sampling models",
    "text": "Sampling models\n\nThis is a sampling model, as it models the random behavior through the sampling of draws from an urn.\nThe total winnings \\(S\\) is simply the sum of these 1,000 independent draws:\n\n\nx &lt;- sample(c(-1, 1), n, replace = TRUE, prob = c(9/19, 10/19)) \ns &lt;- sum(x) \ns \n#&gt; [1] 44\n\n\nIf you rerun the code above, you see that \\(S\\) changes every time.\n\\(S\\) is a random variable."
  },
  {
    "objectID": "slides/prob/21-inference-foundations.html#the-probability-distributions",
    "href": "slides/prob/21-inference-foundations.html#the-probability-distributions",
    "title": "Foundations of Statistical Inference",
    "section": "The probability distributions",
    "text": "The probability distributions\n\nThe probability distribution of a random variable informs us about the probability of the observed value falling in any given interval.\nFor example, if we want to know the probability that we lose money, we are asking the probability that \\(S\\) is in the interval \\((-\\infty,0)\\)."
  },
  {
    "objectID": "slides/prob/21-inference-foundations.html#the-probability-distribution",
    "href": "slides/prob/21-inference-foundations.html#the-probability-distribution",
    "title": "Foundations of Statistical Inference",
    "section": "The probability distribution",
    "text": "The probability distribution\n\nIf we can define a cumulative distribution function \\(F(a) = \\mbox{Pr}(S\\leq a)\\), we can answer any question about the probability of events defined by \\(S\\).\nWe call this \\(F\\) the random variable’s distribution function.\nProbability and Statistics classes dedicate much time to calculating or approximating these.\nWe can also estimate the distribution function for \\(S\\) using a Monte Carlo simulation."
  },
  {
    "objectID": "slides/prob/21-inference-foundations.html#the-probability-distribution-1",
    "href": "slides/prob/21-inference-foundations.html#the-probability-distribution-1",
    "title": "Foundations of Statistical Inference",
    "section": "The probability distribution",
    "text": "The probability distribution\n\nWith this code, we run the experiment of having 1,000 people repeatedly play roulette, specifically \\(B = 10,000\\) times:\n\n\nn &lt;- 1000 \nB &lt;- 10000 \nroulette_winnings &lt;- function(n){ \n  x &lt;- sample(c(-1, 1), n, replace = TRUE, prob = c(9/19, 10/19)) \n  sum(x) \n} \ns &lt;- replicate(B, roulette_winnings(n))"
  },
  {
    "objectID": "slides/prob/21-inference-foundations.html#the-probability-distribution-2",
    "href": "slides/prob/21-inference-foundations.html#the-probability-distribution-2",
    "title": "Foundations of Statistical Inference",
    "section": "The probability distribution",
    "text": "The probability distribution\n\nNow, we can ask the following: in our simulation, how often did we get sums less than or equal to a?\n\n\nmean(s &lt;= a)"
  },
  {
    "objectID": "slides/prob/21-inference-foundations.html#the-probability-distribution-3",
    "href": "slides/prob/21-inference-foundations.html#the-probability-distribution-3",
    "title": "Foundations of Statistical Inference",
    "section": "The probability distribution",
    "text": "The probability distribution\n\nThis will be a very good approximation of \\(F(a)\\).\nThis allows us to easily answer the casino’s question: How likely is it that we will lose money?\nIt is quite low:\n\n\nmean(s &lt; 0) \n#&gt; [1] 0.045"
  },
  {
    "objectID": "slides/prob/21-inference-foundations.html#the-probability-distribution-4",
    "href": "slides/prob/21-inference-foundations.html#the-probability-distribution-4",
    "title": "Foundations of Statistical Inference",
    "section": "The probability distribution",
    "text": "The probability distribution\n\nWe can visualize the distribution of \\(S\\) by creating a histogram showing the probability \\(F(b)-F(a)\\) for several intervals \\((a,b]\\):"
  },
  {
    "objectID": "slides/prob/21-inference-foundations.html#the-probability-distribution-5",
    "href": "slides/prob/21-inference-foundations.html#the-probability-distribution-5",
    "title": "Foundations of Statistical Inference",
    "section": "The probability distribution",
    "text": "The probability distribution\n\nWe see that the distribution appears to be approximately normal.\nA QQ-plot will confirm that the normal approximation is close to a perfect approximation."
  },
  {
    "objectID": "slides/prob/21-inference-foundations.html#the-probability-distribution-6",
    "href": "slides/prob/21-inference-foundations.html#the-probability-distribution-6",
    "title": "Foundations of Statistical Inference",
    "section": "The probability distribution",
    "text": "The probability distribution\n\nRemeber, if the distribution is normal, all we need to define it are the average and the standard deviation (SD).\nSince we have the original values from which the distribution is created, we can easily compute these with mean(s) and sd(s).\nThe blue curve added to the histogram is a normal density with this average and standard deviation."
  },
  {
    "objectID": "slides/prob/21-inference-foundations.html#the-probability-distribution-7",
    "href": "slides/prob/21-inference-foundations.html#the-probability-distribution-7",
    "title": "Foundations of Statistical Inference",
    "section": "The probability distribution",
    "text": "The probability distribution\n\nThis average and this standard deviation have special names; they are referred to as the expected value and standard error (SE) of the random variable \\(S\\)."
  },
  {
    "objectID": "slides/prob/21-inference-foundations.html#distributions-versus-probability-distributions",
    "href": "slides/prob/21-inference-foundations.html#distributions-versus-probability-distributions",
    "title": "Foundations of Statistical Inference",
    "section": "Distributions versus probability distributions",
    "text": "Distributions versus probability distributions\n\nBefore we continue, let’s establish an important distinction and connection between the distribution of a list of numbers and a probability distribution.\nAny list of numbers \\(x_1,\\dots,x_n\\) has a distribution.\nIt does not have a probability distribution because they are not random."
  },
  {
    "objectID": "slides/prob/21-inference-foundations.html#distributions-versus-probability-distributions-1",
    "href": "slides/prob/21-inference-foundations.html#distributions-versus-probability-distributions-1",
    "title": "Foundations of Statistical Inference",
    "section": "Distributions versus probability distributions",
    "text": "Distributions versus probability distributions\n\nWe define \\(F(a)\\) as the function that indicates what proportion of the list is less than or equal to \\(a\\).\nGiven their usefulness as summaries when the distribution is approximately normal, we also define the average and standard deviation."
  },
  {
    "objectID": "slides/prob/21-inference-foundations.html#distributions-versus-probability-distributions-2",
    "href": "slides/prob/21-inference-foundations.html#distributions-versus-probability-distributions-2",
    "title": "Foundations of Statistical Inference",
    "section": "Distributions versus probability distributions",
    "text": "Distributions versus probability distributions\n\nThese are determined with a straightforward operation involving the vector containing the list of numbers, denoted as x:\n\n\nm &lt;- sum(x)/length(x) \ns &lt;- sqrt(sum((x - m)^2)/length(x))"
  },
  {
    "objectID": "slides/prob/21-inference-foundations.html#distributions-versus-probability-distributions-3",
    "href": "slides/prob/21-inference-foundations.html#distributions-versus-probability-distributions-3",
    "title": "Foundations of Statistical Inference",
    "section": "Distributions versus probability distributions",
    "text": "Distributions versus probability distributions\n\nA random variable \\(X\\) has a distribution function.\nTo define this, we do not need a list of numbers; it is a theoretical concept.\nWe define the distribution as the \\(F(a)\\) that answers the question: What is the probability that \\(X\\) is less than or equal to \\(a\\)?"
  },
  {
    "objectID": "slides/prob/21-inference-foundations.html#distributions-versus-probability-distributions-4",
    "href": "slides/prob/21-inference-foundations.html#distributions-versus-probability-distributions-4",
    "title": "Foundations of Statistical Inference",
    "section": "Distributions versus probability distributions",
    "text": "Distributions versus probability distributions\n\nHowever, if \\(X\\) is defined by drawing from an urn containing numbers, then there is a list: the list of numbers inside the urn.\nIn this case, the distribution of that list is the probability distribution of \\(X\\), and the average and standard deviation of that list are the expected value and standard error of the random variable."
  },
  {
    "objectID": "slides/prob/21-inference-foundations.html#distributions-versus-probability-distributions-5",
    "href": "slides/prob/21-inference-foundations.html#distributions-versus-probability-distributions-5",
    "title": "Foundations of Statistical Inference",
    "section": "Distributions versus probability distributions",
    "text": "Distributions versus probability distributions\n\nAnother way to think about it without involving an urn is by running a Monte Carlo simulation and generating a very large list of outcomes of \\(X\\)."
  },
  {
    "objectID": "slides/prob/21-inference-foundations.html#distributions-versus-probability-distributions-6",
    "href": "slides/prob/21-inference-foundations.html#distributions-versus-probability-distributions-6",
    "title": "Foundations of Statistical Inference",
    "section": "Distributions versus probability distributions",
    "text": "Distributions versus probability distributions\n\nThese outcomes form a list of numbers, and the distribution of this list will be a very good approximation of the probability distribution of \\(X\\).\nThe longer the list, the better the approximation.\nThe average and standard deviation of this list will approximate the expected value and standard error of the random variable."
  },
  {
    "objectID": "slides/prob/21-inference-foundations.html#notation-for-random-variables",
    "href": "slides/prob/21-inference-foundations.html#notation-for-random-variables",
    "title": "Foundations of Statistical Inference",
    "section": "Notation for random variables",
    "text": "Notation for random variables\n\nIn statistical textbooks, upper case letters denote random variables, and we will adhere to this convention.\nLower case letters are used for observed values.\nYou will see some notation that include both.\nFor example, you will see events defined as \\(X \\leq x\\).\nHere \\(X\\) is a random variable and \\(x\\) is an arbitrary value and not random."
  },
  {
    "objectID": "slides/prob/21-inference-foundations.html#notation-for-random-variables-1",
    "href": "slides/prob/21-inference-foundations.html#notation-for-random-variables-1",
    "title": "Foundations of Statistical Inference",
    "section": "Notation for random variables",
    "text": "Notation for random variables\n\nSo, for example, \\(X\\) might represent the number on a die roll and \\(x\\) will represent an actual value we see: 1, 2, 3, 4, 5, or 6.\nIn this case, the probability of \\(X=x\\) is 1/6 regardless of the observed value \\(x\\).\nWe can discuss what we expect \\(X\\) to be, what values are probable, but we can’t discuss what value \\(X\\) is."
  },
  {
    "objectID": "slides/prob/21-inference-foundations.html#notation-for-random-variables-2",
    "href": "slides/prob/21-inference-foundations.html#notation-for-random-variables-2",
    "title": "Foundations of Statistical Inference",
    "section": "Notation for random variables",
    "text": "Notation for random variables\n\nOnce we have data, we do see a realization of \\(X\\).\nTherefore, data analysts often speak of what could have been after observing what actually happened."
  },
  {
    "objectID": "slides/prob/21-inference-foundations.html#the-expected-value-and-se",
    "href": "slides/prob/21-inference-foundations.html#the-expected-value-and-se",
    "title": "Foundations of Statistical Inference",
    "section": "The expected value and SE",
    "text": "The expected value and SE\n\nWe will now review the mathematical theory that allows us to approximate the probability distributions for the sum of draws.\nThe same approach we use for the sum of draws will be useful for describing the distribution of averages and proportion, which we will need to understand how polls work.\nThe first important concept to learn is the expected value."
  },
  {
    "objectID": "slides/prob/21-inference-foundations.html#the-expected-value-and-se-1",
    "href": "slides/prob/21-inference-foundations.html#the-expected-value-and-se-1",
    "title": "Foundations of Statistical Inference",
    "section": "The expected value and SE",
    "text": "The expected value and SE\n\nIn statistics books, it is common to represent the expected value of the random variable \\(X\\) with the letter \\(\\mbox{E}\\) like this:\n\n\\[\\mbox{E}[X]\\]"
  },
  {
    "objectID": "slides/prob/21-inference-foundations.html#the-expected-value-and-se-2",
    "href": "slides/prob/21-inference-foundations.html#the-expected-value-and-se-2",
    "title": "Foundations of Statistical Inference",
    "section": "The expected value and SE",
    "text": "The expected value and SE\n\nA random variable will vary around its expected value in a manner that if you take the average of many, many draws, the average will approximate the expected value.\nThis approximation improves as you take more draws, making the expected value a useful quantity to compute."
  },
  {
    "objectID": "slides/prob/21-inference-foundations.html#the-expected-value-and-se-3",
    "href": "slides/prob/21-inference-foundations.html#the-expected-value-and-se-3",
    "title": "Foundations of Statistical Inference",
    "section": "The expected value and SE",
    "text": "The expected value and SE\n\nFor discrete random variable with possible outcomes \\(x_1,\\dots,x_n\\), the expected value is defined as:\n\n\\[\n\\mbox{E}[X] = \\sum_{i=1}^n x_i \\,\\mbox{Pr}(X = x_i)\n\\]"
  },
  {
    "objectID": "slides/prob/21-inference-foundations.html#the-expected-value-and-se-4",
    "href": "slides/prob/21-inference-foundations.html#the-expected-value-and-se-4",
    "title": "Foundations of Statistical Inference",
    "section": "The expected value and SE",
    "text": "The expected value and SE\n\nNote that in the case that we are picking values from an urn, and each value \\(x_i\\) has an equal chance \\(1/n\\) of being selected, the above equation is simply the average of the \\(x_i\\)s.\n\n\\[\n\\mbox{E}[X] = \\frac{1}{n}\\sum_{i=1}^n x_i  \n\\]"
  },
  {
    "objectID": "slides/prob/21-inference-foundations.html#the-expected-value-and-se-5",
    "href": "slides/prob/21-inference-foundations.html#the-expected-value-and-se-5",
    "title": "Foundations of Statistical Inference",
    "section": "The expected value and SE",
    "text": "The expected value and SE\n\nIf \\(X\\) is a continuous random variable with a range of values \\(a\\) to \\(b\\) and a probability density function \\(f(x)\\), this sum transforms into an integral:\n\n\\[\n\\mbox{E}[X] = \\int_a^b x f(x)\n\\]"
  },
  {
    "objectID": "slides/prob/21-inference-foundations.html#the-expected-value-and-se-6",
    "href": "slides/prob/21-inference-foundations.html#the-expected-value-and-se-6",
    "title": "Foundations of Statistical Inference",
    "section": "The expected value and SE",
    "text": "The expected value and SE\n\nIn the urn used to model betting on red in roulette, we have 20 one-dollar bills and 18 negative one-dollar bills, so the expected value is:\n\n\\[\n\\mbox{E}[X] = (20 + -18)/38\n\\]\n\nwhich is about 5 cents."
  },
  {
    "objectID": "slides/prob/21-inference-foundations.html#the-expected-value-and-se-7",
    "href": "slides/prob/21-inference-foundations.html#the-expected-value-and-se-7",
    "title": "Foundations of Statistical Inference",
    "section": "The expected value and SE",
    "text": "The expected value and SE\n\nYou might consider it a bit counterintuitive to say that \\(X\\) varies around 0.05 when it only takes the values 1 and -1.\nTo make sense of the expected value in this context is by realizing that, if we play the game over and over, the casino wins, on average, 5 cents per game."
  },
  {
    "objectID": "slides/prob/21-inference-foundations.html#the-expected-value-and-se-8",
    "href": "slides/prob/21-inference-foundations.html#the-expected-value-and-se-8",
    "title": "Foundations of Statistical Inference",
    "section": "The expected value and SE",
    "text": "The expected value and SE\n\nA Monte Carlo simulation confirms this:\n\n\nB &lt;- 10^6 \nx &lt;- sample(c(-1, 1), B, replace = TRUE, prob = c(9/19, 10/19)) \nmean(x) \n#&gt; [1] 0.0522"
  },
  {
    "objectID": "slides/prob/21-inference-foundations.html#the-expected-value-and-se-9",
    "href": "slides/prob/21-inference-foundations.html#the-expected-value-and-se-9",
    "title": "Foundations of Statistical Inference",
    "section": "The expected value and SE",
    "text": "The expected value and SE\n\nIn general, if the urn has two possible outcomes, say \\(a\\) and \\(b\\), with proportions \\(p\\) and \\(1-p\\) respectively, the average is:\n\n\\[\\mbox{E}[X] = ap + b(1-p)\\]"
  },
  {
    "objectID": "slides/prob/21-inference-foundations.html#the-expected-value-and-se-10",
    "href": "slides/prob/21-inference-foundations.html#the-expected-value-and-se-10",
    "title": "Foundations of Statistical Inference",
    "section": "The expected value and SE",
    "text": "The expected value and SE\n\nTo confirm this, observe that if there are \\(n\\) beads in the urn, then we have \\(np\\) \\(a\\)s and \\(n(1-p)\\) \\(b\\)s, and because the average is the sum, \\(n\\times a \\times p + n\\times b \\times (1-p)\\), divided by the total \\(n\\), we get that the average is \\(ap + b(1-p)\\)."
  },
  {
    "objectID": "slides/prob/21-inference-foundations.html#the-expected-value-and-se-11",
    "href": "slides/prob/21-inference-foundations.html#the-expected-value-and-se-11",
    "title": "Foundations of Statistical Inference",
    "section": "The expected value and SE",
    "text": "The expected value and SE\n\nThe reason we define the expected value is because this mathematical definition turns out to be useful for approximating the probability distributions of sum.\nThis, in turn, is useful for describing the distribution of averages and proportions."
  },
  {
    "objectID": "slides/prob/21-inference-foundations.html#the-expected-value-and-se-12",
    "href": "slides/prob/21-inference-foundations.html#the-expected-value-and-se-12",
    "title": "Foundations of Statistical Inference",
    "section": "The expected value and SE",
    "text": "The expected value and SE\n\nThe first useful fact is that the expected value of the sum of the draws is the number of draws \\(\\times\\) the average of the numbers in the urn.\nTherefore, if 1,000 people play roulette, the casino expects to win, on average, about 1,000 \\(\\times\\) $0.05 = $50."
  },
  {
    "objectID": "slides/prob/21-inference-foundations.html#the-expected-value-and-se-13",
    "href": "slides/prob/21-inference-foundations.html#the-expected-value-and-se-13",
    "title": "Foundations of Statistical Inference",
    "section": "The expected value and SE",
    "text": "The expected value and SE\n\nHowever, this is an expected value.\nHow different can one observation be from the expected value? The casino really needs to know this.\nWhat is the range of possibilities? If negative numbers are too likely, they will not install roulette wheels.\nStatistical theory once again answers this question."
  },
  {
    "objectID": "slides/prob/21-inference-foundations.html#the-expected-value-and-se-14",
    "href": "slides/prob/21-inference-foundations.html#the-expected-value-and-se-14",
    "title": "Foundations of Statistical Inference",
    "section": "The expected value and SE",
    "text": "The expected value and SE\n\nThe standard error (SE) gives us an idea of the size of the variation around the expected value.\nIn statistics books, it’s common to use:\n\n\\[\\mbox{SE}[X] = \\sqrt{\\mbox{Var}[X]}\\]"
  },
  {
    "objectID": "slides/prob/21-inference-foundations.html#the-expected-value-and-se-15",
    "href": "slides/prob/21-inference-foundations.html#the-expected-value-and-se-15",
    "title": "Foundations of Statistical Inference",
    "section": "The expected value and SE",
    "text": "The expected value and SE\n\nto denote the standard error of a random variable.\nFor discrete random variable with possible outcomes \\(x_1,\\dots,x_n\\), the standard error is defined as:\n\n\\[\n\\mbox{SE}[X] = \\sqrt{\\sum_{i=1}^n \\left(x_i - E[X]\\right)^2 \\,\\mbox{Pr}(X = x_i)},\n\\]\n\nwhich you can think of as the expected average distance of \\(X\\) from the expected value."
  },
  {
    "objectID": "slides/prob/21-inference-foundations.html#the-expected-value-and-se-16",
    "href": "slides/prob/21-inference-foundations.html#the-expected-value-and-se-16",
    "title": "Foundations of Statistical Inference",
    "section": "The expected value and SE",
    "text": "The expected value and SE\n\nNote that in the case that we are picking values from an un urn where each value \\(x_i\\) has an equal chance \\(1/n\\) of being selected, the above equation is simply the standard deviation of of the \\(x_i\\)s.\n\n\\[\n\\mbox{SE}[X] = \\sqrt{\\frac{1}{n}\\sum_{i=1}^n (x_i - \\bar{x})^2} \\mbox{ with } \\bar{x} =  \\frac{1}{n}\\sum_{i=1}^n x_i  \n\\]"
  },
  {
    "objectID": "slides/prob/21-inference-foundations.html#the-expected-value-and-se-17",
    "href": "slides/prob/21-inference-foundations.html#the-expected-value-and-se-17",
    "title": "Foundations of Statistical Inference",
    "section": "The expected value and SE",
    "text": "The expected value and SE\n\nIf \\(X\\) is a continuous random variable, with range of values \\(a\\) to \\(b\\) and probability density function \\(f(x)\\), this sum turns into an integral:\n\n\\[\n\\mbox{SE}[X] = \\sqrt{\\int_a^b \\left(x-\\mbox{E}[X]\\right)^2 f(x)\\,\\mathrm{d}x}\n\\]"
  },
  {
    "objectID": "slides/prob/21-inference-foundations.html#the-expected-value-and-se-18",
    "href": "slides/prob/21-inference-foundations.html#the-expected-value-and-se-18",
    "title": "Foundations of Statistical Inference",
    "section": "The expected value and SE",
    "text": "The expected value and SE\n\nUsing the definition of standard deviation, we can derive, with a bit of math, that if an urn contains two values \\(a\\) and \\(b\\) with proportions \\(p\\) and \\((1-p)\\), respectively, the standard deviation is:\n\n\\[| b - a |\\sqrt{p(1-p)}.\\]"
  },
  {
    "objectID": "slides/prob/21-inference-foundations.html#the-expected-value-and-se-19",
    "href": "slides/prob/21-inference-foundations.html#the-expected-value-and-se-19",
    "title": "Foundations of Statistical Inference",
    "section": "The expected value and SE",
    "text": "The expected value and SE\n\nSo in our roulette example, the standard deviation of the values inside the urn is:\n\n\\[\n| 1 - (-1) | \\sqrt{10/19 \\times 9/19}\n\\]\nor:\n\n2*sqrt(90)/19 \n#&gt; [1] 0.999"
  },
  {
    "objectID": "slides/prob/21-inference-foundations.html#the-expected-value-and-se-20",
    "href": "slides/prob/21-inference-foundations.html#the-expected-value-and-se-20",
    "title": "Foundations of Statistical Inference",
    "section": "The expected value and SE",
    "text": "The expected value and SE\n\nSince one draw is obviously the sum of just one draw, we can use the formula above to calculate that the random variable defined by one draw has an expected value of 0.05 and a SE of about 1.\nThis makes sense since we obtain either 1 or -1, with 1 slightly favored over -1."
  },
  {
    "objectID": "slides/prob/21-inference-foundations.html#the-expected-value-and-se-21",
    "href": "slides/prob/21-inference-foundations.html#the-expected-value-and-se-21",
    "title": "Foundations of Statistical Inference",
    "section": "The expected value and SE",
    "text": "The expected value and SE\n\nA widely used mathematical result is that if our draws are independent, then the standard error of the sum is given by the equation:\n\n\\[\n\\sqrt{\\mbox{number of draws}} \\times \\mbox{ SD of the numbers in the urn}\n\\]"
  },
  {
    "objectID": "slides/prob/21-inference-foundations.html#the-expected-value-and-se-22",
    "href": "slides/prob/21-inference-foundations.html#the-expected-value-and-se-22",
    "title": "Foundations of Statistical Inference",
    "section": "The expected value and SE",
    "text": "The expected value and SE\n\nUsing this formula, the sum of 1,000 people playing has standard error of about $32:\n\n\nn &lt;- 1000 \nsqrt(n)*2*sqrt(90)/19 \n#&gt; [1] 31.6"
  },
  {
    "objectID": "slides/prob/21-inference-foundations.html#the-expected-value-and-se-23",
    "href": "slides/prob/21-inference-foundations.html#the-expected-value-and-se-23",
    "title": "Foundations of Statistical Inference",
    "section": "The expected value and SE",
    "text": "The expected value and SE\n\nAs a result, when 1,000 people bet on red, the casino is expected to win $50 with a standard error of $32.\nIt therefore seems like a safe bet to install more roulette wheels.\nBut we still haven’t answered the question: How likely is the casino to lose money? The CLT will help in this regard."
  },
  {
    "objectID": "slides/prob/21-inference-foundations.html#central-limit-theorem",
    "href": "slides/prob/21-inference-foundations.html#central-limit-theorem",
    "title": "Foundations of Statistical Inference",
    "section": "Central Limit Theorem",
    "text": "Central Limit Theorem\n\nThe Central Limit Theorem (CLT) tells us that when the number of draws, also called the sample size, is large, the probability distribution of the sum of the independent draws is approximately normal.\nGiven that sampling models are used for so many data generation processes, the CLT is considered one of the most important mathematical insights in history."
  },
  {
    "objectID": "slides/prob/21-inference-foundations.html#central-limit-theorem-1",
    "href": "slides/prob/21-inference-foundations.html#central-limit-theorem-1",
    "title": "Foundations of Statistical Inference",
    "section": "Central Limit Theorem",
    "text": "Central Limit Theorem\n\nPreviously, we discussed that if we know that the distribution of a list of numbers is approximated by the normal distribution, all we need to describe the list are the average and standard deviation.\nWe also know that the same applies to probability distributions."
  },
  {
    "objectID": "slides/prob/21-inference-foundations.html#central-limit-theorem-2",
    "href": "slides/prob/21-inference-foundations.html#central-limit-theorem-2",
    "title": "Foundations of Statistical Inference",
    "section": "Central Limit Theorem",
    "text": "Central Limit Theorem\n\nIf a random variable has a probability distribution that is approximated with the normal distribution, then all we need to describe the probability distribution are the average and standard deviation, referred to as the expected value and standard error."
  },
  {
    "objectID": "slides/prob/21-inference-foundations.html#central-limit-theorem-3",
    "href": "slides/prob/21-inference-foundations.html#central-limit-theorem-3",
    "title": "Foundations of Statistical Inference",
    "section": "Central Limit Theorem",
    "text": "Central Limit Theorem\n\nWe previously ran this Monte Carlo simulation:\n\n\nn &lt;- 1000 \nB &lt;- 10000 \nroulette_winnings &lt;- function(n){ \n  x &lt;- sample(c(-1, 1), n, replace = TRUE, prob = c(9/19, 10/19)) \n  sum(x) \n} \ns &lt;- replicate(B, roulette_winnings(n))"
  },
  {
    "objectID": "slides/prob/21-inference-foundations.html#central-limit-theorem-4",
    "href": "slides/prob/21-inference-foundations.html#central-limit-theorem-4",
    "title": "Foundations of Statistical Inference",
    "section": "Central Limit Theorem",
    "text": "Central Limit Theorem\n\nThe Central Limit Theorem (CLT) tells us that the sum \\(S\\) is approximated by a normal distribution.\nUsing the formulas above, we know that the expected value and standard error are:\n\n\nn * (20 - 18)/38  \n#&gt; [1] 52.6\nsqrt(n)*2*sqrt(90)/19  \n#&gt; [1] 31.6"
  },
  {
    "objectID": "slides/prob/21-inference-foundations.html#central-limit-theorem-5",
    "href": "slides/prob/21-inference-foundations.html#central-limit-theorem-5",
    "title": "Foundations of Statistical Inference",
    "section": "Central Limit Theorem",
    "text": "Central Limit Theorem\n\nThe theoretical values above match those obtained with the Monte Carlo simulation:\n\n\nmean(s) \n#&gt; [1] 52.6\nsd(s) \n#&gt; [1] 31.5"
  },
  {
    "objectID": "slides/prob/21-inference-foundations.html#central-limit-theorem-6",
    "href": "slides/prob/21-inference-foundations.html#central-limit-theorem-6",
    "title": "Foundations of Statistical Inference",
    "section": "Central Limit Theorem",
    "text": "Central Limit Theorem\n\nUsing the CLT, we can skip the Monte Carlo simulation and instead compute the probability of the casino losing money using this approximation:\n\n\nmu &lt;- n*(20 - 18)/38 \nse &lt;- sqrt(n)*2*sqrt(90)/19  \npnorm(0, mu, se) \n#&gt; [1] 0.0478\n\n\nwhich is also in very good agreement with our Monte Carlo result:\n\n\nmean(s &lt; 0) \n#&gt; [1] 0.0442"
  },
  {
    "objectID": "slides/prob/21-inference-foundations.html#how-large-is-large-in-the-clt",
    "href": "slides/prob/21-inference-foundations.html#how-large-is-large-in-the-clt",
    "title": "Foundations of Statistical Inference",
    "section": "How large is large in the CLT?",
    "text": "How large is large in the CLT?\n\nThe CLT works when the number of draws is large, but “large” is a relative term.\nIn many circumstances, as few as 30 draws is enough to make the CLT useful.\nIn some specific instances, as few as 10 is enough.\nHowever, these should not be considered general rules.\nNote that when the probability of success is very small, much larger sample sizes are needed."
  },
  {
    "objectID": "slides/prob/21-inference-foundations.html#how-large-is-large-in-the-clt-1",
    "href": "slides/prob/21-inference-foundations.html#how-large-is-large-in-the-clt-1",
    "title": "Foundations of Statistical Inference",
    "section": "How large is large in the CLT?",
    "text": "How large is large in the CLT?\n\nBy way of illustration, let’s consider the lottery.\nIn the lottery, the chances of winning are less than 1 in a million.\nThousands of people play so the number of draws is very large.\nYet the number of winners, the sum of the draws, range between 0 and 4.\nThis sum is certainly not well approximated by a normal distribution, so the CLT does not apply, even with the very large sample size."
  },
  {
    "objectID": "slides/prob/21-inference-foundations.html#how-large-is-large-in-the-clt-2",
    "href": "slides/prob/21-inference-foundations.html#how-large-is-large-in-the-clt-2",
    "title": "Foundations of Statistical Inference",
    "section": "How large is large in the CLT?",
    "text": "How large is large in the CLT?\n\nThis is generally true when the probability of a success is very low.\nIn these cases, the Poisson distribution is more appropriate.\nYou can explore the properties of the Poisson distribution using dpois and ppois.\nYou can generate random variables following this distribution with rpois.\nHowever, we won’t cover the theory here."
  },
  {
    "objectID": "slides/prob/21-inference-foundations.html#how-large-is-large-in-the-clt-3",
    "href": "slides/prob/21-inference-foundations.html#how-large-is-large-in-the-clt-3",
    "title": "Foundations of Statistical Inference",
    "section": "How large is large in the CLT?",
    "text": "How large is large in the CLT?\n\nYou can learn about the Poisson distribution in any probability textbook and even Wikipedia"
  },
  {
    "objectID": "slides/prob/21-inference-foundations.html#statistical-properties-of-averages",
    "href": "slides/prob/21-inference-foundations.html#statistical-properties-of-averages",
    "title": "Foundations of Statistical Inference",
    "section": "Statistical properties of averages",
    "text": "Statistical properties of averages\n\nThere are several useful mathematical results that we used above and often employ when working with data.\nWe list them below."
  },
  {
    "objectID": "slides/prob/21-inference-foundations.html#property-1",
    "href": "slides/prob/21-inference-foundations.html#property-1",
    "title": "Foundations of Statistical Inference",
    "section": "Property 1",
    "text": "Property 1\n\nThe expected value of the sum of random variables is the sum of each random variable’s expected value.\nWe can write it like this:\n\n\\[\n\\mbox{E}[X_1+X_2+\\dots+X_n] =  \\mbox{E}[X_1] + \\mbox{E}[X_2]+\\dots+\\mbox{E}[X_n]\n\\]"
  },
  {
    "objectID": "slides/prob/21-inference-foundations.html#property-1-1",
    "href": "slides/prob/21-inference-foundations.html#property-1-1",
    "title": "Foundations of Statistical Inference",
    "section": "Property 1",
    "text": "Property 1\n\nIf \\(X\\) represents independent draws from the urn, then they all have the same expected value.\nLet’s denote the expected value with \\(\\mu\\) and rewrite the equation as:\n\n\\[\n\\mbox{E}[X_1+X_2+\\dots+X_n]=  n\\mu\n\\]\n\nwhich is another way of writing the result we show above for the sum of draws."
  },
  {
    "objectID": "slides/prob/21-inference-foundations.html#property-2",
    "href": "slides/prob/21-inference-foundations.html#property-2",
    "title": "Foundations of Statistical Inference",
    "section": "Property 2",
    "text": "Property 2\n\nThe expected value of a non-random constant times a random variable is the non-random constant times the expected value of a random variable.\nThis is easier to explain with symbols:\n\n\\[\n\\mbox{E}[aX] =  a\\times\\mbox{E}[X]\n\\]"
  },
  {
    "objectID": "slides/prob/21-inference-foundations.html#property-2-1",
    "href": "slides/prob/21-inference-foundations.html#property-2-1",
    "title": "Foundations of Statistical Inference",
    "section": "Property 2",
    "text": "Property 2\n\nTo understand why this is intuitive, consider changing units.\nIf we change the units of a random variable, such as from dollars to cents, the expectation should change in the same way."
  },
  {
    "objectID": "slides/prob/21-inference-foundations.html#property-2-2",
    "href": "slides/prob/21-inference-foundations.html#property-2-2",
    "title": "Foundations of Statistical Inference",
    "section": "Property 2",
    "text": "Property 2\n\nA consequence of the above two facts is that the expected value of the average of independent draws from the same urn is the expected value of the urn, denoted as \\(\\mu\\) again:\n\n\\[\n\\mbox{E}[(X_1+X_2+\\dots+X_n) / n]=   \\mbox{E}[X_1+X_2+\\dots+X_n] / n = n\\mu/n = \\mu  \n\\]"
  },
  {
    "objectID": "slides/prob/21-inference-foundations.html#property-3",
    "href": "slides/prob/21-inference-foundations.html#property-3",
    "title": "Foundations of Statistical Inference",
    "section": "Property 3",
    "text": "Property 3\n\nThe square of the standard error of the sum of independent random variables is the sum of the square of the standard error of each random variable.\nThis one is easier to understand in math form:\n\n\\[\n\\mbox{SE}[X_1+X_2+\\dots+X_n] = \\sqrt{\\mbox{SE}[X_1]^2 + \\mbox{SE}[X_2]^2+\\dots+\\mbox{SE}[X_n]^2  }\n\\]"
  },
  {
    "objectID": "slides/prob/21-inference-foundations.html#property-3-1",
    "href": "slides/prob/21-inference-foundations.html#property-3-1",
    "title": "Foundations of Statistical Inference",
    "section": "Property 3",
    "text": "Property 3\n\nThe square of the standard error is referred to as the variance in statistical textbooks.\nNote that this particular property is not as intuitive as the previous three and more in depth explanations can be found in statistics textbooks."
  },
  {
    "objectID": "slides/prob/21-inference-foundations.html#property-4",
    "href": "slides/prob/21-inference-foundations.html#property-4",
    "title": "Foundations of Statistical Inference",
    "section": "Property 4",
    "text": "Property 4\n\nThe standard error of a non-random constant times a random variable is the non-random constant times the random variable’s standard error.\nAs with the expectation:\n\n\\[\n\\mbox{SE}[aX] =  a \\times \\mbox{SE}[X]\n\\]\n\nTo see why this is intuitive, again think of units."
  },
  {
    "objectID": "slides/prob/21-inference-foundations.html#property-4-1",
    "href": "slides/prob/21-inference-foundations.html#property-4-1",
    "title": "Foundations of Statistical Inference",
    "section": "Property 4",
    "text": "Property 4\n\nA consequence of 3 and 4 is that the standard error of the average of independent draws from the same urn is the standard deviation of the urn divided by the square root of \\(n\\) (the number of draws), call it \\(\\sigma\\):\n\n\\[\n\\begin{aligned}\n\\mbox{SE}[(X_1+X_2+\\dots+X_n) / n] &=   \\mbox{SE}[X_1+X_2+\\dots+X_n]/n \\\\\n&= \\sqrt{\\mbox{SE}[X_1]^2+\\mbox{SE}[X_2]^2+\\dots+\\mbox{SE}[X_n]^2}/n \\\\\n&= \\sqrt{\\sigma^2+\\sigma^2+\\dots+\\sigma^2}/n\\\\\n&= \\sqrt{n\\sigma^2}/n\\\\\n&= \\sigma / \\sqrt{n}     \n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/prob/21-inference-foundations.html#property-5",
    "href": "slides/prob/21-inference-foundations.html#property-5",
    "title": "Foundations of Statistical Inference",
    "section": "Property 5",
    "text": "Property 5\n\nIf \\(X\\) is a normally distributed random variable, then if \\(a\\) and \\(b\\) are non-random constants, \\(aX + b\\) is also a normally distributed random variable.\nAll we are doing is changing the units of the random variable by multiplying by \\(a\\), then shifting the center by \\(b\\)."
  },
  {
    "objectID": "slides/prob/21-inference-foundations.html#notation",
    "href": "slides/prob/21-inference-foundations.html#notation",
    "title": "Foundations of Statistical Inference",
    "section": "Notation",
    "text": "Notation\n\nNote that statistical textbooks use the Greek letters \\(\\mu\\) and \\(\\sigma\\) to denote the expected value and standard error, respectively.\nThis is because \\(\\mu\\) is the Greek letter for \\(m\\), the first letter of mean, which is another term used for expected value.\nSimilarly, \\(\\sigma\\) is the Greek letter for \\(s\\), the first letter of standard error."
  },
  {
    "objectID": "slides/prob/21-inference-foundations.html#the-assumption-of-independence-is-important",
    "href": "slides/prob/21-inference-foundations.html#the-assumption-of-independence-is-important",
    "title": "Foundations of Statistical Inference",
    "section": "The assumption of independence is important",
    "text": "The assumption of independence is important\n\nThe given equation reveals crucial insights for practical scenarios.\nSpecifically, it suggests that the standard error can be minimized by increasing the sample size, \\(n\\), and we can quantify this reduction.\nHowever, this principle holds true only when the variables \\(X_1, X_2, \\dots, X_n\\) are independent.\nIf they are not, the estimated standard error can be significantly off."
  },
  {
    "objectID": "slides/prob/21-inference-foundations.html#the-assumption-of-independence-is-important-1",
    "href": "slides/prob/21-inference-foundations.html#the-assumption-of-independence-is-important-1",
    "title": "Foundations of Statistical Inference",
    "section": "The assumption of independence is important",
    "text": "The assumption of independence is important\n\nWe later introduce the concept of correlation, which quantifies the degree to which variables are interdependent.\nIf the correlation coefficient among the \\(X\\) variables is \\(\\rho\\), the standard error of their average is:\n\n\\[\n\\mbox{SE}\\left(\\bar{X}\\right) = \\sigma \\sqrt{\\frac{1 + (n-1) \\rho}{n}}\n\\]"
  },
  {
    "objectID": "slides/prob/21-inference-foundations.html#the-assumption-of-independence-is-important-2",
    "href": "slides/prob/21-inference-foundations.html#the-assumption-of-independence-is-important-2",
    "title": "Foundations of Statistical Inference",
    "section": "The assumption of independence is important",
    "text": "The assumption of independence is important\n\nThe key observation here is that as \\(\\rho\\) approaches its upper limit of 1, the standard error increases.\nNotably, in the situation where \\(\\rho = 1\\), the standard error, \\(\\mbox{SE}(\\bar{X})\\), equals \\(\\sigma\\), and it becomes unaffected by the sample size \\(n\\)."
  },
  {
    "objectID": "slides/prob/21-inference-foundations.html#law-of-large-numbers",
    "href": "slides/prob/21-inference-foundations.html#law-of-large-numbers",
    "title": "Foundations of Statistical Inference",
    "section": "Law of large numbers",
    "text": "Law of large numbers\n\nAn important implication of result 4 above is that the standard error of the average becomes smaller and smaller as \\(n\\) grows larger.\nWhen \\(n\\) is very large, then the standard error is practically 0 and the average of the draws converges to the average of the urn.\nThis is known in statistical textbooks as the law of large numbers or the law of averages."
  },
  {
    "objectID": "slides/prob/21-inference-foundations.html#misinterpretation-of-the-law-of-averages",
    "href": "slides/prob/21-inference-foundations.html#misinterpretation-of-the-law-of-averages",
    "title": "Foundations of Statistical Inference",
    "section": "Misinterpretation of the law of averages",
    "text": "Misinterpretation of the law of averages\n\nThe law of averages is sometimes misinterpreted.\nFor example, if you toss a coin 5 times and see a head each time, you might hear someone argue that the next toss is probably a tail because of the law of averages: on average we should see 50% heads and 50% tails."
  },
  {
    "objectID": "slides/prob/21-inference-foundations.html#misinterpretation-of-the-law-of-averages-1",
    "href": "slides/prob/21-inference-foundations.html#misinterpretation-of-the-law-of-averages-1",
    "title": "Foundations of Statistical Inference",
    "section": "Misinterpretation of the law of averages",
    "text": "Misinterpretation of the law of averages\n\nA similar argument would be to say that red “is due” on the roulette wheel after seeing black come up five times in a row.\nYet these events are independent so the chance of a coin landing heads is 50%, regardless of the previous 5."
  },
  {
    "objectID": "slides/prob/21-inference-foundations.html#misinterpretation-of-the-law-of-averages-2",
    "href": "slides/prob/21-inference-foundations.html#misinterpretation-of-the-law-of-averages-2",
    "title": "Foundations of Statistical Inference",
    "section": "Misinterpretation of the law of averages",
    "text": "Misinterpretation of the law of averages\n\nThe same principle applies to the roulette outcome.\nThe law of averages applies only when the number of draws is very large and not in small samples."
  },
  {
    "objectID": "slides/prob/21-inference-foundations.html#misinterpretation-of-the-law-of-averages-3",
    "href": "slides/prob/21-inference-foundations.html#misinterpretation-of-the-law-of-averages-3",
    "title": "Foundations of Statistical Inference",
    "section": "Misinterpretation of the law of averages",
    "text": "Misinterpretation of the law of averages\n\nAfter a million tosses, you will definitely see about 50% heads regardless of the outcome of the first five tosses.\nAnother funny misuse of the law of averages is in sports when TV sportscasters predict a player is about to succeed because they have failed a few times in a row."
  },
  {
    "objectID": "slides/R/05-r-basics.html#packages",
    "href": "slides/R/05-r-basics.html#packages",
    "title": "R Basics",
    "section": "Packages",
    "text": "Packages\n\nUse install.packages to install the dslabs package.\nTryout the following functions: sessionInfo, installed.packages"
  },
  {
    "objectID": "slides/R/05-r-basics.html#prebuilt-functions",
    "href": "slides/R/05-r-basics.html#prebuilt-functions",
    "title": "R Basics",
    "section": "Prebuilt functions",
    "text": "Prebuilt functions\n\nMuch of what we do in R is based on prebuilt functions.\nMany are included in automatically loaded packages: stats, graphics, grDevices, utils, datasets, methods.\nThis subset of the R universe is refereed to as R base.\nVery popular packages not included in R base: ggplot2, dplyr, tidyr, and data.table."
  },
  {
    "objectID": "slides/R/05-r-basics.html#prebuilt-functions-1",
    "href": "slides/R/05-r-basics.html#prebuilt-functions-1",
    "title": "R Basics",
    "section": "Prebuilt functions",
    "text": "Prebuilt functions\n\nExample of prebuilt functions that we will use today: ls, rm, library, search, factor, list, exists, str, typeof, and class.\nYou can see the raw code for a function by typing it without the parenthesis: type ls on your console to see an example."
  },
  {
    "objectID": "slides/R/05-r-basics.html#help-system",
    "href": "slides/R/05-r-basics.html#help-system",
    "title": "R Basics",
    "section": "Help system",
    "text": "Help system\n\nIn R you can use ? or help to learn more about functions.\nYou can learn about function using\n\nhelp(\"ls\")\nor\n?ls"
  },
  {
    "objectID": "slides/R/05-r-basics.html#the-workspace",
    "href": "slides/R/05-r-basics.html#the-workspace",
    "title": "R Basics",
    "section": "The workspace",
    "text": "The workspace\n\nDefine a variable.\n\n\na &lt;- 2\n\n\nUse ls to see if it’s there. Also take a look at the Environment tab in RStudio.\n\n\nls()\n\n[1] \"a\"\n\n\n\nUse rm to remove the variable you defined.\n\n\nrm(a)"
  },
  {
    "objectID": "slides/R/05-r-basics.html#variable-name-convention",
    "href": "slides/R/05-r-basics.html#variable-name-convention",
    "title": "R Basics",
    "section": "Variable name convention",
    "text": "Variable name convention\n\nA nice convention to follow is to use meaningful words that describe what is stored, use only lower case, and use underscores as a substitute for spaces.\nFor more we recommend this guide."
  },
  {
    "objectID": "slides/R/05-r-basics.html#data-types",
    "href": "slides/R/05-r-basics.html#data-types",
    "title": "R Basics",
    "section": "Data types",
    "text": "Data types\nThe main data types in R are:\n\nOne dimensional vectors: numeric, integer, logical, complex, characters.\nFactors\nLists: this includes data frames.\nArrays: Matrices are the most widely used.\nDate and time\ntibble\nS4 objects"
  },
  {
    "objectID": "slides/R/05-r-basics.html#data-types-1",
    "href": "slides/R/05-r-basics.html#data-types-1",
    "title": "R Basics",
    "section": "Data types",
    "text": "Data types\n\nMany errors in R come from confusing data types.\nstr stands for structure, gives us information about an object.\ntypeof gives you the basic data type of the object. It reveals the lower-level, more fundamental type of an object in R’s memory.\nclass This function returns the class attribute of an object. The class of an object is essentially type_of at a higher, often user-facing level."
  },
  {
    "objectID": "slides/R/05-r-basics.html#data-types-2",
    "href": "slides/R/05-r-basics.html#data-types-2",
    "title": "R Basics",
    "section": "Data types",
    "text": "Data types\nLet’s see some example:\n\nlibrary(dslabs)\ntypeof(murders)\n\n[1] \"list\"\n\nclass(murders)\n\n[1] \"data.frame\"\n\nstr(murders)\n\n'data.frame':   51 obs. of  5 variables:\n $ state     : chr  \"Alabama\" \"Alaska\" \"Arizona\" \"Arkansas\" ...\n $ abb       : chr  \"AL\" \"AK\" \"AZ\" \"AR\" ...\n $ region    : Factor w/ 4 levels \"Northeast\",\"South\",..: 2 4 4 2 4 4 1 2 2 2 ...\n $ population: num  4779736 710231 6392017 2915918 37253956 ...\n $ total     : num  135 19 232 93 1257 ..."
  },
  {
    "objectID": "slides/R/05-r-basics.html#data-frames",
    "href": "slides/R/05-r-basics.html#data-frames",
    "title": "R Basics",
    "section": "Data frames",
    "text": "Data frames\n\nDate frames are the most common class used in data analysis. It is like a spreadsheet.\nUsually, rows represents observations and columns variables.\nEach variable can be a different data type.\nYou can see part of the content like this\n\n\nhead(murders)\n\n       state abb region population total\n1    Alabama  AL  South    4779736   135\n2     Alaska  AK   West     710231    19\n3    Arizona  AZ   West    6392017   232\n4   Arkansas  AR  South    2915918    93\n5 California  CA   West   37253956  1257\n6   Colorado  CO   West    5029196    65"
  },
  {
    "objectID": "slides/R/05-r-basics.html#data-frames-1",
    "href": "slides/R/05-r-basics.html#data-frames-1",
    "title": "R Basics",
    "section": "Data frames",
    "text": "Data frames\n\nand all of the content like this:\n\n\nView(murders)\n\n\nType the above in RStudio."
  },
  {
    "objectID": "slides/R/05-r-basics.html#data-frames-2",
    "href": "slides/R/05-r-basics.html#data-frames-2",
    "title": "R Basics",
    "section": "Data frames",
    "text": "Data frames\n\nA very common operation is adding columns like this:\n\n\nmurders$pop_rank &lt;- rank(murders$population)\nhead(murders)\n\n       state abb region population total pop_rank\n1    Alabama  AL  South    4779736   135       29\n2     Alaska  AK   West     710231    19        5\n3    Arizona  AZ   West    6392017   232       36\n4   Arkansas  AR  South    2915918    93       20\n5 California  CA   West   37253956  1257       51\n6   Colorado  CO   West    5029196    65       30"
  },
  {
    "objectID": "slides/R/05-r-basics.html#data-frames-3",
    "href": "slides/R/05-r-basics.html#data-frames-3",
    "title": "R Basics",
    "section": "Data frames",
    "text": "Data frames\n\nNote that we used $.\nThis is called the accessor because it lets us access columns.\n\n\nmurders$population\n\n [1]  4779736   710231  6392017  2915918 37253956  5029196  3574097   897934\n [9]   601723 19687653  9920000  1360301  1567582 12830632  6483802  3046355\n[17]  2853118  4339367  4533372  1328361  5773552  6547629  9883640  5303925\n[25]  2967297  5988927   989415  1826341  2700551  1316470  8791894  2059179\n[33] 19378102  9535483   672591 11536504  3751351  3831074 12702379  1052567\n[41]  4625364   814180  6346105 25145561  2763885   625741  8001024  6724540\n[49]  1852994  5686986   563626\n\n\n\nMore generally: used to access components of a list."
  },
  {
    "objectID": "slides/R/05-r-basics.html#data-frames-4",
    "href": "slides/R/05-r-basics.html#data-frames-4",
    "title": "R Basics",
    "section": "Data frames",
    "text": "Data frames\n\nOne way R confuses beginners is by having multiple ways of doing the same thing.\nFor example you can access the 4th column in the following five different ways:\n\n\nmurders$population\nmurders[, \"population\"]\nmurders[[\"population\"]]\nmurders[, 4]\nmurders[[4]]\n\n\nIn general, we recommend using the name rather than the number as it is less likely to change."
  },
  {
    "objectID": "slides/R/05-r-basics.html#with",
    "href": "slides/R/05-r-basics.html#with",
    "title": "R Basics",
    "section": "with",
    "text": "with\n\nwith let’s us use the column names as objects.\nThis is convenient to avoid typing the data frame name over and over:\n\n\nrate &lt;- with(murders, total/population)"
  },
  {
    "objectID": "slides/R/05-r-basics.html#with-1",
    "href": "slides/R/05-r-basics.html#with-1",
    "title": "R Basics",
    "section": "with",
    "text": "with\n\nNote you can write entire code chunks by enclosing it in curly brackets:\n\n\nwith(murders, {\n   rate &lt;- total/population\n   rate &lt;- round(rate*10^5)\n   print(rate[1:5])\n})\n\n[1] 3 3 4 3 3"
  },
  {
    "objectID": "slides/R/05-r-basics.html#vectors",
    "href": "slides/R/05-r-basics.html#vectors",
    "title": "R Basics",
    "section": "Vectors",
    "text": "Vectors\n\nThe columns of data frames are an example of one dimensional (atomic) vectors.\n\n\nlength(murders$population)\n\n[1] 51"
  },
  {
    "objectID": "slides/R/05-r-basics.html#vectors-1",
    "href": "slides/R/05-r-basics.html#vectors-1",
    "title": "R Basics",
    "section": "Vectors",
    "text": "Vectors\n\nOften we have to create vectors.\nThe concatenate function c is the most basic way used to create vectors:\n\n\nx &lt;- c(\"b\", \"s\", \"t\", \" \", \"2\", \"6\", \"0\")"
  },
  {
    "objectID": "slides/R/05-r-basics.html#sequences",
    "href": "slides/R/05-r-basics.html#sequences",
    "title": "R Basics",
    "section": "Sequences",
    "text": "Sequences\n\nSequences are a the common example of vectors we generate.\n\n\nseq(1, 10)\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\nseq(1, 9, 2)\n\n[1] 1 3 5 7 9\n\n\n\nWhen increasing by 1 you can use :\n\n\n1:10\n\n [1]  1  2  3  4  5  6  7  8  9 10"
  },
  {
    "objectID": "slides/R/05-r-basics.html#sequences-1",
    "href": "slides/R/05-r-basics.html#sequences-1",
    "title": "R Basics",
    "section": "Sequences",
    "text": "Sequences\n\nA useful function to quickly generate the sequence 1:length(x) is seq_along:\n\n\nx &lt;- c(\"b\", \"s\", \"t\", \" \", \"2\", \"6\", \"0\")\nseq_along(x)\n\n[1] 1 2 3 4 5 6 7\n\n\n\nA reason to use this is to loop through entries:\n\n\nfor (i in seq_along(x)) {\n  cat(toupper(x[i]))\n}\n\nBST 260"
  },
  {
    "objectID": "slides/R/05-r-basics.html#factors",
    "href": "slides/R/05-r-basics.html#factors",
    "title": "R Basics",
    "section": "Factors",
    "text": "Factors\n\nOne key distinction between data types you need to understad is the difference between factors and characters.\nThe murder dataset has examples of both.\n\n\nclass(murders$state)\n\n[1] \"character\"\n\nclass(murders$region)\n\n[1] \"factor\"\n\n\n\nWhy do you think this is?"
  },
  {
    "objectID": "slides/R/05-r-basics.html#factors-1",
    "href": "slides/R/05-r-basics.html#factors-1",
    "title": "R Basics",
    "section": "Factors",
    "text": "Factors\n\nFactors store levels and the label of each level.\nThis is useful for categorical data.\n\n\nx &lt;- murders$region\nlevels(x)\n\n[1] \"Northeast\"     \"South\"         \"North Central\" \"West\""
  },
  {
    "objectID": "slides/R/05-r-basics.html#categories-based-on-strata",
    "href": "slides/R/05-r-basics.html#categories-based-on-strata",
    "title": "R Basics",
    "section": "Categories based on strata",
    "text": "Categories based on strata\n\nIn data analysis we often have to stratify continuous variables into categories.\nThe function cut helps us do this:\n\n\nage &lt;- c(5, 93, 18, 102, 14, 22, 45, 65, 67, 25, 30, 16, 21)\ncut(age, c(0, 11, 27, 43, 59, 78, 96, Inf))\n\n [1] (0,11]   (78,96]  (11,27]  (96,Inf] (11,27]  (11,27]  (43,59]  (59,78] \n [9] (59,78]  (11,27]  (27,43]  (11,27]  (11,27] \nLevels: (0,11] (11,27] (27,43] (43,59] (59,78] (78,96] (96,Inf]"
  },
  {
    "objectID": "slides/R/05-r-basics.html#categories-based-on-strata-1",
    "href": "slides/R/05-r-basics.html#categories-based-on-strata-1",
    "title": "R Basics",
    "section": "Categories based on strata",
    "text": "Categories based on strata\n\nWe can assign it more meaningful level names:\n\n\nage &lt;- c(5, 93, 18, 102, 14, 22, 45, 65, 67, 25, 30, 16, 21)\ncut(age, c(0, 11, 27, 43, 59, 78, 96, Inf), \n    labels = c(\"Alpha\", \"Zoomer\", \"Millennial\", \"X\", \"Boomer\", \"Silent\", \"Greatest\"))\n\n [1] Alpha      Silent     Zoomer     Greatest   Zoomer     Zoomer    \n [7] X          Boomer     Boomer     Zoomer     Millennial Zoomer    \n[13] Zoomer    \nLevels: Alpha Zoomer Millennial X Boomer Silent Greatest"
  },
  {
    "objectID": "slides/R/05-r-basics.html#changing-levels",
    "href": "slides/R/05-r-basics.html#changing-levels",
    "title": "R Basics",
    "section": "Changing levels",
    "text": "Changing levels\n\nThis is often needed for ordinal data because R defaults to alphabetical order:\n\n\ngen &lt;- factor(c(\"Alpha\", \"Zoomer\", \"Millennial\"))\nlevels(gen)\n\n[1] \"Alpha\"      \"Millennial\" \"Zoomer\"    \n\n\n\nYou can change this with the levels argument:\n\n\ngen &lt;- factor(gen, levels = c(\"Alpha\", \"Zoomer\", \"Millennial\", \"X\", \"Boomer\", \"Silent\", \"Greatest\"))\nlevels(gen)\n\n[1] \"Alpha\"      \"Zoomer\"     \"Millennial\" \"X\"          \"Boomer\"    \n[6] \"Silent\"     \"Greatest\""
  },
  {
    "objectID": "slides/R/05-r-basics.html#changing-levels-1",
    "href": "slides/R/05-r-basics.html#changing-levels-1",
    "title": "R Basics",
    "section": "Changing levels",
    "text": "Changing levels\n\nA common reason we need to change levels is to assure R is aware which is the reference strata.\nThis is important for linear models because the first level is assumed to be the reference.\n\n\nx &lt;- factor(c(\"no drug\", \"drug 1\", \"drug 2\"))\nlevels(x)\n\n[1] \"drug 1\"  \"drug 2\"  \"no drug\"\n\nx &lt;- relevel(x, ref = \"no drug\")\nlevels(x)          \n\n[1] \"no drug\" \"drug 1\"  \"drug 2\""
  },
  {
    "objectID": "slides/R/05-r-basics.html#changing-levels-2",
    "href": "slides/R/05-r-basics.html#changing-levels-2",
    "title": "R Basics",
    "section": "Changing levels",
    "text": "Changing levels\n\nWe often want to order strata based on a summary statistic.\nThis is common in data visualization.\nWe can use reorder for this:\n\n\nx &lt;- reorder(murders$region, murders$population, sum)"
  },
  {
    "objectID": "slides/R/05-r-basics.html#factors-2",
    "href": "slides/R/05-r-basics.html#factors-2",
    "title": "R Basics",
    "section": "Factors",
    "text": "Factors\n\nAnother reason we used factors is because they more efficient:\n\n\nx &lt;- sample(murders$state[c(5,33,44)], 10^7, replace = TRUE)\ny &lt;- factor(x)\nobject.size(x)\n\n80000232 bytes\n\nobject.size(y)\n\n40000648 bytes\n\n\n\nAn integer is easier to store than a character string."
  },
  {
    "objectID": "slides/R/05-r-basics.html#factors-3",
    "href": "slides/R/05-r-basics.html#factors-3",
    "title": "R Basics",
    "section": "Factors",
    "text": "Factors\nExercise: How can we make this go much faster?\n\nsystem.time({levels(y) &lt;- tolower(levels(y))})\n\n   user  system elapsed \n  0.018   0.001   0.019"
  },
  {
    "objectID": "slides/R/05-r-basics.html#factors-can-be-confusing",
    "href": "slides/R/05-r-basics.html#factors-can-be-confusing",
    "title": "R Basics",
    "section": "Factors can be confusing",
    "text": "Factors can be confusing\n\nTry to make sense of this:\n\n\nx &lt;- factor(c(\"3\",\"2\",\"1\"), levels = c(\"3\",\"2\",\"1\"))\nas.numeric(x)\n\n[1] 1 2 3\n\nx[1]\n\n[1] 3\nLevels: 3 2 1\n\nlevels(x[1])\n\n[1] \"3\" \"2\" \"1\"\n\ntable(x[1])\n\n\n3 2 1 \n1 0 0"
  },
  {
    "objectID": "slides/R/05-r-basics.html#factors-can-be-confusing-1",
    "href": "slides/R/05-r-basics.html#factors-can-be-confusing-1",
    "title": "R Basics",
    "section": "Factors can be confusing",
    "text": "Factors can be confusing\n\nAvoid keeping extra levels with droplevels:\n\n\nz &lt;- x[1]\nz &lt;- droplevels(z)\n\n\nBut note what happens if we change to another level:\n\n\nz[1] &lt;- \"1\"\nz\n\n[1] &lt;NA&gt;\nLevels: 3"
  },
  {
    "objectID": "slides/R/05-r-basics.html#nas",
    "href": "slides/R/05-r-basics.html#nas",
    "title": "R Basics",
    "section": "NAs",
    "text": "NAs\n\nNA stands for not available.\nData analysts have to deal with NAs often."
  },
  {
    "objectID": "slides/R/05-r-basics.html#nas-1",
    "href": "slides/R/05-r-basics.html#nas-1",
    "title": "R Basics",
    "section": "NAs",
    "text": "NAs\n\ndslabs includes an example dataset with NAs\n\n\nlibrary(dslabs)\nna_example[1:20]\n\n [1]  2  1  3  2  1  3  1  4  3  2  2 NA  2  2  1  4 NA  1  1  2\n\n\n\nThe is.na function is key for dealing with NAs\n\n\nis.na(na_example[1])\n\n[1] FALSE\n\nis.na(na_example[17])\n\n[1] TRUE\n\nis.na(NA)\n\n[1] TRUE\n\nis.na(\"NA\")\n\n[1] FALSE"
  },
  {
    "objectID": "slides/R/05-r-basics.html#nas-2",
    "href": "slides/R/05-r-basics.html#nas-2",
    "title": "R Basics",
    "section": "NAs",
    "text": "NAs\n\nTechnically NA is a logical\n\n\nclass(NA)\n\n[1] \"logical\"\n\n\n\nWhen used with ands and ors, NAs behaves like FALSE\n\n\nTRUE & NA\n\n[1] NA\n\nTRUE | NA\n\n[1] TRUE\n\n\n\nBut NA is not FALSE. Try this:\n\n\nif (NA) print(1) else print(0)"
  },
  {
    "objectID": "slides/R/05-r-basics.html#nans",
    "href": "slides/R/05-r-basics.html#nans",
    "title": "R Basics",
    "section": "NaNs",
    "text": "NaNs\n\nA related constant is NaN.\nUnlike NA, which is a logical, NaN is a number.\nIt is a numeric that is Not a Number.\nHere are some examples:\n\n\n0/0\n\n[1] NaN\n\nclass(0/0)\n\n[1] \"numeric\"\n\nsqrt(-1)\n\n[1] NaN\n\nlog(-1)\n\n[1] NaN"
  },
  {
    "objectID": "slides/R/05-r-basics.html#coercing",
    "href": "slides/R/05-r-basics.html#coercing",
    "title": "R Basics",
    "section": "Coercing",
    "text": "Coercing\n\nWhen you do something inconsistent with data types, R tries to figure out what you mean and change it accordingly.\nWe call this coercing.\nR does not return an error and in some cases does not return a warning either.\nThis can cause confusion and unnoticed errors.\nSo it’s important to understand how and when it happens."
  },
  {
    "objectID": "slides/R/05-r-basics.html#coercing-1",
    "href": "slides/R/05-r-basics.html#coercing-1",
    "title": "R Basics",
    "section": "Coercing",
    "text": "Coercing\n\nHere are some examples:\n\n\ntypeof(1L)\n\n[1] \"integer\"\n\ntypeof(1)\n\n[1] \"double\"\n\ntypeof(1 + 1L)\n\n[1] \"double\"\n\nc(\"a\", 1, 2)\n\n[1] \"a\" \"1\" \"2\"\n\nTRUE + FALSE\n\n[1] 1\n\nfactor(\"a\") == \"a\"\n\n[1] TRUE\n\nidentical(factor(\"a\"), \"a\")\n\n[1] FALSE"
  },
  {
    "objectID": "slides/R/05-r-basics.html#coercing-2",
    "href": "slides/R/05-r-basics.html#coercing-2",
    "title": "R Basics",
    "section": "Coercing",
    "text": "Coercing\n\nWhen R can’t figure out how to coerce, rather an error it returns an NA:\n\n\nas.numeric(\"a\")\n\n[1] NA\n\n\n\nNote that including NAs in arithmetical operations usually returns an NA.\n\n\n1 + 2 + NA\n\n[1] NA"
  },
  {
    "objectID": "slides/R/05-r-basics.html#coercing-3",
    "href": "slides/R/05-r-basics.html#coercing-3",
    "title": "R Basics",
    "section": "Coercing",
    "text": "Coercing\n\nYou want to avoid automatic coercion and instead explicitly do it.\nMost coercion functions start with as.\nHere is an example.\n\n\nx &lt;- factor(c(\"a\",\"b\",\"b\",\"c\"))\nas.character(x)\n\n[1] \"a\" \"b\" \"b\" \"c\"\n\nas.numeric(x)\n\n[1] 1 2 2 3"
  },
  {
    "objectID": "slides/R/05-r-basics.html#coercing-4",
    "href": "slides/R/05-r-basics.html#coercing-4",
    "title": "R Basics",
    "section": "Coercing",
    "text": "Coercing\n\nMore examples:\n\n\nx &lt;- c(\"12323\", \"12,323\")\nas.numeric(x)\n\n[1] 12323    NA\n\nlibrary(readr)\nparse_guess(x)\n\n[1] 12323 12323"
  },
  {
    "objectID": "slides/R/05-r-basics.html#lists",
    "href": "slides/R/05-r-basics.html#lists",
    "title": "R Basics",
    "section": "Lists",
    "text": "Lists\n\nData frames are a type of list.\nLists permit components of different types and, unlike data frames, different lengths:\n\n\nx &lt;- list(name = \"John\", id = 112, grades = c(95, 87, 92))\n\n\nThe JSON format is best represented as list in R."
  },
  {
    "objectID": "slides/R/05-r-basics.html#lists-1",
    "href": "slides/R/05-r-basics.html#lists-1",
    "title": "R Basics",
    "section": "Lists",
    "text": "Lists\n\nYou can access components in different ways:\n\n\nx$name\n\n[1] \"John\"\n\nx[[1]]\n\n[1] \"John\"\n\nx[[\"name\"]]\n\n[1] \"John\""
  },
  {
    "objectID": "slides/R/05-r-basics.html#matrics",
    "href": "slides/R/05-r-basics.html#matrics",
    "title": "R Basics",
    "section": "Matrics",
    "text": "Matrics\n\nMatrices are another widely used data type.\nThey are similar to data frames except all entries need to be of the same type.\nWe will learn more about matrices in the High Dimensional data Analysis part of the class."
  },
  {
    "objectID": "slides/R/05-r-basics.html#functions",
    "href": "slides/R/05-r-basics.html#functions",
    "title": "R Basics",
    "section": "Functions",
    "text": "Functions\n\nYou can define your own function. The form is like this:\n\n\nf &lt;- function(x, y, z = 0){\n  ### do calculations with x, y, z to compute object\n  ## return(object)\n}"
  },
  {
    "objectID": "slides/R/05-r-basics.html#functions-1",
    "href": "slides/R/05-r-basics.html#functions-1",
    "title": "R Basics",
    "section": "Functions",
    "text": "Functions\n\nHere is an example of a function that sums \\(1,2,\\dots,n\\)\n\n\ns &lt;- function(n){\n   return(sum(1:n))\n}"
  },
  {
    "objectID": "slides/R/05-r-basics.html#lexical-scope",
    "href": "slides/R/05-r-basics.html#lexical-scope",
    "title": "R Basics",
    "section": "Lexical scope",
    "text": "Lexical scope\n\nStudy what happens here:\n\n\nf &lt;- function(x){\n  cat(\"y is\", y,\"\\n\")\n  y &lt;- x\n  cat(\"y is\", y,\"\\n\")\n  return(y)\n}\ny &lt;- 2\nf(3)\n\ny is 2 \ny is 3 \n\n\n[1] 3\n\ny &lt;- f(3)\n\ny is 2 \ny is 3 \n\ny\n\n[1] 3"
  },
  {
    "objectID": "slides/R/05-r-basics.html#namespaces",
    "href": "slides/R/05-r-basics.html#namespaces",
    "title": "R Basics",
    "section": "Namespaces",
    "text": "Namespaces\n\nLook at how this function changes by typing the following:\n\n\nfilter\nlibrary(dplyr)\nfilter"
  },
  {
    "objectID": "slides/R/05-r-basics.html#namespaces-1",
    "href": "slides/R/05-r-basics.html#namespaces-1",
    "title": "R Basics",
    "section": "Namespaces",
    "text": "Namespaces\n\nNote what R searches the Global Environment first.\nUse search to see other environments R searches.\nNote many prebuilt functions are in stats."
  },
  {
    "objectID": "slides/R/05-r-basics.html#namespaces-2",
    "href": "slides/R/05-r-basics.html#namespaces-2",
    "title": "R Basics",
    "section": "Namespaces",
    "text": "Namespaces\n\nYou can explicitly say which filter you want using namespaces:\n\n\nstats::filter\ndplyr::filter"
  },
  {
    "objectID": "slides/R/05-r-basics.html#namespaces-3",
    "href": "slides/R/05-r-basics.html#namespaces-3",
    "title": "R Basics",
    "section": "Namespaces",
    "text": "Namespaces\n\nRestart yoru R Consuole and study this example:\n\n\nlibrary(dslabs)\nexists(\"murders\")\n\n[1] TRUE\n\nmurders &lt;- murders\nmurders2 &lt;- murders\nrm(murders)\nexists(\"murders\")\n\n[1] TRUE\n\ndetach(\"package:dslabs\")\nexists(\"murders\")\n\n[1] FALSE\n\nexists(\"murders2\")\n\n[1] TRUE"
  },
  {
    "objectID": "slides/R/05-r-basics.html#object-oriented-programming",
    "href": "slides/R/05-r-basics.html#object-oriented-programming",
    "title": "R Basics",
    "section": "Object Oriented Programming",
    "text": "Object Oriented Programming\n\nR uses object oriented programming (OOP).\nIt uses two approaches referred to as S3 and S4, respectively.\nS3, the original approach, is more common.\nThe S4 approach is more similar to the conventions used by modern OOP languages."
  },
  {
    "objectID": "slides/R/05-r-basics.html#object-oriented-programming-1",
    "href": "slides/R/05-r-basics.html#object-oriented-programming-1",
    "title": "R Basics",
    "section": "Object Oriented Programming",
    "text": "Object Oriented Programming\n\nTime seriesNumeric\n\n\n\nplot(co2)\n\n\n\n\n\n\n\n\n\n\n\nplot(as.numeric(co2))"
  },
  {
    "objectID": "slides/R/05-r-basics.html#object-oriented-programming-2",
    "href": "slides/R/05-r-basics.html#object-oriented-programming-2",
    "title": "R Basics",
    "section": "Object Oriented Programming",
    "text": "Object Oriented Programming\n\nNote co2 is not numeric:\n\n\nclass(co2)\n\n[1] \"ts\"\n\n\n\nThe plots are different because plot behaves different with different classes."
  },
  {
    "objectID": "slides/R/05-r-basics.html#object-oriented-programming-3",
    "href": "slides/R/05-r-basics.html#object-oriented-programming-3",
    "title": "R Basics",
    "section": "Object Oriented Programming",
    "text": "Object Oriented Programming\n\nThe first plot actually calls the function\n\n\nplot.ts\n\n\nNotice all the plot functions that start with plot by typing plot. and then tab.\nThe function plot will call different functions depending on the class of the arguments."
  },
  {
    "objectID": "slides/R/05-r-basics.html#plots",
    "href": "slides/R/05-r-basics.html#plots",
    "title": "R Basics",
    "section": "Plots",
    "text": "Plots\n\nSoon we will learn how to use the ggplot2 package to make plots.\nR base does have functions for plotting though\nSome you should know about are:\n\nplot - mainly for making scatterplots.\nlines - add lines/curves to an existing plot.\nhist - to make a histogram.\nboxplot - makes boxplots.\nimage - uses color to represent entries in a matrix."
  },
  {
    "objectID": "slides/R/05-r-basics.html#plots-1",
    "href": "slides/R/05-r-basics.html#plots-1",
    "title": "R Basics",
    "section": "Plots",
    "text": "Plots\n\nAlthough, in general, we recommend using ggplot2, R base plots are often better for quick exploratory plots.\nFor example, to make a histogram of values in x simply type:\n\n\nhist(x)\n\n\nTo make a scatter plot of y versus x and then interpolate we type:\n\n\nplot(x,y)\nlines(x,y)"
  },
  {
    "objectID": "slides/R/06-vectorization.html#vectorization",
    "href": "slides/R/06-vectorization.html#vectorization",
    "title": "Vectorization",
    "section": "Vectorization",
    "text": "Vectorization\n\nWe will be using the murders dataset in the dslabs package.\nIncludes data on 2010 gun murders for the US 50 states and DC.\nWe will use it to answer questions such as “What is the state with lowest crime rate in the Western part of the US?”"
  },
  {
    "objectID": "slides/R/06-vectorization.html#vectorization-1",
    "href": "slides/R/06-vectorization.html#vectorization-1",
    "title": "Vectorization",
    "section": "Vectorization",
    "text": "Vectorization\n\nFirst, some simple examples of vectorization.\nLet’s convert the following heights in inches to meters:\n\n\nheights &lt;- c(69, 62, 66, 70, 70, 73, 67, 73, 67, 70)\n\n\nRather than loop we use vectorization:\n\n\nheights*2.54/100\n\n [1] 1.7526 1.5748 1.6764 1.7780 1.7780 1.8542 1.7018 1.8542 1.7018 1.7780"
  },
  {
    "objectID": "slides/R/06-vectorization.html#vectorization-2",
    "href": "slides/R/06-vectorization.html#vectorization-2",
    "title": "Vectorization",
    "section": "Vectorization",
    "text": "Vectorization\n\nWe can subtract a constant from each element of a vector.\nThis is convenient for computing residuals or deviations from an average:\n\n\navg &lt;- mean(heights)\nheights - avg \n\n [1]  0.3 -6.7 -2.7  1.3  1.3  4.3 -1.7  4.3 -1.7  1.3"
  },
  {
    "objectID": "slides/R/06-vectorization.html#vectorization-3",
    "href": "slides/R/06-vectorization.html#vectorization-3",
    "title": "Vectorization",
    "section": "Vectorization",
    "text": "Vectorization\n\nThis means we can compute standard units like this:\n\n\ns &lt;- sd(heights)\n(heights - avg)/s\n\n [1]  0.08995503 -2.00899575 -0.80959530  0.38980515  0.38980515  1.28935548\n [7] -0.50974519  1.28935548 -0.50974519  0.38980515\n\n\n\nThere is actually a function, scale, that does this. We describe it soon."
  },
  {
    "objectID": "slides/R/06-vectorization.html#vectorization-4",
    "href": "slides/R/06-vectorization.html#vectorization-4",
    "title": "Vectorization",
    "section": "Vectorization",
    "text": "Vectorization\n\nIf we operate on two vectors, vectorization is componentwise.\nHere is an example:\n\n\nheights &lt;- c(69, 62, 66, 70, 70, 73, 67, 73, 67, 70)\nerror &lt;- rnorm(length(heights), 0, 0.1)\nheights + error\n\n [1] 68.93825 61.93416 65.95103 70.07787 70.02220 72.94999 67.04702 72.88729\n [9] 67.15027 70.05584"
  },
  {
    "objectID": "slides/R/06-vectorization.html#exercise",
    "href": "slides/R/06-vectorization.html#exercise",
    "title": "Vectorization",
    "section": "Exercise",
    "text": "Exercise\n\nAdd a column to the murders dataset with the murder rate.\nUse murders per 100,000 persons as the unit."
  },
  {
    "objectID": "slides/R/06-vectorization.html#functions-that-vectorize",
    "href": "slides/R/06-vectorization.html#functions-that-vectorize",
    "title": "Vectorization",
    "section": "Functions that vectorize",
    "text": "Functions that vectorize\n\nMost arithmetic functions work on vectors.\n\n\nx &lt;- 1:10\nsqrt(x)\n\n [1] 1.000000 1.414214 1.732051 2.000000 2.236068 2.449490 2.645751 2.828427\n [9] 3.000000 3.162278\n\nlog(x)\n\n [1] 0.0000000 0.6931472 1.0986123 1.3862944 1.6094379 1.7917595 1.9459101\n [8] 2.0794415 2.1972246 2.3025851\n\n2^x\n\n [1]    2    4    8   16   32   64  128  256  512 1024"
  },
  {
    "objectID": "slides/R/06-vectorization.html#functions-that-vectorize-1",
    "href": "slides/R/06-vectorization.html#functions-that-vectorize-1",
    "title": "Vectorization",
    "section": "Functions that vectorize",
    "text": "Functions that vectorize\n\nscale(heights)\n\n             [,1]\n [1,]  0.08995503\n [2,] -2.00899575\n [3,] -0.80959530\n [4,]  0.38980515\n [5,]  0.38980515\n [6,]  1.28935548\n [7,] -0.50974519\n [8,]  1.28935548\n [9,] -0.50974519\n[10,]  0.38980515\nattr(,\"scaled:center\")\n[1] 68.7\nattr(,\"scaled:scale\")\n[1] 3.335\n\n\nprovides the same results,\n\n(heights - mean(heights))/sd(heights)\n\n [1]  0.08995503 -2.00899575 -0.80959530  0.38980515  0.38980515  1.28935548\n [7] -0.50974519  1.28935548 -0.50974519  0.38980515"
  },
  {
    "objectID": "slides/R/06-vectorization.html#functions-that-vectorize-2",
    "href": "slides/R/06-vectorization.html#functions-that-vectorize-2",
    "title": "Vectorization",
    "section": "Functions that vectorize",
    "text": "Functions that vectorize\n\nBut scale coerces to a column matrix:\n\n\nclass(scale(heights))\n\n[1] \"matrix\" \"array\""
  },
  {
    "objectID": "slides/R/06-vectorization.html#functions-that-vectorize-3",
    "href": "slides/R/06-vectorization.html#functions-that-vectorize-3",
    "title": "Vectorization",
    "section": "Functions that vectorize",
    "text": "Functions that vectorize\n\nThe conditional function if-else does not vectorize.\nFunctions such as any and all, covert vectors to logicals of lenght one needed for if-else.\nA particularly useful function is a vectorized version ifelse.\nHere is an example:\n\n\na &lt;- c(0, 1, 2, -4, 5)\nifelse(a &gt; 0, 1/a, NA)\n\n[1]  NA 1.0 0.5  NA 0.2"
  },
  {
    "objectID": "slides/R/06-vectorization.html#indexing",
    "href": "slides/R/06-vectorization.html#indexing",
    "title": "Vectorization",
    "section": "Indexing",
    "text": "Indexing\n\nVectorization also works for logical relationships:\n\n\nlibrary(dslabs)\nind &lt;- murders$population &lt; 10^6\n\n\nA convenient aspect of this is that you can subset a vector using this logical vector for indexing:\n\n\nmurders$state[ind]\n\n[1] \"Alaska\"               \"Delaware\"             \"District of Columbia\"\n[4] \"Montana\"              \"North Dakota\"         \"South Dakota\"        \n[7] \"Vermont\"              \"Wyoming\""
  },
  {
    "objectID": "slides/R/06-vectorization.html#indexing-1",
    "href": "slides/R/06-vectorization.html#indexing-1",
    "title": "Vectorization",
    "section": "Indexing",
    "text": "Indexing\n\nYou can also use vectorization to apply logical operators:\n\n\nind &lt;- murders$population &lt; 10^6 & murders$region == \"West\"\nmurders$state[ind]\n\n[1] \"Alaska\"  \"Montana\" \"Wyoming\""
  },
  {
    "objectID": "slides/R/06-vectorization.html#split",
    "href": "slides/R/06-vectorization.html#split",
    "title": "Vectorization",
    "section": "split",
    "text": "split\n\nsplit is a useful function to get indexes using a factor:\n\n\ninds &lt;- with(murders, split(seq_along(region), region))\nmurders$state[inds$West]\n\n [1] \"Alaska\"     \"Arizona\"    \"California\" \"Colorado\"   \"Hawaii\"    \n [6] \"Idaho\"      \"Montana\"    \"Nevada\"     \"New Mexico\" \"Oregon\"    \n[11] \"Utah\"       \"Washington\" \"Wyoming\""
  },
  {
    "objectID": "slides/R/06-vectorization.html#functions-for-subsetting",
    "href": "slides/R/06-vectorization.html#functions-for-subsetting",
    "title": "Vectorization",
    "section": "Functions for subsetting",
    "text": "Functions for subsetting\n\nThe functions which, match and the operator %in% are useful for sub-setting\nTo understand how they work it’s best to use examples."
  },
  {
    "objectID": "slides/R/06-vectorization.html#which",
    "href": "slides/R/06-vectorization.html#which",
    "title": "Vectorization",
    "section": "which",
    "text": "which\n\nind &lt;- which(murders$state == \"California\")\nind\n\n[1] 5\n\nmurders[ind,]\n\n       state abb region population total\n5 California  CA   West   37253956  1257"
  },
  {
    "objectID": "slides/R/06-vectorization.html#match",
    "href": "slides/R/06-vectorization.html#match",
    "title": "Vectorization",
    "section": "match",
    "text": "match\n\nind &lt;- match(c(\"New York\", \"Florida\", \"Texas\"), murders$state)\nind\n\n[1] 33 10 44\n\nmurders[ind,]\n\n      state abb    region population total\n33 New York  NY Northeast   19378102   517\n10  Florida  FL     South   19687653   669\n44    Texas  TX     South   25145561   805"
  },
  {
    "objectID": "slides/R/06-vectorization.html#in",
    "href": "slides/R/06-vectorization.html#in",
    "title": "Vectorization",
    "section": "%in%",
    "text": "%in%\n\nind &lt;- which(murders$state %in% c(\"New York\", \"Florida\", \"Texas\"))\nind\n\n[1] 10 33 44\n\nmurders[ind,]\n\n      state abb    region population total\n10  Florida  FL     South   19687653   669\n33 New York  NY Northeast   19378102   517\n44    Texas  TX     South   25145561   805\n\n\n\nNote this is similar to using match.\nBut note the order is different."
  },
  {
    "objectID": "slides/R/06-vectorization.html#match-versus-in",
    "href": "slides/R/06-vectorization.html#match-versus-in",
    "title": "Vectorization",
    "section": "match versus %in%",
    "text": "match versus %in%\n\nc(\"Boston\", \"Dakota\", \"Washington\") %in% murders$state\n\n[1] FALSE FALSE  TRUE\n\n\n\nmatch(c(\"Boston\", \"Dakota\", \"Washington\"), murders$state)\n\n[1] NA NA 48\n\n\n\nmatch(murders$state, c(\"Boston\", \"Dakota\", \"Washington\"))\n\n [1] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA\n[26] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA  3 NA NA\n[51] NA"
  },
  {
    "objectID": "slides/R/06-vectorization.html#the-apply-functions",
    "href": "slides/R/06-vectorization.html#the-apply-functions",
    "title": "Vectorization",
    "section": "The apply functions",
    "text": "The apply functions\n\nThe apply functions let use the concept of vectorization with functions that don’t vectorize.\nHere is an example of a function that won’t vectorize in a convenient way:\n\n\ns &lt;- function(n){\n   return(sum(1:n))\n}\n\n\nTry it on a vector:\n\n\nns &lt;- c(25, 100, 1000)\ns(ns)\n\n[1] 325"
  },
  {
    "objectID": "slides/R/06-vectorization.html#the-apply-functions-1",
    "href": "slides/R/06-vectorization.html#the-apply-functions-1",
    "title": "Vectorization",
    "section": "The apply functions",
    "text": "The apply functions\n\nWe can use sapply, one of the apply functions:\n\n\nsapply(ns, s)\n\n[1]    325   5050 500500\n\n\n\nsapply will work on any vector, including lists."
  },
  {
    "objectID": "slides/R/06-vectorization.html#the-apply-functions-2",
    "href": "slides/R/06-vectorization.html#the-apply-functions-2",
    "title": "Vectorization",
    "section": "The apply functions",
    "text": "The apply functions\n\nThere are other apply functions:\n\nlapply - returns a list. Convenient when the function returns something other than a number.\ntapply - can apply to subsets defined by second variable.\nmapply - multivariate version of sapply.\napply - applies function to rows or columns o matrix.\n\nWe will learn some of these as we go."
  },
  {
    "objectID": "slides/R/08-ggplot2.html#ggplot2",
    "href": "slides/R/08-ggplot2.html#ggplot2",
    "title": "ggplot2",
    "section": "ggplot2",
    "text": "ggplot2\nThe code in this lecture assumes these three libraries are loaded:\n\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(dslabs)"
  },
  {
    "objectID": "slides/R/08-ggplot2.html#the-components-of-a-graph",
    "href": "slides/R/08-ggplot2.html#the-components-of-a-graph",
    "title": "ggplot2",
    "section": "The components of a graph",
    "text": "The components of a graph\nIn today’s lecture we recreate this:"
  },
  {
    "objectID": "slides/R/08-ggplot2.html#the-components-of-a-graph-1",
    "href": "slides/R/08-ggplot2.html#the-components-of-a-graph-1",
    "title": "ggplot2",
    "section": "The components of a graph",
    "text": "The components of a graph\n\ngg stands for grammar of graphics.\nAnalogy: we learn verbs and nouns to construct sentences.\nThe first step in learning ggplot2 is breaking a graph apart into components.\nLet’s break down the plot we want to recreate while introducing some ggplot2 terminology."
  },
  {
    "objectID": "slides/R/08-ggplot2.html#the-components-of-a-graph-2",
    "href": "slides/R/08-ggplot2.html#the-components-of-a-graph-2",
    "title": "ggplot2",
    "section": "The components of a graph",
    "text": "The components of a graph\n\nThe main three components to note are:\n\nData: The US murders data table is being summarized. We refer to this as the data component.\n\nGeometry: The plot above is a scatterplot. This is referred to as the geometry component.\nAesthetic mapping: How we map visual cues to information provided by the dataset."
  },
  {
    "objectID": "slides/R/08-ggplot2.html#aesthetic-mapping",
    "href": "slides/R/08-ggplot2.html#aesthetic-mapping",
    "title": "ggplot2",
    "section": "Aesthetic mapping",
    "text": "Aesthetic mapping\n\nThe two most important cues in the plot we are recreating are the point positions on the x-axis and y-axis.\nEach point represents a different observation, and we map data about these observations to visual cues like x- and y-scale.\nColor is another visual cue that we map to region.\nHow we define the mapping depends on what geometry we are using."
  },
  {
    "objectID": "slides/R/08-ggplot2.html#the-components-of-a-graph-3",
    "href": "slides/R/08-ggplot2.html#the-components-of-a-graph-3",
    "title": "ggplot2",
    "section": "The components of a graph",
    "text": "The components of a graph\n\nWe also note that:\n\nThe points are labeled with the state abbreviations.\nThe range of the x-axis and y-axis appears to be defined by the range of the data.\nAxes are in the log-scales.\nThere are labels, a title, a legend, and we use the style of The Economist magazine.\n\nWe will now construct the plot, piece by piece."
  },
  {
    "objectID": "slides/R/08-ggplot2.html#ggplot-objects",
    "href": "slides/R/08-ggplot2.html#ggplot-objects",
    "title": "ggplot2",
    "section": "ggplot objects",
    "text": "ggplot objects\n\nStart by defining the dataset:\n\n\nggplot(data = murders)\n\n\nWe can also use the pipe:\n\n\nmurders |&gt; ggplot()\n\n\nWe call also assign the output to a variable\n\n\np &lt;- ggplot(data = murders)\nclass(p)\n\n[1] \"gg\"     \"ggplot\""
  },
  {
    "objectID": "slides/R/08-ggplot2.html#ggplot-objects-1",
    "href": "slides/R/08-ggplot2.html#ggplot-objects-1",
    "title": "ggplot2",
    "section": "ggplot objects",
    "text": "ggplot objects\nTo see the plot we can print it:\n\nprint(p)"
  },
  {
    "objectID": "slides/R/08-ggplot2.html#geometries",
    "href": "slides/R/08-ggplot2.html#geometries",
    "title": "ggplot2",
    "section": "Geometries",
    "text": "Geometries\n\nWe create graphs by adding layers.\nLayers define geometries, compute summary statistics, define what scales to use, or even change styles.\nTo add layers, we use the symbol +.\nIn general, a line of code will look like this:\n\n\nDATA |&gt; ggplot() + LAYER 1 + LAYER 2 + ... + LAYER N\n\n\nUsually, the first added layer defines the geometry."
  },
  {
    "objectID": "slides/R/08-ggplot2.html#geometries-1",
    "href": "slides/R/08-ggplot2.html#geometries-1",
    "title": "ggplot2",
    "section": "Geometries",
    "text": "Geometries\n\nSo if we want to make a scatterplot, what geometry do we use?\nLet’s look at the cheat sheet: https://rstudio.github.io/cheatsheets/data-visualization.pdf"
  },
  {
    "objectID": "slides/R/08-ggplot2.html#aesthetic-mappings",
    "href": "slides/R/08-ggplot2.html#aesthetic-mappings",
    "title": "ggplot2",
    "section": "Aesthetic mappings",
    "text": "Aesthetic mappings\n\nTo make a scatter plot we use geom_points.\nThe help file tells us this is how we use it:\n\n\nmurders |&gt; ggplot() + geom_point(aes(x = population/10^6, y = total))"
  },
  {
    "objectID": "slides/R/08-ggplot2.html#aesthetic-mappings-1",
    "href": "slides/R/08-ggplot2.html#aesthetic-mappings-1",
    "title": "ggplot2",
    "section": "Aesthetic mappings",
    "text": "Aesthetic mappings\n\nSince we defined p earlier, we can add a layer like this:\n\n\np + geom_point(aes(population/10^6, total))\n\n\n\nNote we are no longer using x= and y =."
  },
  {
    "objectID": "slides/R/08-ggplot2.html#layers",
    "href": "slides/R/08-ggplot2.html#layers",
    "title": "ggplot2",
    "section": "Layers",
    "text": "Layers\n\nTo add text we use geom_text:\n\n\np + geom_point(aes(population/10^6, total)) +\n  geom_text(aes(population/10^6, total, label = abb))"
  },
  {
    "objectID": "slides/R/08-ggplot2.html#layers-1",
    "href": "slides/R/08-ggplot2.html#layers-1",
    "title": "ggplot2",
    "section": "Layers",
    "text": "Layers\n\nAs an example of the unique behavior of aes note that this call:\n\n\np_test &lt;- p + geom_text(aes(population/10^6, total, label = abb))\n\nis fine, whereas this call:\n\np_test &lt;- p + geom_text(aes(population/10^6, total), label = abb) \n\nwill give you an error since abb is not found because it is outside of the aes function.\n\nThe layer geom_text does not know where to find abb: it’s a column name and not a global variable."
  },
  {
    "objectID": "slides/R/08-ggplot2.html#tinkering-with-arguments",
    "href": "slides/R/08-ggplot2.html#tinkering-with-arguments",
    "title": "ggplot2",
    "section": "Tinkering with arguments",
    "text": "Tinkering with arguments\n\np + geom_point(aes(population/10^6, total), size = 3) +\n  geom_text(aes(population/10^6, total, label = abb))\n\n\n\nsize can be an aesthetic mapping, but here it is not, so all points get bigger."
  },
  {
    "objectID": "slides/R/08-ggplot2.html#tinkering-with-arguments-1",
    "href": "slides/R/08-ggplot2.html#tinkering-with-arguments-1",
    "title": "ggplot2",
    "section": "Tinkering with arguments",
    "text": "Tinkering with arguments\n\np + geom_point(aes(population/10^6, total), size = 3) +\n  geom_text(aes(population/10^6, total, label = abb), nudge_x = 1.5)\n\n\n\nnudge_x is not an aesthetic mapping."
  },
  {
    "objectID": "slides/R/08-ggplot2.html#global-versus-local-mappings",
    "href": "slides/R/08-ggplot2.html#global-versus-local-mappings",
    "title": "ggplot2",
    "section": "Global versus local mappings",
    "text": "Global versus local mappings\n\nNote that in we can define a global aes in the ggplot function:\n\n\nargs(ggplot)\n\nfunction (data = NULL, mapping = aes(), ..., environment = parent.frame()) \nNULL\n\n\n\nWe refer to this as the global mapping."
  },
  {
    "objectID": "slides/R/08-ggplot2.html#global-versus-local-mappings-1",
    "href": "slides/R/08-ggplot2.html#global-versus-local-mappings-1",
    "title": "ggplot2",
    "section": "Global versus local mappings",
    "text": "Global versus local mappings\n\nAll the layers will assume the global mapping unless we explicitly define another one.\n\n\np &lt;- murders |&gt; ggplot(aes(population/10^6, total, label = abb))\np + geom_point(size = 3) + geom_text(nudge_x = 1.5)\n\n\n\nThe two layers use the global mapping."
  },
  {
    "objectID": "slides/R/08-ggplot2.html#global-versus-local-mappings-2",
    "href": "slides/R/08-ggplot2.html#global-versus-local-mappings-2",
    "title": "ggplot2",
    "section": "Global versus local mappings",
    "text": "Global versus local mappings\n\nWe can override the global aes by defining one in the geometry functions:\n\n\np + geom_point(size = 3) +  \n  geom_text(aes(x = 10, y = 800, label = \"Hello there!\"))"
  },
  {
    "objectID": "slides/R/08-ggplot2.html#scales",
    "href": "slides/R/08-ggplot2.html#scales",
    "title": "ggplot2",
    "section": "Scales",
    "text": "Scales\n\nLayers can define transformations:\n\n\np + geom_point(size = 3) +  \n  geom_text(nudge_x = 0.05) + \n  scale_x_continuous(trans = \"log10\") +\n  scale_y_continuous(trans = \"log10\")"
  },
  {
    "objectID": "slides/R/08-ggplot2.html#scales-1",
    "href": "slides/R/08-ggplot2.html#scales-1",
    "title": "ggplot2",
    "section": "Scales",
    "text": "Scales\n\nThis particular transformation is so common that ggplot2 provides the specialized functions:\n\n\np + geom_point(size = 3) +  \n  geom_text(nudge_x = 0.05) + \n  scale_x_log10() +\n  scale_y_log10()"
  },
  {
    "objectID": "slides/R/08-ggplot2.html#labels-and-titles",
    "href": "slides/R/08-ggplot2.html#labels-and-titles",
    "title": "ggplot2",
    "section": "Labels and titles",
    "text": "Labels and titles\n\nThere are layers for adding labels and titles:\n\n\np + geom_point(size = 3) +  \n  geom_text(nudge_x = 0.05) + \n  scale_x_log10() +\n  scale_y_log10() +\n  xlab(\"Populations in millions (log scale)\") + \n  ylab(\"Total number of murders (log scale)\") +\n  ggtitle(\"US Gun Murders in 2010\")"
  },
  {
    "objectID": "slides/R/08-ggplot2.html#labels-and-titles-1",
    "href": "slides/R/08-ggplot2.html#labels-and-titles-1",
    "title": "ggplot2",
    "section": "Labels and titles",
    "text": "Labels and titles\n\nWe can also use the labs function:\n\n\np + geom_point(size = 3) +  \n  geom_text(nudge_x = 0.05) + \n  scale_x_log10() +\n  scale_y_log10() +\n  labs(x = \"Populations in millions (log scale)\", \n       y = \"Total number of murders (log scale)\", \n       title = \"US Gun Murders in 2010\")\n\n\nThis produces the same graph as in the previous slide."
  },
  {
    "objectID": "slides/R/08-ggplot2.html#almost-there",
    "href": "slides/R/08-ggplot2.html#almost-there",
    "title": "ggplot2",
    "section": "Almost there",
    "text": "Almost there\n\nTargetCurrent draftCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\np + geom_point(size = 3) +  \n  geom_text(nudge_x = 0.05) + \n  scale_x_log10() +\n  scale_y_log10() +\n  labs(x = \"Populations in millions (log scale)\", \n       y = \"Total number of murders (log scale)\", \n       title = \"US Gun Murders in 2010\")"
  },
  {
    "objectID": "slides/R/08-ggplot2.html#adding-color",
    "href": "slides/R/08-ggplot2.html#adding-color",
    "title": "ggplot2",
    "section": "Adding color",
    "text": "Adding color\n\nmurders |&gt; ggplot(aes(population/10^6, total, label = abb)) +   \n  geom_text(nudge_x = 0.05) + \n  scale_x_log10() +\n  scale_y_log10() +\n  labs(x = \"Populations in millions (log scale)\", \n       y = \"Total number of murders (log scale)\", \n       title = \"US Gun Murders in 2010\") +\n  geom_point(size = 3, color = \"blue\")"
  },
  {
    "objectID": "slides/R/08-ggplot2.html#a-mapped-color",
    "href": "slides/R/08-ggplot2.html#a-mapped-color",
    "title": "ggplot2",
    "section": "A mapped color",
    "text": "A mapped color\n\nmurders |&gt; ggplot(aes(population/10^6, total, label = abb)) +   \n  geom_text(nudge_x = 0.05) + \n  scale_x_log10() +\n  scale_y_log10() +\n  labs(x = \"Populations in millions (log scale)\", \n       y = \"Total number of murders (log scale)\", \n       title = \"US Gun Murders in 2010\") +\n  geom_point(aes(col = region), size = 3)\n\n\nA legend is added automatically!"
  },
  {
    "objectID": "slides/R/08-ggplot2.html#change-legend-name",
    "href": "slides/R/08-ggplot2.html#change-legend-name",
    "title": "ggplot2",
    "section": "Change legend name",
    "text": "Change legend name\n\nmurders |&gt; ggplot(aes(population/10^6, total, label = abb)) +   \n  geom_text(nudge_x = 0.05) + \n  scale_x_log10() +\n  scale_y_log10() +\n  labs(x = \"Populations in millions (log scale)\", \n       y = \"Total number of murders (log scale)\", \n       title = \"US Gun Murders in 2010\",\n       color = \"Region\") +\n  geom_point(aes(col = region), size = 3)"
  },
  {
    "objectID": "slides/R/08-ggplot2.html#other-adjustments",
    "href": "slides/R/08-ggplot2.html#other-adjustments",
    "title": "ggplot2",
    "section": "Other adjustments",
    "text": "Other adjustments\n\nWe want to add a line with intercept the US rate.\nLets compute that\n\n\nr &lt;- murders |&gt; \n  summarize(rate = sum(total) /  sum(population) * 10^6) |&gt; \n  pull(rate)"
  },
  {
    "objectID": "slides/R/08-ggplot2.html#add-a-line",
    "href": "slides/R/08-ggplot2.html#add-a-line",
    "title": "ggplot2",
    "section": "Add a line",
    "text": "Add a line\n\nmurders |&gt; ggplot(aes(population/10^6, total, label = abb)) +   \n  geom_text(nudge_x = 0.05) + \n  scale_x_log10() +\n  scale_y_log10() +\n  labs(x = \"Populations in millions (log scale)\", \n       y = \"Total number of murders (log scale)\", \n       title = \"US Gun Murders in 2010\",\n       color = \"Region\") +\n  geom_point(aes(col = region), size = 3) +\n  geom_abline(intercept = log10(r), lty = 2, color = \"darkgrey\")"
  },
  {
    "objectID": "slides/R/08-ggplot2.html#we-are-close",
    "href": "slides/R/08-ggplot2.html#we-are-close",
    "title": "ggplot2",
    "section": "We are close!",
    "text": "We are close!"
  },
  {
    "objectID": "slides/R/08-ggplot2.html#other-adjustments-1",
    "href": "slides/R/08-ggplot2.html#other-adjustments-1",
    "title": "ggplot2",
    "section": "Other adjustments",
    "text": "Other adjustments\n\nTo make the final adjustments we will save our current draft in p and add layers.\n\n\np &lt;- murders |&gt; ggplot(aes(population/10^6, total, label = abb)) +   \n  geom_text(nudge_x = 0.05) + \n  scale_x_log10() +\n  scale_y_log10() +\n  labs(x = \"Populations in millions (log scale)\", \n       y = \"Total number of murders (log scale)\", \n       title = \"US Gun Murders in 2010\",\n       color = \"Region\") +\n  geom_point(aes(col = region), size = 3) +\n  geom_abline(intercept = log10(r), lty = 2, color = \"darkgrey\")"
  },
  {
    "objectID": "slides/R/08-ggplot2.html#add-on-packages",
    "href": "slides/R/08-ggplot2.html#add-on-packages",
    "title": "ggplot2",
    "section": "Add-on packages",
    "text": "Add-on packages\n\nThe dslabs package can define the look used in the textbook:\n\n\nds_theme_set()\n\n\nMany other themes are added by the package ggthemes."
  },
  {
    "objectID": "slides/R/08-ggplot2.html#add-on-packages-1",
    "href": "slides/R/08-ggplot2.html#add-on-packages-1",
    "title": "ggplot2",
    "section": "Add-on packages",
    "text": "Add-on packages\nggthemes provides pre-designed themes.\n\nlibrary(ggthemes)\np + theme_economist()"
  },
  {
    "objectID": "slides/R/08-ggplot2.html#add-on-packages-2",
    "href": "slides/R/08-ggplot2.html#add-on-packages-2",
    "title": "ggplot2",
    "section": "Add-on packages",
    "text": "Add-on packages\nHere is the FiveThirtyEight theme:\n\np + theme_fivethirtyeight()"
  },
  {
    "objectID": "slides/R/08-ggplot2.html#add-on-packages-3",
    "href": "slides/R/08-ggplot2.html#add-on-packages-3",
    "title": "ggplot2",
    "section": "Add-on packages",
    "text": "Add-on packages\nIf you want to ruin the plot use the excel theme:\n\np + theme_excel()"
  },
  {
    "objectID": "slides/R/08-ggplot2.html#add-on-packages-4",
    "href": "slides/R/08-ggplot2.html#add-on-packages-4",
    "title": "ggplot2",
    "section": "Add-on packages",
    "text": "Add-on packages\nThemePark provides fun themes:\n\nlibrary(ThemePark)\np + theme_starwars()"
  },
  {
    "objectID": "slides/R/08-ggplot2.html#add-on-packages-5",
    "href": "slides/R/08-ggplot2.html#add-on-packages-5",
    "title": "ggplot2",
    "section": "Add-on packages",
    "text": "Add-on packages\nThis is a fan favorite:\n\np + theme_barbie()"
  },
  {
    "objectID": "slides/R/08-ggplot2.html#add-on-packages-6",
    "href": "slides/R/08-ggplot2.html#add-on-packages-6",
    "title": "ggplot2",
    "section": "Add-on packages",
    "text": "Add-on packages\n\nTo avoid the state abbreviations being on top of each other we can use the ggrepel package.\nWe change the layer geom_text(nudge_x = 0.05) to geom_text_repel()"
  },
  {
    "objectID": "slides/R/08-ggplot2.html#putting-it-all-together",
    "href": "slides/R/08-ggplot2.html#putting-it-all-together",
    "title": "ggplot2",
    "section": "Putting it all together",
    "text": "Putting it all together\n\nCodePlot\n\n\n\nlibrary(ggthemes)\nlibrary(ggrepel)\n\nr &lt;- murders |&gt; \n  summarize(rate = sum(total) /  sum(population) * 10^6) |&gt;\n  pull(rate)\n\nmurders |&gt; ggplot(aes(population/10^6, total, label = abb)) +   \n  geom_abline(intercept = log10(r), lty = 2, color = \"darkgrey\") +\n  geom_point(aes(col = region), size = 3) +\n  geom_text_repel() + \n  scale_x_log10() +\n  scale_y_log10() +\n  labs(x = \"Populations in millions (log scale)\", \n       y = \"Total number of murders (log scale)\", \n       title = \"US Gun Murders in 2010\",\n       color = \"Region\") +\n  theme_economist()"
  },
  {
    "objectID": "slides/R/08-ggplot2.html#grids-of-plots",
    "href": "slides/R/08-ggplot2.html#grids-of-plots",
    "title": "ggplot2",
    "section": "Grids of plots",
    "text": "Grids of plots\n\nWe often want to put plots next to each other.\nThe gridExtra package permits us to do that:\n\n\nCodePlot\n\n\n\nlibrary(gridExtra)\np1 &lt;- murders |&gt; \n  ggplot(aes(log10(population))) + \n  geom_histogram()\np2 &lt;- murders |&gt; \n  gplot(aes(log10(population), log10(total))) + \n  geom_point()\ngrid.arrange(p1, p2, ncol = 2)"
  },
  {
    "objectID": "slides/R/08-ggplot2.html#grids-of-plots-1",
    "href": "slides/R/08-ggplot2.html#grids-of-plots-1",
    "title": "ggplot2",
    "section": "Grids of plots",
    "text": "Grids of plots\n\nThere are several additional packages for combining ggplot2 plots into visually appealing layouts:**\ncowplot: A versatile package designed for publication-quality plots, offering seamless integration with ggplot2.\nggpubr: Provides user-friendly functions for combining and annotating ggplot2 plots with minimal effort.\nNew packages frequently emerge. Explore beyond these options and stay curious—there might be new tools that suit your needs even better!"
  },
  {
    "objectID": "slides/wrangling/10-intro-to-wrangling.html#data-wrangling",
    "href": "slides/wrangling/10-intro-to-wrangling.html#data-wrangling",
    "title": "Introduction to Wrangling",
    "section": "Data Wrangling",
    "text": "Data Wrangling\n\nThe two datasets used in the problem sets are already tidy data frames.\nHowever, very rarely in a data science project is data already available in this form.\nMuch more typical is for the data to be in a file, a database, or extracted from a document, including web pages, tweets, or PDFs.\nAs a result, data might be unstructured in complex ways."
  },
  {
    "objectID": "slides/wrangling/10-intro-to-wrangling.html#data-wrangling-1",
    "href": "slides/wrangling/10-intro-to-wrangling.html#data-wrangling-1",
    "title": "Introduction to Wrangling",
    "section": "Data Wrangling",
    "text": "Data Wrangling\n\nData wrangling is what we call the process of structuring data from it’s original state into a form that permits us to focus on analysis.\nTidy data is an example of a form that permits us to focus on analysis.\nWe focus on tidy data as a target, but we can have other forms as targets, such as matrices."
  },
  {
    "objectID": "slides/wrangling/10-intro-to-wrangling.html#data-wrangling-2",
    "href": "slides/wrangling/10-intro-to-wrangling.html#data-wrangling-2",
    "title": "Introduction to Wrangling",
    "section": "Data Wrangling",
    "text": "Data Wrangling\nData wrangling can involve several complicated steps such as:\n\nextracting data from a file,\nconverting nested key-value pairs into a data frame,\nintegrating data from different source, and\nconstructing requests for data bases."
  },
  {
    "objectID": "slides/wrangling/10-intro-to-wrangling.html#data-wrangling-3",
    "href": "slides/wrangling/10-intro-to-wrangling.html#data-wrangling-3",
    "title": "Introduction to Wrangling",
    "section": "Data Wrangling",
    "text": "Data Wrangling\nToday we briefly discuss five concepts/tools considered essential for data wrangling:\n\nImporting data from files\nRESTful APIs\nJoining tables\nhtml parsing\nworking with dates and times\nlocales"
  },
  {
    "objectID": "slides/wrangling/10-intro-to-wrangling.html#data-wrangling-4",
    "href": "slides/wrangling/10-intro-to-wrangling.html#data-wrangling-4",
    "title": "Introduction to Wrangling",
    "section": "Data Wrangling",
    "text": "Data Wrangling\n\nWe barely scratch the surface on these topics.\nRarely are all these relevant for a single analysis.\nYou will likely face them all at some point.\nLecture goal is to make you aware of challenges, tools to tackle them, and help you learn how to learn more."
  },
  {
    "objectID": "slides/wrangling/10-intro-to-wrangling.html#further-learning",
    "href": "slides/wrangling/10-intro-to-wrangling.html#further-learning",
    "title": "Introduction to Wrangling",
    "section": "Further learning",
    "text": "Further learning\n\nSQL widely used in data-intensive industries to manage and manipulate large databases.\nIn R, dplyr functions like filter, select, and the joins we will learn this week, mirror SQL operations.\nBy learning dplyr, you’ve already covered many key SQL concepts and makes the transition to SQL easier.\nRecommended SQL Resources: W3Schools, Codecademy, Khan Academy, and SQLZoo"
  },
  {
    "objectID": "slides/wrangling/14-data-apis.html#data-apis",
    "href": "slides/wrangling/14-data-apis.html#data-apis",
    "title": "Data APIs",
    "section": "Data APIs",
    "text": "Data APIs\n\nAn Application Programming Interface (API) is a set of rules and protocols that allows different software entities to communicate with each other.\nIt defines methods and data formats that software components should use when requesting and exchanging information.\nAPIs play a crucial role in enabling the integration that make today’s software so interconnected and versatile."
  },
  {
    "objectID": "slides/wrangling/14-data-apis.html#types-and-concepts",
    "href": "slides/wrangling/14-data-apis.html#types-and-concepts",
    "title": "Data APIs",
    "section": "Types and concepts",
    "text": "Types and concepts\nThe main APIs related to retrieving data are:\n\nWeb Services - Often built using protocols like HTTP/HTTPS.\nDatabase APIs - Enable communication between an application and a database, SQL-based calls for example.\n\nHere we focus on Web Services since it more common among public resources such CDC and the US Census."
  },
  {
    "objectID": "slides/wrangling/14-data-apis.html#key-concepts",
    "href": "slides/wrangling/14-data-apis.html#key-concepts",
    "title": "Data APIs",
    "section": "Key concepts",
    "text": "Key concepts\n\nEndpoints: Usually a URL where API can be accessed.\nMethods: Actions that can be performed, for example HTTP methods like GET, POST, PUT, or DELETE.\nRequest: Asking the API to perform a function.\nResponse: The data it returns.\nRate Limits: Restrictions on calls to API.\nAuthentication and Authorization: Methods include API keys, OAuth, or Jason Web Tokens (JWT).\nData Formats: Many web APIs exchange data in a specific format, often JSON or CSV."
  },
  {
    "objectID": "slides/wrangling/14-data-apis.html#json",
    "href": "slides/wrangling/14-data-apis.html#json",
    "title": "Data APIs",
    "section": "JSON",
    "text": "JSON\n\nSharing data on the internet has become more and more common.\nUnfortunately, providers use different formats, which makes wrangling harder.\nYet there are some standards that are also becoming more common.\nA format that is widely being adopted is the JavaScript Object Notation or JSON.\nBecause this format is very general, it is nothing like a spreadsheet."
  },
  {
    "objectID": "slides/wrangling/14-data-apis.html#json-1",
    "href": "slides/wrangling/14-data-apis.html#json-1",
    "title": "Data APIs",
    "section": "JSON",
    "text": "JSON\n\nJSON files look like code you use to define a list:\n\n\n\n[\n  {\n    \"name\": \"Miguel\",\n    \"student_id\": 1,\n    \"exam_1\": 85,\n    \"exam_2\": 86\n  },\n  {\n    \"name\": \"Sofia\",\n    \"student_id\": 2,\n    \"exam_1\": 94,\n    \"exam_2\": 93\n  },\n  {\n    \"name\": \"Aya\",\n    \"student_id\": 3,\n    \"exam_1\": 87,\n    \"exam_2\": 88\n  },\n  {\n    \"name\": \"Cheng\",\n    \"student_id\": 4,\n    \"exam_1\": 90,\n    \"exam_2\": 91\n  }\n] \n\n\n\nThe file above actually represents a data frame."
  },
  {
    "objectID": "slides/wrangling/14-data-apis.html#json-2",
    "href": "slides/wrangling/14-data-apis.html#json-2",
    "title": "Data APIs",
    "section": "JSON",
    "text": "JSON\n\nWe can use the function fromJSON from the jsonlite package to read files.\nHere is an example providing information Nobel prize winners:\n\n\nlibrary(jsonlite) \nnobel &lt;- fromJSON(\"http://api.nobelprize.org/v1/prize.json\") \n\n\nThis downloads a JSON file and reads into a list:\n\n\nclass(nobel)\n\n[1] \"list\""
  },
  {
    "objectID": "slides/wrangling/14-data-apis.html#json-3",
    "href": "slides/wrangling/14-data-apis.html#json-3",
    "title": "Data APIs",
    "section": "JSON",
    "text": "JSON\nThe JSON parsers have arguments that make the list components into vectors and lists into data frames when possible:\n\nsimplifyVector\nsimplifyDataFrame\nsimplifyMatrix\nflatten"
  },
  {
    "objectID": "slides/wrangling/14-data-apis.html#json-4",
    "href": "slides/wrangling/14-data-apis.html#json-4",
    "title": "Data APIs",
    "section": "JSON",
    "text": "JSON\n\nThe object is rather complicated. The prizes component includes a list of data frames with information about Nobel Laureates:\n\n\nnobel$prizes |&gt; \n  filter(category == \"literature\" & year == \"1971\") |&gt;  \n  pull(laureates) |&gt; \n  first() |&gt; \n  select(id, firstname, surname) \n\n   id firstname surname\n1 645     Pablo  Neruda"
  },
  {
    "objectID": "slides/wrangling/14-data-apis.html#the-httr2-package",
    "href": "slides/wrangling/14-data-apis.html#the-httr2-package",
    "title": "Data APIs",
    "section": "The httr2 package",
    "text": "The httr2 package\n\nHTTPS is the most widely used protocol for data sharing through the internet.\nThe httr2 package provides functions to work with HTTPS requests.\nOne of the core functions in this package is request, which is used to form request to send to web services.\nThe req_perform function sends the request.\nThis request function forms an HTTP GET request to the specified URL."
  },
  {
    "objectID": "slides/wrangling/14-data-apis.html#the-httr2-package-1",
    "href": "slides/wrangling/14-data-apis.html#the-httr2-package-1",
    "title": "Data APIs",
    "section": "The httr2 package",
    "text": "The httr2 package\n\nTypically, HTTP GET requests are used to retrieve information from a server based on the provided URL.\nThe function returns an object of class response.\nThis object contains all the details of the server’s response, including status code, headers, and content.\nYou can then use other httr2 functions to extract or interpret information from this response.\nLet’s say you want to retrieve COVID-19 deaths by state from the CDC."
  },
  {
    "objectID": "slides/wrangling/14-data-apis.html#the-httr2-package-2",
    "href": "slides/wrangling/14-data-apis.html#the-httr2-package-2",
    "title": "Data APIs",
    "section": "The httr2 package",
    "text": "The httr2 package\n\nBy visiting their data catalog https://data.cdc.gov you can search for datasets and find that the data is provided through this API:\n\n\nurl &lt;- \"https://data.cdc.gov/resource/muzy-jte6.csv\" \n\n\nWe can then make create and perform a request like this:\n\n\nlibrary(httr2) \nresponse &lt;- request(url) |&gt; req_perform()"
  },
  {
    "objectID": "slides/wrangling/14-data-apis.html#the-httr2-package-3",
    "href": "slides/wrangling/14-data-apis.html#the-httr2-package-3",
    "title": "Data APIs",
    "section": "The httr2 package",
    "text": "The httr2 package\n\nWe can see the results of the request by looking at the returned object.\n\n\nresponse\n\n&lt;httr2_response&gt;\n\n\nGET https://data.cdc.gov/resource/muzy-jte6.csv\n\n\nStatus: 200 OK\n\n\nContent-Type: text/csv\n\n\nBody: In memory (210808 bytes)"
  },
  {
    "objectID": "slides/wrangling/14-data-apis.html#the-httr2-package-4",
    "href": "slides/wrangling/14-data-apis.html#the-httr2-package-4",
    "title": "Data APIs",
    "section": "The httr2 package",
    "text": "The httr2 package\n\nTo extract the body, which is where the data are, we can use resp_body_string and send the result, a comma delimited string, to read_csv.\n\n\nlibrary(readr) \ntab &lt;- response |&gt; resp_body_string() |&gt; read_csv() \n\n\nWe note that the returned object is only 1000 entries.\nAPI often limit how much you can download."
  },
  {
    "objectID": "slides/wrangling/14-data-apis.html#the-httr2-package-5",
    "href": "slides/wrangling/14-data-apis.html#the-httr2-package-5",
    "title": "Data APIs",
    "section": "The httr2 package",
    "text": "The httr2 package\n\nThe documentation for this API explains that we can change this limit through the.\n$limit parameters.\nWe can use the req_url_path_append to add this to our request:\n\n\nresponse &lt;- request(url) |&gt;  \n  req_url_path_append(\"?$limit=100000\") |&gt;  \n  req_perform()  \n\n\nThe CDC service returns data in csv format but a more common format used by web services is JSON."
  },
  {
    "objectID": "slides/wrangling/14-data-apis.html#the-httr2-package-6",
    "href": "slides/wrangling/14-data-apis.html#the-httr2-package-6",
    "title": "Data APIs",
    "section": "The httr2 package",
    "text": "The httr2 package\n\nThe CDC also provides data in json format through:\n\n\nurl &lt;- \"https://data.cdc.gov/resource/muzy-jte6.json\" \n\n\nTo extract the data table we use the fromJSON function from the jsonlite package.\n\n\ntab &lt;- request(url) |&gt;  \n   req_perform() |&gt;  \n   resp_body_json(simplifyDataFrame = TRUE) \n\n\nWhen working with APIs, it’s essential to check the API’s documentation for rate limits, required headers, or authentication methods."
  },
  {
    "objectID": "slides/wrangling/14-data-apis.html#the-httr2-package-7",
    "href": "slides/wrangling/14-data-apis.html#the-httr2-package-7",
    "title": "Data APIs",
    "section": "The httr2 package",
    "text": "The httr2 package\n\nThe httr2 package provides tools to handle these requirements, such as setting headers or authentication parameters."
  },
  {
    "objectID": "slides/wrangling/11-importing-files.html#importing-data",
    "href": "slides/wrangling/11-importing-files.html#importing-data",
    "title": "Importing files",
    "section": "Importing data",
    "text": "Importing data\n\nOne of the most common ways of storing and sharing data is through electronic spreadsheets.\nA spreadsheet is a file version of a data frame.\nBut there are many ways to store spreadsheets in files."
  },
  {
    "objectID": "slides/wrangling/11-importing-files.html#importing-data-1",
    "href": "slides/wrangling/11-importing-files.html#importing-data-1",
    "title": "Importing files",
    "section": "Importing data",
    "text": "Importing data\nTo import data we need to:\n\nIdentify the file’s location.\nKnow what function or parsers to use.\n\nFor the second step it helps to know the file type and encoding."
  },
  {
    "objectID": "slides/wrangling/11-importing-files.html#file-types",
    "href": "slides/wrangling/11-importing-files.html#file-types",
    "title": "Importing files",
    "section": "File types",
    "text": "File types\n\nFiles can generally be classified into two categories: text and binary.\nWe describe the most widely used format for storing data for both these types and learn how to identify them."
  },
  {
    "objectID": "slides/wrangling/11-importing-files.html#text-files",
    "href": "slides/wrangling/11-importing-files.html#text-files",
    "title": "Importing files",
    "section": "Text files",
    "text": "Text files\n\nYou have already worked with text files: R scripts and Quarto files, for example.\ndslabs offers examples:\n\n\ndir &lt;- system.file(package = \"dslabs\") \nfile_path &lt;- file.path(dir, \"extdata/murders.csv\") \nfile.copy(file_path, \"murders.csv\") \n\n[1] TRUE"
  },
  {
    "objectID": "slides/wrangling/11-importing-files.html#text-files-1",
    "href": "slides/wrangling/11-importing-files.html#text-files-1",
    "title": "Importing files",
    "section": "Text files",
    "text": "Text files\n\nAn advantage of text files is that we can easily “look” at them without having to purchase any kind of special software or follow complicated instructions.\nExercise:\n\ncopy murders.csv into your working directory and examine it with less.\nThen try the Open file RStudio tool."
  },
  {
    "objectID": "slides/wrangling/11-importing-files.html#text-files-2",
    "href": "slides/wrangling/11-importing-files.html#text-files-2",
    "title": "Importing files",
    "section": "Text files",
    "text": "Text files\n\nLine breaks are used to separate rows and a delimiter to separate columns within a row.\nThe most common delimiters are comma (,), semicolon (;), space (), and tab (\\t).\nDifferent parsers are used to read these files, so we need to know what delimiter was used.\nIn some cases, the delimiter can be inferred from file suffix: csv, tsv, for example.\nBut we recommend looking at the file rather than inferring from the suffix."
  },
  {
    "objectID": "slides/wrangling/11-importing-files.html#text-files-3",
    "href": "slides/wrangling/11-importing-files.html#text-files-3",
    "title": "Importing files",
    "section": "Text files",
    "text": "Text files\n\nIn R, you can look at any number of lines from within R using the readLines function:\n\n\nreadLines(\"murders.csv\", n = 3) \n\n[1] \"state,abb,region,population,total\" \"Alabama,AL,South,4779736,135\"     \n[3] \"Alaska,AK,West,710231,19\""
  },
  {
    "objectID": "slides/wrangling/11-importing-files.html#binary-files",
    "href": "slides/wrangling/11-importing-files.html#binary-files",
    "title": "Importing files",
    "section": "Binary files",
    "text": "Binary files\n\nOpening image files such as jpg or png in a text editor or using readLines in R will not show comprehensible content: these are binary files.\nUnlike text files, which are designed for human readability and have standardized conventions, binary files have many formats specific to their data type.\nWhile R’s readBin function can process any binary file, interpreting the output necessitates a thorough understanding of the file’s structure.\nWe focus on the the most prevalent binary formats for spreadsheets: Microsoft Excel xls and xlsx."
  },
  {
    "objectID": "slides/wrangling/11-importing-files.html#r-base-parsers",
    "href": "slides/wrangling/11-importing-files.html#r-base-parsers",
    "title": "Importing files",
    "section": "R Base Parsers",
    "text": "R Base Parsers\nHere example of useful R base parsers:\n\nx &lt;- read.table(\"murders.csv\", sep = \"\\t\")\nx &lt;- read.csv(\"murders.csv\")"
  },
  {
    "objectID": "slides/wrangling/11-importing-files.html#readr-parsers",
    "href": "slides/wrangling/11-importing-files.html#readr-parsers",
    "title": "Importing files",
    "section": "readr Parsers",
    "text": "readr Parsers\nreadr provides alternatives that produce tibbles:\n\nlibrary(readr)\nx &lt;- read_csv(\"murders.csv\")\nx &lt;- read_delim(\"murders.csv\", delim = \"\\t\")\n\nNotice the messages produced."
  },
  {
    "objectID": "slides/wrangling/11-importing-files.html#readr-parsers-1",
    "href": "slides/wrangling/11-importing-files.html#readr-parsers-1",
    "title": "Importing files",
    "section": "readr Parsers",
    "text": "readr Parsers\n\n\n\n\n\n\n\n\nFunction\nFormat\nSuffix\n\n\n\n\nread_table\nwhite space separated values\ntxt\n\n\nread_csv\ncomma separated values\ncsv\n\n\nread_csv2\nsemicolon separated values\ncsv\n\n\nread_tsv\ntab separated values\ntsv\n\n\nread_delim\nmust define delimiter\ntxt\n\n\nread_lines\nsimilar to readLines\nany file"
  },
  {
    "objectID": "slides/wrangling/11-importing-files.html#readxl-parsers",
    "href": "slides/wrangling/11-importing-files.html#readxl-parsers",
    "title": "Importing files",
    "section": "readxl Parsers",
    "text": "readxl Parsers\nFor Excel files you can use the readxl package.\n\nlibrary(readxl)\nfn &lt;- file.path(dir, \"extdata/2010_bigfive_regents.xls\") \ny &lt;- read_xls(fn)"
  },
  {
    "objectID": "slides/wrangling/11-importing-files.html#readxl-parsers-1",
    "href": "slides/wrangling/11-importing-files.html#readxl-parsers-1",
    "title": "Importing files",
    "section": "readxl Parsers",
    "text": "readxl Parsers\nYou can read specific sheets and see them using\n\nexcel_sheets(fn)\n\n[1] \"Sheet1\" \"Sheet2\" \"Sheet3\"\n\n\nNote that read_xls has a sheet argument."
  },
  {
    "objectID": "slides/wrangling/11-importing-files.html#readxl-parsers-2",
    "href": "slides/wrangling/11-importing-files.html#readxl-parsers-2",
    "title": "Importing files",
    "section": "readxl Parsers",
    "text": "readxl Parsers\n\n\n\n\n\n\n\n\nFunction\nFormat\nSuffix\n\n\n\n\nread_excel\nauto detect the format\nxls, xlsx\n\n\nread_xls\noriginal format\nxls\n\n\nread_xlsx\nnew format\nxlsx\n\n\nexcel_sheets\ndetects sheets\nxls, xlsx"
  },
  {
    "objectID": "slides/wrangling/11-importing-files.html#data.table-parsers",
    "href": "slides/wrangling/11-importing-files.html#data.table-parsers",
    "title": "Importing files",
    "section": "data.table Parsers",
    "text": "data.table Parsers\nThe data.table package provide a very fast parser:\n\nlibrary(data.table)\nx &lt;- fread(\"murders.csv\")\n\nNote: It returns a file in data.table format which we have mentioned but not explained."
  },
  {
    "objectID": "slides/wrangling/11-importing-files.html#scan",
    "href": "slides/wrangling/11-importing-files.html#scan",
    "title": "Importing files",
    "section": "scan",
    "text": "scan\n\nThe scan function is the most general parser.\nIt will read in any text file and return a vector so you are on your own coverting it to a data frame.\nBecause it returns a vector, you need to tell it in advance what data type to expect:\n\n\nscan(\"murders.csv\", what = \"c\", sep = \",\", n = 10)\n\n [1] \"state\"      \"abb\"        \"region\"     \"population\" \"total\"     \n [6] \"Alabama\"    \"AL\"         \"South\"      \"4779736\"    \"135\"       \n\n\n\nIt can also be used to read from the console. Try typing scan(). Hit return to stop."
  },
  {
    "objectID": "slides/wrangling/11-importing-files.html#encoding",
    "href": "slides/wrangling/11-importing-files.html#encoding",
    "title": "Importing files",
    "section": "Encoding",
    "text": "Encoding\n\nComputer translates everything into 0s and 1s.\nASCII is an encoding system that assigns specific numbers to characters.\nUsing 7 bits, ASCII can represent \\(2^7 = 128\\) unique symbols, sufficient for all English keyboard characters.\nHowever, many global languages contain characters outside ASCII’s range."
  },
  {
    "objectID": "slides/wrangling/11-importing-files.html#encoding-1",
    "href": "slides/wrangling/11-importing-files.html#encoding-1",
    "title": "Importing files",
    "section": "Encoding",
    "text": "Encoding\n\nFor instance, the é in “México” isn’t in ASCII’s catalog.\nTo address this, broader encodings emerged.\nUnicode offers variations using 8, 16, or 32 bits, known as UTF-8, UTF-16, and UTF-32.\nRStudio typically uses UTF-8 as its default.\nNotably, ASCII is a subset of UTF-8, meaning that if a file is ASCII-encoded, presuming it’s UTF-8 encoded won’t cause issues."
  },
  {
    "objectID": "slides/wrangling/11-importing-files.html#encoding-2",
    "href": "slides/wrangling/11-importing-files.html#encoding-2",
    "title": "Importing files",
    "section": "Encoding",
    "text": "Encoding\n\nHowever, there other encodings, such as ISO-8859-1 (also known as Latin-1) developed for the western European languages, Big5 for Traditional Chinese, and ISO-8859-6 for Arabic.\nTake a look at this file:\n\n\nfn &lt;- \"calificaciones.csv\" \nfile.copy(file.path(system.file(\"extdata\", package = \"dslabs\"), fn), fn) \n\n[1] TRUE\n\nreadLines(fn, n = 1) \n\n[1] \"\\\"nombre\\\",\\\"f.n.\\\",\\\"estampa\\\",\\\"puntuaci\\xf3n\\\"\""
  },
  {
    "objectID": "slides/wrangling/11-importing-files.html#encoding-3",
    "href": "slides/wrangling/11-importing-files.html#encoding-3",
    "title": "Importing files",
    "section": "Encoding",
    "text": "Encoding\n\nThe readr parsers permit us to specify an encoding.\nIt also includes a function that tries to guess the encoding:\n\n\nguess_encoding(\"murders.csv\") \n\n# A tibble: 1 × 2\n  encoding confidence\n  &lt;chr&gt;         &lt;dbl&gt;\n1 ASCII             1\n\nguess_encoding(\"calificaciones.csv\") \n\n# A tibble: 3 × 2\n  encoding   confidence\n  &lt;chr&gt;           &lt;dbl&gt;\n1 ISO-8859-1       0.92\n2 ISO-8859-2       0.72\n3 ISO-8859-9       0.53"
  },
  {
    "objectID": "slides/wrangling/11-importing-files.html#encoding-4",
    "href": "slides/wrangling/11-importing-files.html#encoding-4",
    "title": "Importing files",
    "section": "Encoding",
    "text": "Encoding\n\nOnce we know the encoding we can specify it through the locale argument:\n\n\ndat &lt;- read_csv(\"calificaciones.csv\", show_col_types = FALSE, \n                locale = locale(encoding = \"ISO-8859-1\")) \n\n\nWe learn about locales in later."
  },
  {
    "objectID": "slides/wrangling/11-importing-files.html#encoding-5",
    "href": "slides/wrangling/11-importing-files.html#encoding-5",
    "title": "Importing files",
    "section": "Encoding",
    "text": "Encoding\n\nWe can now see that the characters in the header were read in correctly:\n\n\ndat\n\n# A tibble: 7 × 4\n  nombre   f.n.                     estampa             puntuación\n  &lt;chr&gt;    &lt;chr&gt;                    &lt;dttm&gt;                   &lt;dbl&gt;\n1 Beyoncé  04 de septiembre de 1981 2023-09-22 02:11:02        875\n2 Blümchen 20 de abril de 1980      2023-09-22 03:23:05        990\n3 João     10 de junio de 1931      2023-09-21 22:43:28        989\n4 López    24 de julio de 1969      2023-09-22 01:06:59        887\n5 Ñengo    15 de diciembre de 1981  2023-09-21 23:35:37        931\n6 Plácido  24 de enero de 1941      2023-09-21 23:17:21        887\n7 Thalía   26 de agosto de 1971     2023-09-21 23:08:02        830"
  },
  {
    "objectID": "slides/wrangling/11-importing-files.html#downloading-files",
    "href": "slides/wrangling/11-importing-files.html#downloading-files",
    "title": "Importing files",
    "section": "Downloading files",
    "text": "Downloading files\n\nA common place for data to reside is on the internet.\nWe can download these files and then import them.\nWe can also read them directly from the web.\n\n\nurl &lt;- paste0(\"https://raw.githubusercontent.com/\", \n              \"rafalab/dslabs/master/inst/extdata/murders.csv\") \nx &lt;- read.csv(url)"
  },
  {
    "objectID": "slides/wrangling/11-importing-files.html#downloading-files-1",
    "href": "slides/wrangling/11-importing-files.html#downloading-files-1",
    "title": "Importing files",
    "section": "Downloading files",
    "text": "Downloading files\n\nIf you want a local copy, you can use `download.file:\n\n\ndownload.file(url, \"murders.csv\") \n\n\nThis will download the file and save it on your system with the name murders.csv.\nNote You can use any name here, not necessarily murders.csv."
  },
  {
    "objectID": "slides/wrangling/11-importing-files.html#downloading-files-2",
    "href": "slides/wrangling/11-importing-files.html#downloading-files-2",
    "title": "Importing files",
    "section": "Downloading files",
    "text": "Downloading files\n\n\n\n\n\n\nWarning\n\n\nThe function download.file overwrites existing files without warning.\n\n\n\n\nTwo functions that are sometimes useful when downloading data from the internet are tempdir and tempfile.\n\n\ntmp_filename &lt;- tempfile() \ndownload.file(url, tmp_filename) \ndat &lt;- read_csv(tmp_filename) \nfile.remove(tmp_filename)"
  },
  {
    "objectID": "slides/inference/24-confidence-intervals.html#confidence-intervals",
    "href": "slides/inference/24-confidence-intervals.html#confidence-intervals",
    "title": "Confidence Intervals",
    "section": "Confidence intervals",
    "text": "Confidence intervals\n\nConfidence intervals are a very useful concept widely employed by data analysts.\nA version of these that are commonly seen come from the ggplot geometry geom_smooth.\nBelow is an example using a temperature dataset available in R:"
  },
  {
    "objectID": "slides/inference/24-confidence-intervals.html#confidence-intervals-1",
    "href": "slides/inference/24-confidence-intervals.html#confidence-intervals-1",
    "title": "Confidence Intervals",
    "section": "Confidence intervals",
    "text": "Confidence intervals"
  },
  {
    "objectID": "slides/inference/24-confidence-intervals.html#confidence-intervals-2",
    "href": "slides/inference/24-confidence-intervals.html#confidence-intervals-2",
    "title": "Confidence Intervals",
    "section": "Confidence intervals",
    "text": "Confidence intervals\n\nIn our competition, you were asked to give an interval.\nIf the interval you submitted includes the \\(p\\), you receive half the money you spent on your “poll” back and proceed to the next stage of the competition."
  },
  {
    "objectID": "slides/inference/24-confidence-intervals.html#confidence-intervals-3",
    "href": "slides/inference/24-confidence-intervals.html#confidence-intervals-3",
    "title": "Confidence Intervals",
    "section": "Confidence intervals",
    "text": "Confidence intervals\n\nOne way to pass to the second round is to report a very large interval.\nFor example, the interval \\([0,1]\\) is guaranteed to include \\(p\\).\nHowever, with an interval this big, we have no chance of winning the competition."
  },
  {
    "objectID": "slides/inference/24-confidence-intervals.html#confidence-intervals-4",
    "href": "slides/inference/24-confidence-intervals.html#confidence-intervals-4",
    "title": "Confidence Intervals",
    "section": "Confidence intervals",
    "text": "Confidence intervals\n\nSimilarly, if you are an election forecaster and predict the spread will be between -100% and 100%, you will be ridiculed for stating the obvious.\nEven a smaller interval, such as saying the spread will be between -10 and 10%, will not be considered serious."
  },
  {
    "objectID": "slides/inference/24-confidence-intervals.html#confidence-intervals-5",
    "href": "slides/inference/24-confidence-intervals.html#confidence-intervals-5",
    "title": "Confidence Intervals",
    "section": "Confidence intervals",
    "text": "Confidence intervals\n\nOn the other hand, the smaller the interval we report, the smaller our chances are of winning the prize.\nLikewise, a bold pollster that reports very small intervals and misses the mark most of the time will not be considered a good pollster.\nWe might want to be somewhere in between.\nWe can use the statistical theory we have learned to compute the probability of any given interval including \\(p\\)."
  },
  {
    "objectID": "slides/inference/24-confidence-intervals.html#confidence-intervals-6",
    "href": "slides/inference/24-confidence-intervals.html#confidence-intervals-6",
    "title": "Confidence Intervals",
    "section": "Confidence intervals",
    "text": "Confidence intervals\n\nTo illustrate this we run the Monte Carlo simulation.\nWe use the same parameters as above:\n\n\np &lt;- 0.45 \nN &lt;- 1000"
  },
  {
    "objectID": "slides/inference/24-confidence-intervals.html#confidence-intervals-7",
    "href": "slides/inference/24-confidence-intervals.html#confidence-intervals-7",
    "title": "Confidence Intervals",
    "section": "Confidence intervals",
    "text": "Confidence intervals\n\nAnd notice that the interval here:\n\n\nx &lt;- sample(c(0, 1), size = N, replace = TRUE, prob = c(1 - p, p)) \nx_hat &lt;- mean(x) \nse_hat &lt;- sqrt(x_hat*(1 - x_hat)/N) \nc(x_hat - 1.96*se_hat, x_hat + 1.96*se_hat) \n\n[1] 0.4082412 0.4697588\n\n\n\nis different from this one:\n\n\nx &lt;- sample(c(0,1), size = N, replace = TRUE, prob = c(1 - p, p)) \nx_hat &lt;- mean(x) \nse_hat &lt;- sqrt(x_hat*(1 - x_hat)/N) \nc(x_hat - 1.96*se_hat, x_hat + 1.96*se_hat) \n\n[1] 0.4151909 0.4768091\n\n\n\nKeep sampling and creating intervals, and you will see the random variation."
  },
  {
    "objectID": "slides/inference/24-confidence-intervals.html#confidence-intervals-8",
    "href": "slides/inference/24-confidence-intervals.html#confidence-intervals-8",
    "title": "Confidence Intervals",
    "section": "Confidence intervals",
    "text": "Confidence intervals\n\nTo determine the probability that the interval includes \\(p\\), we need to compute the following:\n\n\\[\n\\mbox{Pr}\\left(\\bar{X} - 1.96\\hat{\\mbox{SE}}(\\bar{X}) \\leq p \\leq \\bar{X} + 1.96\\hat{\\mbox{SE}}(\\bar{X})\\right)\n\\]"
  },
  {
    "objectID": "slides/inference/24-confidence-intervals.html#confidence-intervals-9",
    "href": "slides/inference/24-confidence-intervals.html#confidence-intervals-9",
    "title": "Confidence Intervals",
    "section": "Confidence intervals",
    "text": "Confidence intervals\n\nBy subtracting and dividing the same quantities in all parts of the equation, we find that the above is equivalent to:\n\n\\[\n\\mbox{Pr}\\left(-1.96 \\leq \\frac{\\bar{X}- p}{\\hat{\\mbox{SE}}(\\bar{X})} \\leq  1.96\\right)\n\\]"
  },
  {
    "objectID": "slides/inference/24-confidence-intervals.html#confidence-intervals-10",
    "href": "slides/inference/24-confidence-intervals.html#confidence-intervals-10",
    "title": "Confidence Intervals",
    "section": "Confidence intervals",
    "text": "Confidence intervals\n\nThe term in the middle is an approximately normal random variable with expected value 0 and standard error 1, which we have been denoting with \\(Z\\), so we have:\n\n\\[\n\\mbox{Pr}\\left(-1.96 \\leq Z \\leq  1.96\\right)\n\\]\n\nwhich we can quickly compute using :\n\n\npnorm(1.96) - pnorm(-1.96) \n\n[1] 0.9500042\n\n\n\nproving that we have a 95% probability."
  },
  {
    "objectID": "slides/inference/24-confidence-intervals.html#confidence-intervals-11",
    "href": "slides/inference/24-confidence-intervals.html#confidence-intervals-11",
    "title": "Confidence Intervals",
    "section": "Confidence intervals",
    "text": "Confidence intervals\n\nIf we want to have a larger probability, say 99%, we need to multiply by whatever z satisfies the following:\n\n\\[\n\\mbox{Pr}\\left(-z \\leq Z \\leq  z\\right) = 0.99\n\\]\n\nWe use:\n\n\nz &lt;- qnorm(0.995) \nz \n\n[1] 2.575829\n\npnorm(z) - pnorm(-z) \n\n[1] 0.99"
  },
  {
    "objectID": "slides/inference/24-confidence-intervals.html#confidence-intervals-12",
    "href": "slides/inference/24-confidence-intervals.html#confidence-intervals-12",
    "title": "Confidence Intervals",
    "section": "Confidence intervals",
    "text": "Confidence intervals\n\nIn statistics textbooks, confidence interval formulas are given for arbitraty probabilities written as \\(1-\\alpha\\).\nWe can obtain the \\(z\\) for the equation above using z = qnorm(1 - alpha / 2) because \\(1 - \\alpha/2 - \\alpha/2 = 1 - \\alpha\\).\nSo, for example, for \\(\\alpha=0.05\\), \\(1 - \\alpha/2 = 0.975\\) and we get the \\(z=1.96\\) we used above:\n\n\nqnorm(0.975) \n\n[1] 1.959964"
  },
  {
    "objectID": "slides/inference/24-confidence-intervals.html#a-monte-carlo-simulation",
    "href": "slides/inference/24-confidence-intervals.html#a-monte-carlo-simulation",
    "title": "Confidence Intervals",
    "section": "A Monte Carlo simulation",
    "text": "A Monte Carlo simulation\n\nWe can run a Monte Carlo simulation to confirm that, in fact, a 95% confidence interval includes \\(p\\) 95% of the time.\n\n\nN &lt;- 1000 \nB &lt;- 10000 \ninside &lt;- replicate(B, { \n  x &lt;- sample(c(0,1), size = N, replace = TRUE, prob = c(1 - p, p)) \n  x_hat &lt;- mean(x) \n  se_hat &lt;- sqrt(x_hat*(1 - x_hat)/N) \n  between(p, x_hat - 1.96*se_hat, x_hat + 1.96*se_hat) \n}) \nmean(inside) \n\n[1] 0.9511"
  },
  {
    "objectID": "slides/inference/24-confidence-intervals.html#a-monte-carlo-simulation-1",
    "href": "slides/inference/24-confidence-intervals.html#a-monte-carlo-simulation-1",
    "title": "Confidence Intervals",
    "section": "A Monte Carlo simulation",
    "text": "A Monte Carlo simulation\n\nThe following plot shows the first 100 confidence intervals."
  },
  {
    "objectID": "slides/inference/22-intro-inference.html#statistical-inference",
    "href": "slides/inference/22-intro-inference.html#statistical-inference",
    "title": "Introduction to Statistical Inference and Models",
    "section": "Statistical inference",
    "text": "Statistical inference\n\nStatistical Inference is the branch of statistics dedicated to distinguishing patterns arising from signal versus those arising from chance.\nIt is a broad topic and we review the basics using polls as a motivating example.\nWe motivate the concepts with election forecasting as a case study."
  },
  {
    "objectID": "slides/inference/22-intro-inference.html#statistical-inference-1",
    "href": "slides/inference/22-intro-inference.html#statistical-inference-1",
    "title": "Introduction to Statistical Inference and Models",
    "section": "Statistical inference",
    "text": "Statistical inference\n\nThe day before the 2008 presidential election, Nate Silver’s FiveThirtyEight stated that “Barack Obama appears poised for a decisive electoral victory”.\nThey went further and predicted that Obama would win the election with 349 electoral votes to 189, and the popular vote by a margin of 6.1%.\nFiveThirtyEight also attached a probabilistic statement to their prediction claiming that Obama had a 91% chance of winning the election."
  },
  {
    "objectID": "slides/inference/22-intro-inference.html#statistical-inference-2",
    "href": "slides/inference/22-intro-inference.html#statistical-inference-2",
    "title": "Introduction to Statistical Inference and Models",
    "section": "Statistical inference",
    "text": "Statistical inference\n\nThe predictions were quite accurate since, in the final results, Obama won the electoral college 365 to 173 and the popular vote by a 7.2% difference.\nTheir performance in the 2008 election brought FiveThirtyEight to the attention of political pundits and TV personalities.\nFour years later, the week before the 2012 presidential election, FiveThirtyEight’s Nate Silver was giving Obama a 90% chance of winning despite many of the experts thinking the final results would be closer."
  },
  {
    "objectID": "slides/inference/22-intro-inference.html#statistical-inference-3",
    "href": "slides/inference/22-intro-inference.html#statistical-inference-3",
    "title": "Introduction to Statistical Inference and Models",
    "section": "Statistical inference",
    "text": "Statistical inference\n\nPolitical commentator Joe Scarborough said during his show\n\n\n\nAnybody that thinks that this race is anything but a toss-up right now is such an ideologue they’re jokes."
  },
  {
    "objectID": "slides/inference/22-intro-inference.html#statistical-inference-4",
    "href": "slides/inference/22-intro-inference.html#statistical-inference-4",
    "title": "Introduction to Statistical Inference and Models",
    "section": "Statistical inference",
    "text": "Statistical inference\n\nTo which Nate Silver responded via Twitter:\n\n\n\nIf you think it’s a toss-up, let’s bet. If Obama wins, you donate $1,000 to the American Red Cross. If Romney wins, I do. Deal?"
  },
  {
    "objectID": "slides/inference/22-intro-inference.html#statistical-inference-5",
    "href": "slides/inference/22-intro-inference.html#statistical-inference-5",
    "title": "Introduction to Statistical Inference and Models",
    "section": "Statistical inference",
    "text": "Statistical inference\n\nIn 2016, Silver was not as certain and gave Hillary Clinton only a 71% of winning.\nIn contrast, many other forecasters were almost certain she would win.\nShe lost."
  },
  {
    "objectID": "slides/inference/22-intro-inference.html#statistical-inference-6",
    "href": "slides/inference/22-intro-inference.html#statistical-inference-6",
    "title": "Introduction to Statistical Inference and Models",
    "section": "Statistical inference",
    "text": "Statistical inference\n\nBut 71% is still more than 50%, so was Mr. Silver wrong?\nWhat does probability mean in this context anyway?\nWe will demonstrate how the probability concepts covered in the previous part can be applied to develop statistical approaches that render polls effective tools."
  },
  {
    "objectID": "slides/inference/22-intro-inference.html#statistical-inference-7",
    "href": "slides/inference/22-intro-inference.html#statistical-inference-7",
    "title": "Introduction to Statistical Inference and Models",
    "section": "Statistical inference",
    "text": "Statistical inference\n\nForecasting an election is a more complex process that involves combining results from 50 states and DC.\nWe will learn the statistical concepts necessary to define estimates and margins of errors for the popular vote, and show how these are used to construct confidence intervals.\nOnce we grasp these ideas, we will be able to understand statistical power and p-values, concepts that are ubiquitous in the academic literature."
  },
  {
    "objectID": "slides/inference/22-intro-inference.html#statistical-inference-8",
    "href": "slides/inference/22-intro-inference.html#statistical-inference-8",
    "title": "Introduction to Statistical Inference and Models",
    "section": "Statistical inference",
    "text": "Statistical inference\n\nWe will then aggregate data from different pollsters to highlight the shortcomings of the models used by traditional pollsters and present a method for improving these models.\nTo understand probabilistic statements about the chances of a candidate winning, we will introduce Bayesian modeling.\nFinally, we put it all together using hierarchical models to recreate the simplified version of the FiveThirtyEight model and apply it to the 2016 election."
  },
  {
    "objectID": "slides/productivity/02-rstudio.html#the-panes",
    "href": "slides/productivity/02-rstudio.html#the-panes",
    "title": "RStudio",
    "section": "The panes",
    "text": "The panes"
  },
  {
    "objectID": "slides/productivity/02-rstudio.html#the-basics",
    "href": "slides/productivity/02-rstudio.html#the-basics",
    "title": "RStudio",
    "section": "The Basics",
    "text": "The Basics\nLet’s try a few things together:\n\nOpen a new R script file.\nLearn tab complete.\nRun commands while editing scripts.\nRun the entire script.\nMake a plot.\nChange options to never save workspace.\nChange IDE appearance."
  },
  {
    "objectID": "slides/productivity/02-rstudio.html#projects",
    "href": "slides/productivity/02-rstudio.html#projects",
    "title": "RStudio",
    "section": "Projects",
    "text": "Projects\nLet’s try this together:\n\nStart new project in new directory.\nStart new project in existing directory.\nChange projects."
  },
  {
    "objectID": "slides/productivity/02-rstudio.html#type-of-editor",
    "href": "slides/productivity/02-rstudio.html#type-of-editor",
    "title": "RStudio",
    "section": "Type of editor",
    "text": "Type of editor\nLet’s examine the two types of editors available:\n\nSource - See the actual code (WYSIWYG)\nVisual - Partial preview of final document.\n\nNote: You can state your preference in a the header:\neditor: source\n\nWe learn about headers in the Quarto lecture."
  },
  {
    "objectID": "slides/productivity/04-git.html#goal-for-the-day",
    "href": "slides/productivity/04-git.html#goal-for-the-day",
    "title": "Git and GitHub",
    "section": "Goal for the day",
    "text": "Goal for the day\n\nCreate a repository\npush something to the repository\nconnect RStudio to GitHub"
  },
  {
    "objectID": "slides/productivity/04-git.html#do-you-have-git",
    "href": "slides/productivity/04-git.html#do-you-have-git",
    "title": "Git and GitHub",
    "section": "Do you have git?",
    "text": "Do you have git?\nBefore we start:\n\nMake sure you have Git installed.\nOpen a terminal and type:\n\n\ngit --version\n\nIf not installed\n\non a Mac, follow the instructions after typing the above.\non Windows follow these instructions"
  },
  {
    "objectID": "slides/productivity/04-git.html#motivation",
    "href": "slides/productivity/04-git.html#motivation",
    "title": "Git and GitHub",
    "section": "Motivation",
    "text": "Motivation\nWe want to avoid this:\n\nPosted by rjkb041 on r/ProgrammerHumor"
  },
  {
    "objectID": "slides/productivity/04-git.html#motivation-1",
    "href": "slides/productivity/04-git.html#motivation-1",
    "title": "Git and GitHub",
    "section": "Motivation",
    "text": "Motivation\n\nThis is particularly true when more than one person is collaborating and editing the file.\nEven more important when there are multiple files, as there is in software development, and to some extend data analysis."
  },
  {
    "objectID": "slides/productivity/04-git.html#motivation-2",
    "href": "slides/productivity/04-git.html#motivation-2",
    "title": "Git and GitHub",
    "section": "Motivation",
    "text": "Motivation\n\nGit is a version control system that provides a systematic approach to keeping versions of files.\n\n\nPosted on devrant.com/ by bhimanshukalra"
  },
  {
    "objectID": "slides/productivity/04-git.html#motivation-3",
    "href": "slides/productivity/04-git.html#motivation-3",
    "title": "Git and GitHub",
    "section": "Motivation",
    "text": "Motivation\nBut we have to learn some things.\n\nFrom Meme Git Compilation by Lulu Ilmaknun Qurotaini"
  },
  {
    "objectID": "slides/productivity/04-git.html#why-use-git-and-github",
    "href": "slides/productivity/04-git.html#why-use-git-and-github",
    "title": "Git and GitHub",
    "section": "Why use Git and GitHub?",
    "text": "Why use Git and GitHub?\n\nSharing.\nCollaborating.\nVersion control.\n\nWe focus on the sharing aspects of Git and GitHub, but introduce some of the basics that permit you to collaborate and use version control."
  },
  {
    "objectID": "slides/productivity/04-git.html#what-is-git",
    "href": "slides/productivity/04-git.html#what-is-git",
    "title": "Git and GitHub",
    "section": "What is Git?",
    "text": "What is Git?"
  },
  {
    "objectID": "slides/productivity/04-git.html#what-is-github",
    "href": "slides/productivity/04-git.html#what-is-github",
    "title": "Git and GitHub",
    "section": "What is GitHub?",
    "text": "What is GitHub?\n\nDescribed a social network for software developers.\nBasically, it’s a service that hosts the remote repository (repo) on the web.\nThis facilitates collaboration and sharing greatly."
  },
  {
    "objectID": "slides/productivity/04-git.html#what-is-github-1",
    "href": "slides/productivity/04-git.html#what-is-github-1",
    "title": "Git and GitHub",
    "section": "What is GitHub?",
    "text": "What is GitHub?\nThere many other features such as\n\nRecognition system: reward, badges and stars.\nYou can host web pages, like the class notes for example.\nPermits contributions via forks and pull requests.\nIssue tracking\nAutomation tools."
  },
  {
    "objectID": "slides/productivity/04-git.html#what-is-github-2",
    "href": "slides/productivity/04-git.html#what-is-github-2",
    "title": "Git and GitHub",
    "section": "What is GitHub?",
    "text": "What is GitHub?\n\nThe main tool behind GitHub is Git.\nSimilar to how the main tool behind RStudio is R."
  },
  {
    "objectID": "slides/productivity/04-git.html#github-accounts",
    "href": "slides/productivity/04-git.html#github-accounts",
    "title": "Git and GitHub",
    "section": "GitHub accounts",
    "text": "GitHub accounts\n\nPick a professional sounding name.\nConsider adding a profile README.md.\nInstructions are here.\nExample here."
  },
  {
    "objectID": "slides/productivity/04-git.html#repositories",
    "href": "slides/productivity/04-git.html#repositories",
    "title": "Git and GitHub",
    "section": "Repositories",
    "text": "Repositories\n\nWe are ready to create a GitHub repository (repo).\nYou will have at least two copies of your code: one on your computer and one on GitHub.\nIf you add collaborators to this repo, then each will have a copy on their computer.\nThe GitHub copy is considered the main (previously called master) copy that everybody syncs to.\nGit will help you keep all the different copies synced."
  },
  {
    "objectID": "slides/productivity/04-git.html#repositories-1",
    "href": "slides/productivity/04-git.html#repositories-1",
    "title": "Git and GitHub",
    "section": "Repositories",
    "text": "Repositories\n\nLet’s go make one on GitHub…\nThen create a directory on your computer, this will be the local repo, and connect it to the Github repository.\nFirst copy and paste the location of your git repository. It should look something like this:\n\nhttps://github.com/your-username/your-repo-name.git"
  },
  {
    "objectID": "slides/productivity/04-git.html#connect-git-and-github",
    "href": "slides/productivity/04-git.html#connect-git-and-github",
    "title": "Git and GitHub",
    "section": "Connect Git and GitHub",
    "text": "Connect Git and GitHub\n\nWhen accessing GitHub you need credentials to verify your identity.\nThere are two ways to connect: HTTPS or SSH, each requiring different credentials.\nWe recommend using HTTPS, which uses a Personal Access Token (PAT).\nNote that your GitHub website password isn’t your access token."
  },
  {
    "objectID": "slides/productivity/04-git.html#connect-git-and-github-1",
    "href": "slides/productivity/04-git.html#connect-git-and-github-1",
    "title": "Git and GitHub",
    "section": "Connect Git and GitHub",
    "text": "Connect Git and GitHub\n\nDetailed instructions are here.\nCarefully follow the instructions provided by GitHub.\nWhen setting permissions for the token, choose non-expiring and select the repo option in the scopes section.\nOnce you complete these steps, GitHub will display your token—a lengthy string of characters.\nImmediately copy this token to your clipboard. This is the only time GitHub will show it to you."
  },
  {
    "objectID": "slides/productivity/04-git.html#generate-a-token",
    "href": "slides/productivity/04-git.html#generate-a-token",
    "title": "Git and GitHub",
    "section": "Generate a token:",
    "text": "Generate a token:\n\nFor security, save this token in a password manager. This ensures you can access it if needed later on.\nWhen git prompts you to enter your password, paste the token you’ve copied. After this, password prompts should no longer appear.\nIf you ever need the token again, retrieve it from your password manager.\n\nMore details available from Happy Git and GitHub for the use."
  },
  {
    "objectID": "slides/productivity/04-git.html#connect-git-and-github-2",
    "href": "slides/productivity/04-git.html#connect-git-and-github-2",
    "title": "Git and GitHub",
    "section": "Connect Git and GitHub",
    "text": "Connect Git and GitHub\n\nThe next step is to let Git know who we are on Github.\nTo to this type the following two commands in our terminal window:\n\n\ngit config --global user.name \"Your Name\"\ngit config --global user.mail \"your@email.com\""
  },
  {
    "objectID": "slides/productivity/04-git.html#connect-git-and-github-3",
    "href": "slides/productivity/04-git.html#connect-git-and-github-3",
    "title": "Git and GitHub",
    "section": "Connect Git and GitHub",
    "text": "Connect Git and GitHub\n\nThis will change the Git configuration in way that anytime you use Git, it will know this information.\nNote that you need to use the email account that you used to open your GitHub account."
  },
  {
    "objectID": "slides/productivity/04-git.html#connect-git-and-github-4",
    "href": "slides/productivity/04-git.html#connect-git-and-github-4",
    "title": "Git and GitHub",
    "section": "Connect Git and GitHub",
    "text": "Connect Git and GitHub\nTo connect working directory to the GitHub repo\n\ninitialize the directory:\n\n\ngit init\n\n\nLet Git know what is the remote repository.\n\n\ngit remote add origin &lt;remote-url&gt;\n\nNow the two are connected.\n\n\n\n\n\n\nNote\n\n\norigin is a nickname we will use for the remote. We can call it something else, but everybody calls it origin so best to stick with that."
  },
  {
    "objectID": "slides/productivity/04-git.html#overview-of-git",
    "href": "slides/productivity/04-git.html#overview-of-git",
    "title": "Git and GitHub",
    "section": "Overview of Git",
    "text": "Overview of Git\nThe main actions in Git are to:\n\npull changes from the remote repo.\nadd files, or as we say in the Git lingo stage files.\ncommit changes to the local repo.\npush changes to the remote repo."
  },
  {
    "objectID": "slides/productivity/04-git.html#the-four-areas-of-git",
    "href": "slides/productivity/04-git.html#the-four-areas-of-git",
    "title": "Git and GitHub",
    "section": "The four areas of Git",
    "text": "The four areas of Git"
  },
  {
    "objectID": "slides/productivity/04-git.html#status",
    "href": "slides/productivity/04-git.html#status",
    "title": "Git and GitHub",
    "section": "Status",
    "text": "Status\n\n\ngit status filename"
  },
  {
    "objectID": "slides/productivity/04-git.html#add",
    "href": "slides/productivity/04-git.html#add",
    "title": "Git and GitHub",
    "section": "Add",
    "text": "Add\nUse git add to put file to staging area.\n\n\ngit add &lt;filename&gt;\n\nWe say that this file has been staged. Check to see what happened:\n\ngit status &lt;filename&gt;"
  },
  {
    "objectID": "slides/productivity/04-git.html#commit",
    "href": "slides/productivity/04-git.html#commit",
    "title": "Git and GitHub",
    "section": "Commit",
    "text": "Commit\n\nTo move all the staged files to the local repository we use git commit.\n\n\n\ngit commit -m \"must add comment\"\n\n\nOnce committed the files are tracked and a copy of this version is kept going forward.\nThis is like adding V1 to your filename."
  },
  {
    "objectID": "slides/productivity/04-git.html#commit-1",
    "href": "slides/productivity/04-git.html#commit-1",
    "title": "Git and GitHub",
    "section": "Commit",
    "text": "Commit\n\n\n\n\n\n\nNote\n\n\nYou can commit files directly without using add by explicitely writing the files at the end of the commit:\n\n\n\n\ngit commit -m \"must add comment\" &lt;filename&gt;"
  },
  {
    "objectID": "slides/productivity/04-git.html#push",
    "href": "slides/productivity/04-git.html#push",
    "title": "Git and GitHub",
    "section": "Push",
    "text": "Push\n\nTo move to upstream repo we use git push\n\n\n\ngit push -u origin main\n\n\nThe -u flag sets the upstream repo.\nBy using this flag, going forward you can simply use git push to push changes.\nSo going forward we can just type:\n\n\ngit push"
  },
  {
    "objectID": "slides/productivity/04-git.html#push-1",
    "href": "slides/productivity/04-git.html#push-1",
    "title": "Git and GitHub",
    "section": "Push",
    "text": "Push\n\nWhen using git push we need to be careful as if collaborating this will affect the work of others.\nIt might also create a conflict.\n\n\nPosted by andortang on Nothing is Impossible!"
  },
  {
    "objectID": "slides/productivity/04-git.html#fetch",
    "href": "slides/productivity/04-git.html#fetch",
    "title": "Git and GitHub",
    "section": "Fetch",
    "text": "Fetch\n\nTo update our local repository to the remote one we use\n\n\ngit fetch"
  },
  {
    "objectID": "slides/productivity/04-git.html#merge",
    "href": "slides/productivity/04-git.html#merge",
    "title": "Git and GitHub",
    "section": "Merge",
    "text": "Merge\n\nOnce we are sure this is good, we can merge with our local files:\n\n\ngit merge"
  },
  {
    "objectID": "slides/productivity/04-git.html#pull",
    "href": "slides/productivity/04-git.html#pull",
    "title": "Git and GitHub",
    "section": "Pull",
    "text": "Pull\n\nI rarely use fetch and merge and instead use pull which does both of these in one step\n\n\ngit pull"
  },
  {
    "objectID": "slides/productivity/04-git.html#checkout",
    "href": "slides/productivity/04-git.html#checkout",
    "title": "Git and GitHub",
    "section": "Checkout",
    "text": "Checkout\n\nIf you want to pull down a specific file you from the remote repo you can use:\n\n\ngit checkout filename\n\n\nI use this when I make changes but decide I want to go back to original version on remote repo.\n\n\n\n\n\n\n\nWarning\n\n\nIf you have a newer version in your local repository this will create a conflict. It won’t let you do it. If you are sure you want to get rid of your local copy you can remove it and then use checkout."
  },
  {
    "objectID": "slides/productivity/04-git.html#checkout-1",
    "href": "slides/productivity/04-git.html#checkout-1",
    "title": "Git and GitHub",
    "section": "Checkout",
    "text": "Checkout\n\nYou can also use checkout to obtain older version:\n\n\ngit checkout &lt;commit-id&gt; &lt;filename&gt;\n\n\nYou can get the commit-id either on the GitHub webpage or using\n\n\ngit log filename"
  },
  {
    "objectID": "slides/productivity/04-git.html#reset",
    "href": "slides/productivity/04-git.html#reset",
    "title": "Git and GitHub",
    "section": "Reset",
    "text": "Reset\n\nWhat if I commit and realize it was a mistake?\n\n\ngit reset HEAD~1\n\nundos the commit and unstages the files, but keeps your local copies. I use this on very often.\n\nThere are many wasy of using get reset and it covers most scenarios.\nChatGPT and stackoverflow are great resources to learn more."
  },
  {
    "objectID": "slides/productivity/04-git.html#branches",
    "href": "slides/productivity/04-git.html#branches",
    "title": "Git and GitHub",
    "section": "Branches",
    "text": "Branches\n\nWe are just sratching the surface of Git.\nOne advanced feature to be aware of is that you can have several branches, useful for working in parallel or testing stuff out that might not make the main repo.\n\n\nArt by: Allison Horst"
  },
  {
    "objectID": "slides/productivity/04-git.html#branches-1",
    "href": "slides/productivity/04-git.html#branches-1",
    "title": "Git and GitHub",
    "section": "Branches",
    "text": "Branches\n\nWe wont go over this, but we might need to use these two related commands:\n\n\ngit remote -v\ngit brach"
  },
  {
    "objectID": "slides/productivity/04-git.html#clone",
    "href": "slides/productivity/04-git.html#clone",
    "title": "Git and GitHub",
    "section": "Clone",
    "text": "Clone\n\nAnother common command is git clone.\nIt let’s download an entire repo, including version history.\n\n\ngit clone &lt;repo-url&gt;"
  },
  {
    "objectID": "slides/productivity/04-git.html#using-git-in-rstudio",
    "href": "slides/productivity/04-git.html#using-git-in-rstudio",
    "title": "Git and GitHub",
    "section": "Using Git in RStudio",
    "text": "Using Git in RStudio\n\nGo to file, new project, version control, and follow the instructions.\nThen notice the Git tab in the preferences."
  }
]